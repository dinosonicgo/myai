### AI Lover Log - Last updated at 2025-09-14T22:32:47.042610 ###

2025-09-14 22:25:43 - [INFO] - [512280345618546699] 正在創建模型 'gemini-2.5-flash-lite' 實例 (API Key index: 4)
2025-09-14 22:25:43 - [INFO] - [512280345618546699] --- 開始嘗試模型: 'gemini-2.5-pro' (優先級 1/3) ---
2025-09-14 22:25:43 - [INFO] - [512280345618546699] 正在創建 Embedding 模型實例 (API Key index: 0)
2025-09-14 22:25:43 - [INFO] - [512280345618546699] 正在創建模型 'gemini-2.5-pro' 實例 (API Key index: 1)
2025-09-14 22:25:43 - [ERROR] - [512280345618546699] 在 ainvoke 期間發生未知錯誤 (模型: gemini-2.5-pro): "Input to ChatPromptTemplate is missing variables {'historical_context'}.  Expected: ['core_protocol_prompt', 'historical_context', 'latest_user_input', 'plot_anchor', 'response_style_prompt', 'world_snapshot'] Received: ['core_protocol_prompt', 'response_style_prompt', 'chat_history', 'plot_anchor', 'world_snapshot', 'tool_execution_results', 'latest_user_input']\nNote: if you intended {historical_context} to be part of the string and not a variable, please escape it with double curly braces like: '{{historical_context}}'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT "
Traceback (most recent call last):
  File "D:\DINO\SD\ComfyUI\personal_server\ai_lover_service\src\ai_core.py", line 3721, in ainvoke_with_rotation
    result = await asyncio.wait_for(
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\asyncio\tasks.py", line 445, in wait_for
    return fut.result()
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\runnables\base.py", line 5447, in ainvoke
    return await self.bound.ainvoke(
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\runnables\base.py", line 3088, in ainvoke
    input_ = await coro_with_context(part(), context, create_task=True)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\runnables\base.py", line 1990, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    inner_input_ = self._validate_input(inner_input)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: "Input to ChatPromptTemplate is missing variables {'historical_context'}.  Expected: ['core_protocol_prompt', 'historical_context', 'latest_user_input', 'plot_anchor', 'response_style_prompt', 'world_snapshot'] Received: ['core_protocol_prompt', 'response_style_prompt', 'chat_history', 'plot_anchor', 'world_snapshot', 'tool_execution_results', 'latest_user_input']\nNote: if you intended {historical_context} to be part of the string and not a variable, please escape it with double curly braces like: '{{historical_context}}'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT "
2025-09-14 22:25:46 - [WARNING] - [512280345618546699] [Model Degradation] 模型 'gemini-2.5-pro' 在嘗試所有可用 API 金鑰後均失敗。正在降級到下一個模型...
2025-09-14 22:25:46 - [INFO] - [512280345618546699] --- 開始嘗試模型: 'gemini-2.5-flash' (優先級 2/3) ---
2025-09-14 22:25:46 - [INFO] - [512280345618546699] 正在創建 Embedding 模型實例 (API Key index: 3)
2025-09-14 22:25:46 - [INFO] - [512280345618546699] 正在創建模型 'gemini-2.5-flash' 實例 (API Key index: 4)
2025-09-14 22:25:46 - [ERROR] - [512280345618546699] 在 ainvoke 期間發生未知錯誤 (模型: gemini-2.5-flash): "Input to ChatPromptTemplate is missing variables {'historical_context'}.  Expected: ['core_protocol_prompt', 'historical_context', 'latest_user_input', 'plot_anchor', 'response_style_prompt', 'world_snapshot'] Received: ['core_protocol_prompt', 'response_style_prompt', 'chat_history', 'plot_anchor', 'world_snapshot', 'tool_execution_results', 'latest_user_input']\nNote: if you intended {historical_context} to be part of the string and not a variable, please escape it with double curly braces like: '{{historical_context}}'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT "
Traceback (most recent call last):
  File "D:\DINO\SD\ComfyUI\personal_server\ai_lover_service\src\ai_core.py", line 3721, in ainvoke_with_rotation
    result = await asyncio.wait_for(
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\asyncio\tasks.py", line 445, in wait_for
    return fut.result()
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\runnables\base.py", line 5447, in ainvoke
    return await self.bound.ainvoke(
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\runnables\base.py", line 3088, in ainvoke
    input_ = await coro_with_context(part(), context, create_task=True)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\runnables\base.py", line 1990, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    inner_input_ = self._validate_input(inner_input)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: "Input to ChatPromptTemplate is missing variables {'historical_context'}.  Expected: ['core_protocol_prompt', 'historical_context', 'latest_user_input', 'plot_anchor', 'response_style_prompt', 'world_snapshot'] Received: ['core_protocol_prompt', 'response_style_prompt', 'chat_history', 'plot_anchor', 'world_snapshot', 'tool_execution_results', 'latest_user_input']\nNote: if you intended {historical_context} to be part of the string and not a variable, please escape it with double curly braces like: '{{historical_context}}'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT "
2025-09-14 22:25:49 - [WARNING] - [512280345618546699] [Model Degradation] 模型 'gemini-2.5-flash' 在嘗試所有可用 API 金鑰後均失敗。正在降級到下一個模型...
2025-09-14 22:25:49 - [INFO] - [512280345618546699] --- 開始嘗試模型: 'gemini-2.5-flash-lite' (優先級 3/3) ---
2025-09-14 22:25:49 - [INFO] - [512280345618546699] 正在創建 Embedding 模型實例 (API Key index: 0)
2025-09-14 22:25:49 - [INFO] - [512280345618546699] 正在創建模型 'gemini-2.5-flash-lite' 實例 (API Key index: 1)
2025-09-14 22:25:49 - [ERROR] - [512280345618546699] 在 ainvoke 期間發生未知錯誤 (模型: gemini-2.5-flash-lite): "Input to ChatPromptTemplate is missing variables {'historical_context'}.  Expected: ['core_protocol_prompt', 'historical_context', 'latest_user_input', 'plot_anchor', 'response_style_prompt', 'world_snapshot'] Received: ['core_protocol_prompt', 'response_style_prompt', 'chat_history', 'plot_anchor', 'world_snapshot', 'tool_execution_results', 'latest_user_input']\nNote: if you intended {historical_context} to be part of the string and not a variable, please escape it with double curly braces like: '{{historical_context}}'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT "
Traceback (most recent call last):
  File "D:\DINO\SD\ComfyUI\personal_server\ai_lover_service\src\ai_core.py", line 3721, in ainvoke_with_rotation
    result = await asyncio.wait_for(
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\asyncio\tasks.py", line 445, in wait_for
    return fut.result()
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\runnables\base.py", line 5447, in ainvoke
    return await self.bound.ainvoke(
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\runnables\base.py", line 3088, in ainvoke
    input_ = await coro_with_context(part(), context, create_task=True)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\runnables\base.py", line 1990, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    inner_input_ = self._validate_input(inner_input)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: "Input to ChatPromptTemplate is missing variables {'historical_context'}.  Expected: ['core_protocol_prompt', 'historical_context', 'latest_user_input', 'plot_anchor', 'response_style_prompt', 'world_snapshot'] Received: ['core_protocol_prompt', 'response_style_prompt', 'chat_history', 'plot_anchor', 'world_snapshot', 'tool_execution_results', 'latest_user_input']\nNote: if you intended {historical_context} to be part of the string and not a variable, please escape it with double curly braces like: '{{historical_context}}'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT "
2025-09-14 22:25:52 - [ERROR] - [512280345618546699] [Final Failure] 所有模型 (gemini-2.5-pro, gemini-2.5-flash, gemini-2.5-flash-lite) 和所有可用 API 金鑰均嘗試失敗。
2025-09-14 22:25:52 - [ERROR] - [512280345618546699] 所有標準嘗試均失敗。啟動最終備援策略: 'force'
2025-09-14 22:25:52 - [WARNING] - [512280345618546699] 鏈遭遇審查。啟動【地毯式指令強化重試】策略...
2025-09-14 22:25:52 - [INFO] - [512280345618546699] 已對參數中的所有字符串欄位附加強制指令，正在進行強化重試...
2025-09-14 22:25:52 - [ERROR] - [512280345618546699] 指令強化重試最終失敗: "Input to ChatPromptTemplate is missing variables {'historical_context'}.  Expected: ['core_protocol_prompt', 'historical_context', 'latest_user_input', 'plot_anchor', 'response_style_prompt', 'world_snapshot'] Received: ['core_protocol_prompt', 'response_style_prompt', 'chat_history', 'plot_anchor', 'world_snapshot', 'tool_execution_results', 'latest_user_input']\nNote: if you intended {historical_context} to be part of the string and not a variable, please escape it with double curly braces like: '{{historical_context}}'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT "
Traceback (most recent call last):
  File "D:\DINO\SD\ComfyUI\personal_server\ai_lover_service\src\ai_core.py", line 3669, in _force_and_retry
    return await failed_chain.ainvoke(retry_params)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\runnables\base.py", line 3088, in ainvoke
    input_ = await coro_with_context(part(), context, create_task=True)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\prompts\base.py", line 242, in ainvoke
    return await self._acall_with_config(
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\runnables\base.py", line 1990, in _acall_with_config
    output: Output = await coro_with_context(coro, context)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\prompts\base.py", line 195, in _aformat_prompt_with_error_handling
    inner_input_ = self._validate_input(inner_input)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python310\lib\site-packages\langchain_core\prompts\base.py", line 183, in _validate_input
    raise KeyError(
KeyError: "Input to ChatPromptTemplate is missing variables {'historical_context'}.  Expected: ['core_protocol_prompt', 'historical_context', 'latest_user_input', 'plot_anchor', 'response_style_prompt', 'world_snapshot'] Received: ['core_protocol_prompt', 'response_style_prompt', 'chat_history', 'plot_anchor', 'world_snapshot', 'tool_execution_results', 'latest_user_input']\nNote: if you intended {historical_context} to be part of the string and not a variable, please escape it with double curly braces like: '{{historical_context}}'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT "
2025-09-14 22:25:52 - [INFO] - [512280345618546699] [敘事] 敘事生成成功。
2025-09-14 22:25:52 - [INFO] - [512280345618546699] (階段 3) 敘事生成完成。
2025-09-14 22:25:52 - [ERROR] - 處理使用者 512280345618546699 的「思考-行動-敘事」流程時發生異常: 'AILover' object has no attribute 'update_memories'
Traceback (most recent call last):
  File "D:\DINO\SD\ComfyUI\personal_server\ai_lover_service\src\discord_bot.py", line 760, in on_message
    await ai_instance.update_memories(user_input, final_response)
AttributeError: 'AILover' object has no attribute 'update_memories'
2025-09-14 22:32:32 - [INFO] - 所有持久化 UI 視圖已成功註冊。
2025-09-14 22:32:33 - [INFO] - Discord Bot is ready and commands are synced!
2025-09-14 22:32:35 - [INFO] - 【健康檢查 & Keep-Alive】背景任務已啟動。
2025-09-14 22:32:35 - [INFO] - Logged in as AI#4450 (ID: 1358417100250808531)
2025-09-14 22:32:36 - [INFO] - 已成功發送啟動成功通知給管理員。
