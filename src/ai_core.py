# ai_core.py çš„ä¸­æ–‡è¨»é‡‹(v210.0 - â€œè¦åŠƒ-æ¸²æŸ“â€çµ±ä¸€æ¶æ§‹é‡æ§‹)
# æ›´æ–°ç´€éŒ„:
# v210.0 (2025-09-09): [é‡å¤§æ¶æ§‹é‡æ§‹] æ ¹æ“šâ€œæ¥µè‡´æº–ç¢ºâ€è—åœ–ï¼Œå°æ ¸å¿ƒç”Ÿæˆæµç¨‹é€²è¡Œäº†æ ¹æœ¬æ€§é‡æ§‹ã€‚
#    1. [â€œè¦åŠƒ-æ¸²æŸ“â€çµ±ä¸€åŒ–] å»¢æ£„äº†æ‰€æœ‰â€œä¸€æ­¥åˆ°ä½â€çš„ç”Ÿæˆéˆ (å¦‚ get_direct_nsfw_chain)ï¼Œå°‡æ‰€æœ‰ SFWã€NSFWã€é æ™¯è·¯å¾‘çš„ç”Ÿæˆé‚è¼¯çµ±ä¸€ç‚ºâ€œè¦åŠƒ-æ¸²æŸ“â€å…©éšæ®µæ¨¡å¼ã€‚
#    2. [æ–°å¢å°ˆç”¨è¦åŠƒå™¨] å‰µå»ºäº†æ–°çš„ get_nsfw_planning_chain å’Œ get_remote_planning_chainï¼Œå®ƒå€‘åªè² è²¬è¼¸å‡ºçµæ§‹åŒ–çš„ TurnPlan JSONï¼Œå°‡æ±ºç­–èˆ‡å¯«ä½œå¾¹åº•åˆ†é›¢ã€‚
#    3. [å¼·åŒ–æ¸²æŸ“å™¨] å¼·åŒ–äº† get_narrative_chainï¼Œä½¿å…¶æˆç‚ºèƒ½å¤ è™•ç†æ‰€æœ‰é¡å‹ TurnPlan çš„çµ±ä¸€â€œå°èªªå®¶â€ç¯€é»ã€‚
#    4. [é å‚™ç¯€é»æ‹†åˆ†] æ–°å¢äº† retrieve_and_summarize_memories, _query_lore_from_entities, _assemble_context_from_lore ç­‰è¼”åŠ©å‡½å¼ï¼Œç‚ºä¸‹ä¸€æ­¥å°‡ graph.py ä¸­çš„åˆå§‹åŒ–ç¯€é»æ‹†åˆ†ç‚ºæ›´ç´°ç²’åº¦çš„ç¨ç«‹ç¯€é»åšå¥½äº†æº–å‚™ã€‚
# v209.0 (2025-09-06): [æ¶æ§‹é©é…] é©é…äº† v209.0 ç‰ˆæœ¬çš„ã€æ›´ç°¡åŒ–çš„æœ€çµ‚å®‰å…¨ç¶²å§”å©‰åŒ–ç­–ç•¥ã€‚
# v208.0 (2025-09-06): [ç½é›£æ€§BUGä¿®å¾©] å¾¹åº•é‡å¯«æ­¤å‡½å¼ï¼Œå¯¦ç¾æœ€çµ‚çš„â€œç¨‹åºåŒ–è§£æ§‹-é‡æ§‹â€ç­–ç•¥ã€‚

import re
import json
import time
import shutil
import warnings
import datetime
from typing import List, Dict, Optional, Any, Literal, Callable
import asyncio
import gc
from pathlib import Path
from sqlalchemy import select, or_
from collections import defaultdict
import functools

from google.api_core.exceptions import ResourceExhausted, InternalServerError, ServiceUnavailable, DeadlineExceeded

from langchain_google_genai import (
    ChatGoogleGenerativeAI, 
    GoogleGenerativeAIEmbeddings,
    HarmCategory,
    HarmBlockThreshold
)
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain.output_parsers import BooleanOutputParser
from langchain_core.exceptions import OutputParserException
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, PromptTemplate
from langchain_core.runnables import Runnable, RunnablePassthrough, RunnableParallel, RunnableBinding, RunnableLambda
from langchain_core.documents import Document
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, BaseMessage
from langchain_core._api.deprecation import LangChainDeprecationWarning
from pydantic import BaseModel, Field, ValidationError, field_validator
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_chroma import Chroma
from chromadb.errors import InternalError
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever
from Levenshtein import ratio as levenshtein_ratio

from pydantic import BaseModel, Field

from . import tools, lore_tools, lore_book
from .lore_book import add_or_update_lore as db_add_or_update_lore, get_lores_by_category_and_filter, Lore
from .models import UserProfile, PersonalMemoryEntry, GameState, CharacterProfile
from .schemas import (WorldGenesisResult, ToolCallPlan, CanonParsingResult, 
                      BatchResolutionPlan, TurnPlan, ToolCall, SceneCastingResult, 
                      UserInputAnalysis, SceneAnalysisResult, ValidationResult, ExtractedEntities, ExpansionDecision,
                      IntentClassificationResult, StyleAnalysisResult, CharacterAction)
from .database import AsyncSessionLocal, UserData, MemoryData
from src.config import settings
from .logger import logger
from .tool_context import tool_context

# å…¨å±€å¸¸é‡ï¼šGemini å®‰å…¨é–¥å€¼è¨­å®š
SAFETY_SETTINGS = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}

PROJ_DIR = Path(__file__).resolve().parent.parent

# é¡åˆ¥ï¼šAIæ ¸å¿ƒé¡
class AILover:
    MODEL_NAME = "models/gemini-2.5-flash-lite"

    # å‡½å¼ï¼šåˆå§‹åŒ–AIæ ¸å¿ƒ
    def __init__(self, user_id: str):
        self.user_id: str = user_id
        self.profile: Optional[UserProfile] = None
        self.gm_model: Optional[Runnable] = None
        
        # éˆåˆå§‹åŒ–
        self.intent_classification_chain: Optional[Runnable] = None
        self.style_analysis_chain: Optional[Runnable] = None
        self.input_analysis_chain: Optional[Runnable] = None
        self.expansion_decision_chain: Optional[Runnable] = None
        self.scene_casting_chain: Optional[Runnable] = None
        self.sfw_planning_chain: Optional[Runnable] = None
        self.nsfw_planning_chain: Optional[Runnable] = None
        self.remote_planning_chain: Optional[Runnable] = None
        self.narrative_chain: Optional[Runnable] = None
        self.output_validation_chain: Optional[Runnable] = None
        self.rewrite_chain: Optional[Runnable] = None
        self.personal_memory_chain: Optional[Runnable] = None
        self.entity_extraction_chain: Optional[Runnable] = None
        self.euphemization_chain: Optional[Runnable] = None
        
        # LORE/Setup ç›¸é—œéˆ
        self.world_genesis_chain: Optional[Runnable] = None
        self.canon_parser_chain: Optional[Runnable] = None
        self.batch_entity_resolution_chain: Optional[Runnable] = None
        self.single_entity_resolution_chain: Optional[Runnable] = None
        self.param_reconstruction_chain: Optional[Runnable] = None
        self.profile_completion_chain: Optional[Runnable] = None
        self.profile_parser_chain: Optional[Runnable] = None
        self.profile_rewriting_chain: Optional[Runnable] = None

        # Prompt æ¨¡æ¿
        self.profile_parser_prompt: Optional[ChatPromptTemplate] = None
        self.profile_completion_prompt: Optional[ChatPromptTemplate] = None
        self.profile_rewriting_prompt: Optional[ChatPromptTemplate] = None
        
        self.modular_prompts: Dict[str, str] = {}
        self.world_snapshot_template: str = ""
        
        # è¨˜æ†¶èˆ‡RAG
        self.session_histories: Dict[str, ChatMessageHistory] = {}
        self.vector_store: Optional[Chroma] = None
        self.retriever: Optional[EnsembleRetriever] = None
        self.embeddings: Optional[GoogleGenerativeAIEmbeddings] = None
        
        # å…¶ä»–
        self.available_tools: Dict[str, Runnable] = {}
        
        # API é‡‘é‘°ç®¡ç†
        self.api_keys: List[str] = settings.GOOGLE_API_KEYS_LIST
        self.current_key_index: int = 0
        if not self.api_keys:
            raise ValueError("æœªæ‰¾åˆ°ä»»ä½• Google API é‡‘é‘°ã€‚")
        
        self.vector_store_path = str(PROJ_DIR / "data" / "vector_stores" / self.user_id)
        Path(self.vector_store_path).mkdir(parents=True, exist_ok=True)
    # å‡½å¼ï¼šåˆå§‹åŒ–AIæ ¸å¿ƒ

    # å‡½å¼ï¼šå‰µå»ºä¸€å€‹åŸå§‹çš„ LLM å¯¦ä¾‹
    def _create_llm_instance(self, temperature: float = 0.7) -> ChatGoogleGenerativeAI:
        """å‰µå»ºä¸¦è¿”å›ä¸€å€‹åŸå§‹çš„ ChatGoogleGenerativeAI å¯¦ä¾‹ï¼Œä¸¦è‡ªå‹•è¼ªæ›åˆ°ä¸‹ä¸€å€‹ API é‡‘é‘°ä»¥å¯¦ç¾è² è¼‰å‡è¡¡ã€‚"""
        key_to_use = self.api_keys[self.current_key_index]
        llm = ChatGoogleGenerativeAI(
            model=self.MODEL_NAME,
            google_api_key=key_to_use,
            temperature=temperature,
            safety_settings=SAFETY_SETTINGS,
        )
        self.current_key_index = (self.current_key_index + 1) % len(self.api_keys)
        logger.info(f"[{self.user_id}] LLM å¯¦ä¾‹å·²ä½¿ç”¨ API Key #{self.current_key_index} å‰µå»ºã€‚ä¸‹ä¸€æ¬¡å°‡ä½¿ç”¨ Key #{ (self.current_key_index % len(self.api_keys)) + 1 }ã€‚")
        return llm
    # å‡½å¼ï¼šå‰µå»ºä¸€å€‹åŸå§‹çš„ LLM å¯¦ä¾‹
    
    # å‡½å¼ï¼šåˆå§‹åŒ–AIå¯¦ä¾‹
    async def initialize(self) -> bool:
        async with AsyncSessionLocal() as session:
            result = await session.get(UserData, self.user_id)
            if not result:
                return False
            if not result.one_instruction:
                try:
                    one_instruction_path = PROJ_DIR / "prompts" / "one_instruction_template.txt"
                    with open(one_instruction_path, "r", encoding="utf-8") as f:
                        result.one_instruction = f.read()
                    await session.commit()
                    await session.refresh(result)
                except FileNotFoundError: pass
            if result.username and result.ai_name and (not result.user_profile or not result.ai_profile):
                result.user_profile = CharacterProfile(name=result.username).model_dump()
                result.ai_profile = CharacterProfile(name=result.ai_name, description=result.ai_settings).model_dump()
                await session.commit()
                await session.refresh(result)
            self.profile = UserProfile(
                user_id=result.user_id,
                user_profile=CharacterProfile.model_validate(result.user_profile or {}),
                ai_profile=CharacterProfile.model_validate(result.ai_profile or {}),
                affinity=result.affinity,
                world_settings=result.world_settings,
                one_instruction=result.one_instruction,
                response_style_prompt=result.response_style_prompt,
                game_state=GameState.model_validate(result.game_state or {})
            )
        
        try:
            await self._configure_pre_requisites()
            await self._rehydrate_short_term_memory()
        except Exception as e:
            logger.error(f"[{self.user_id}] é…ç½®å‰ç½®è³‡æºæˆ–æ¢å¾©è¨˜æ†¶æ™‚ç™¼ç”Ÿè‡´å‘½éŒ¯èª¤: {e}", exc_info=True)
            return False
        return True
    # å‡½å¼ï¼šåˆå§‹åŒ–AIå¯¦ä¾‹

    # å‡½å¼ï¼šæ›´æ–°ä¸¦æŒä¹…åŒ–ä½¿ç”¨è€…è¨­å®šæª”
    async def update_and_persist_profile(self, updates: Dict[str, Any]) -> bool:
        if not self.profile:
            logger.error(f"[{self.user_id}] å˜—è©¦åœ¨æœªåˆå§‹åŒ–çš„ profile ä¸Šé€²è¡Œæ›´æ–°ã€‚")
            return False
        
        try:
            logger.info(f"[{self.user_id}] æ¥æ”¶åˆ° profile æ›´æ–°è«‹æ±‚: {list(updates.keys())}")
            
            profile_dict = self.profile.model_dump()
            
            for key, value in updates.items():
                if key in profile_dict:
                    profile_dict[key] = value

            self.profile = UserProfile.model_validate(profile_dict)

            async with AsyncSessionLocal() as session:
                user_data = await session.get(UserData, self.user_id)
                
                if not user_data:
                    logger.warning(f"[{self.user_id}] åœ¨æŒä¹…åŒ–æ›´æ–°æ™‚æ‰¾ä¸åˆ°ä½¿ç”¨è€…è³‡æ–™ï¼Œå°‡å‰µå»ºæ–°è¨˜éŒ„ã€‚")
                    user_data = UserData(user_id=self.user_id)
                    session.add(user_data)
                    try:
                        with open(PROJ_DIR / "prompts" / "zero_instruction.txt", "r", encoding="utf-8") as f:
                            user_data.one_instruction = f.read()
                    except FileNotFoundError:
                        user_data.one_instruction = "# é è¨­æŒ‡ä»¤"

                user_data.user_profile = self.profile.user_profile.model_dump()
                user_data.ai_profile = self.profile.ai_profile.model_dump()
                user_data.world_settings = self.profile.world_settings
                user_data.response_style_prompt = self.profile.response_style_prompt
                user_data.game_state = self.profile.game_state.model_dump()
                user_data.affinity = self.profile.affinity
                
                user_data.username = self.profile.user_profile.name
                user_data.ai_name = self.profile.ai_profile.name
                user_data.ai_settings = self.profile.ai_profile.description
                
                await session.commit()
            
            logger.info(f"[{self.user_id}] Profile æ›´æ–°ä¸¦æŒä¹…åŒ–æˆåŠŸã€‚")
            return True
        except ValidationError as e:
            logger.error(f"[{self.user_id}] æ›´æ–° profile æ™‚ç™¼ç”Ÿ Pydantic é©—è­‰éŒ¯èª¤: {e}", exc_info=True)
            return False
        except Exception as e:
            logger.error(f"[{self.user_id}] æ›´æ–°ä¸¦æŒä¹…åŒ– profile æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}", exc_info=True)
            return False
    # å‡½å¼ï¼šæ›´æ–°ä¸¦æŒä¹…åŒ–ä½¿ç”¨è€…è¨­å®šæª”

    # å‡½å¼ï¼šè¼•é‡ç´šé‡å»ºæ ¸å¿ƒæ¨¡å‹
    async def _rebuild_agent_with_new_key(self):
        """è¼•é‡ç´šåœ°é‡æ–°åˆå§‹åŒ–æ‰€æœ‰æ ¸å¿ƒæ¨¡å‹ï¼Œä»¥æ‡‰ç”¨æ–°çš„ API é‡‘é‘°ç­–ç•¥ï¼ˆå¦‚è² è¼‰å‡è¡¡ï¼‰ã€‚"""
        if not self.profile:
            logger.error(f"[{self.user_id}] å˜—è©¦åœ¨ç„¡ profile çš„æƒ…æ³ä¸‹é‡å»º Agentã€‚")
            return
        logger.info(f"[{self.user_id}] æ­£åœ¨è¼•é‡ç´šé‡å»ºæ ¸å¿ƒæ¨¡å‹ä»¥æ‡‰ç”¨é‡‘é‘°ç­–ç•¥...")
        self._initialize_models()
        logger.info(f"[{self.user_id}] æ ¸å¿ƒæ¨¡å‹å·²æˆåŠŸé‡å»ºã€‚")
    # å‡½å¼ï¼šè¼•é‡ç´šé‡å»ºæ ¸å¿ƒæ¨¡å‹

    # å‡½å¼ï¼šå¾è³‡æ–™åº«æ¢å¾©çŸ­æœŸè¨˜æ†¶
    async def _rehydrate_short_term_memory(self):
        logger.info(f"[{self.user_id}] æ­£åœ¨å¾è³‡æ–™åº«æ¢å¾©çŸ­æœŸè¨˜æ†¶...")
        
        if self.user_id not in self.session_histories:
            self.session_histories[self.user_id] = ChatMessageHistory()
        
        chat_history_manager = self.session_histories[self.user_id]
        
        if chat_history_manager.messages:
            logger.info(f"[{self.user_id}] çŸ­æœŸè¨˜æ†¶å·²å­˜åœ¨ï¼Œè·³éæ¢å¾©ã€‚")
            return

        async with AsyncSessionLocal() as session:
            stmt = select(MemoryData).where(MemoryData.user_id == self.user_id).order_by(MemoryData.timestamp.desc()).limit(20)
            result = await session.execute(stmt)
            recent_memories = result.scalars().all()
        
        recent_memories.reverse()

        if not recent_memories:
            logger.info(f"[{self.user_id}] æœªæ‰¾åˆ°æ­·å²å°è©±è¨˜éŒ„ï¼Œç„¡éœ€æ¢å¾©è¨˜æ†¶ã€‚")
            return

        for record in recent_memories:
            try:
                parts = record.content.split("\n\n[å ´æ™¯å›æ‡‰]:\n", 1)
                if len(parts) == 2:
                    user_part, ai_part = parts
                    user_input_match = re.search(r"èªª: (.*)", user_part, re.DOTALL)
                    if user_input_match:
                        user_input = user_input_match.group(1).strip()
                        ai_response = ai_part.strip()
                        chat_history_manager.add_user_message(user_input)
                        chat_history_manager.add_ai_message(ai_response)
            except Exception as e:
                logger.warning(f"[{self.user_id}] è§£æè¨˜æ†¶è¨˜éŒ„ ID {record.id} æ™‚å‡ºéŒ¯: {e}")
        
        logger.info(f"[{self.user_id}] æˆåŠŸæ¢å¾©äº† {len(recent_memories)} æ¢å°è©±è¨˜éŒ„åˆ°çŸ­æœŸè¨˜æ†¶ä¸­ã€‚")
    # å‡½å¼ï¼šå¾è³‡æ–™åº«æ¢å¾©çŸ­æœŸè¨˜æ†¶

    # å‡½å¼ï¼šé—œé–‰ AI å¯¦ä¾‹ä¸¦é‡‹æ”¾è³‡æº
    async def shutdown(self):
        logger.info(f"[{self.user_id}] æ­£åœ¨é—œé–‰ AI å¯¦ä¾‹ä¸¦é‡‹æ”¾è³‡æº...")
        
        if self.vector_store:
            try:
                client = self.vector_store._client
                if client and hasattr(client, '_system') and hasattr(client._system, 'stop'):
                    client._system.stop()
                    logger.info(f"[{self.user_id}] ChromaDB å¾Œå°æœå‹™å·²è«‹æ±‚åœæ­¢ã€‚")
            except Exception as e:
                logger.warning(f"[{self.user_id}] é—œé–‰ ChromaDB å®¢æˆ¶ç«¯æ™‚ç™¼ç”Ÿéè‡´å‘½éŒ¯èª¤: {e}", exc_info=True)
        
        self.vector_store = None
        self.retriever = None
        gc.collect()
        await asyncio.sleep(1.0)
        
        self.gm_model = None
        # ... æ¸…ç†æ‰€æœ‰éˆ ...
        self.session_histories.clear()
        
        logger.info(f"[{self.user_id}] AI å¯¦ä¾‹è³‡æºå·²é‡‹æ”¾ã€‚")
    # å‡½å¼ï¼šé—œé–‰ AI å¯¦ä¾‹ä¸¦é‡‹æ”¾è³‡æº

    # ==============================================================================
    # == ğŸ“ Prompt æ¨¡æ¿ç²å–å™¨ v210.0 ğŸ“
    # ==============================================================================

    # å‡½å¼ï¼šç²å–è§’è‰²æª”æ¡ˆè§£æå™¨ Prompt
    def get_profile_parser_prompt(self) -> ChatPromptTemplate:
        if self.profile_parser_prompt is None:
            prompt_str = """ä½ æ˜¯ä¸€ä½ç²¾ç¢ºçš„æ•¸æ“šåˆ†æå¸«ã€‚ä½ çš„ä»»å‹™æ˜¯å°‡ã€åŸå§‹è§’è‰²JSONã€‘èˆ‡ã€ä½¿ç”¨è€…çš„è‡ªç„¶èªè¨€è¼¸å…¥ã€‘ç›¸çµåˆï¼Œç”Ÿæˆä¸€å€‹æ›´æ–°åçš„ã€çµæ§‹åŒ–çš„è§’è‰²JSONã€‚

ã€æ ¸å¿ƒè¦å‰‡ã€‘
1.  **ä»¥åŸå§‹JSONç‚ºåŸºç¤**: ä½ å¿…é ˆä»¥ã€åŸå§‹è§’è‰²JSONã€‘ç‚ºåŸºç¤é€²è¡Œæ›´æ–°ã€‚
2.  **æ™ºèƒ½æå–èˆ‡åˆä½µ**: å¾ã€ä½¿ç”¨è€…çš„è‡ªç„¶èªè¨€è¼¸å…¥ã€‘ä¸­ï¼Œæ™ºèƒ½åœ°æå–æ‰€æœ‰é—œæ–¼è§’è‰²çš„å…·é«”è³‡è¨Šï¼ˆå¦‚åå­—ã€æ€§åˆ¥ã€å¹´é½¡ã€ç¨®æ—ã€é«®å‹ã€ç³è‰²ã€ä¸‰åœã€èº«é«˜é«”é‡ã€æ€§æ ¼ã€èƒŒæ™¯æ•…äº‹ç­‰ï¼‰ï¼Œä¸¦å°‡é€™äº›æ–°è³‡è¨Šå¡«å¯«æˆ–è¦†è“‹åˆ°å°æ‡‰çš„æ¬„ä½ä¸­ã€‚
3.  **ä¿ç•™æœªæåŠçš„è³‡è¨Š**: å°æ–¼ä½¿ç”¨è€…æ²’æœ‰æåŠçš„æ¬„ä½ï¼Œä½ å¿…é ˆä¿ç•™ã€åŸå§‹è§’è‰²JSONã€‘ä¸­çš„åŸæœ‰æ•¸å€¼ã€‚
4.  **è¼¸å‡ºç´”æ·¨JSON**: ä½ çš„æœ€çµ‚è¼¸å‡ºã€å¿…é ˆä¸”åªèƒ½ã€‘æ˜¯ä¸€å€‹æ›´æ–°å¾Œçš„ã€ç¬¦åˆ CharacterProfile Pydantic æ ¼å¼çš„ JSON ç‰©ä»¶ã€‚

---
ã€åŸå§‹è§’è‰²JSONã€‘:
{original_profile_json}
---
ã€ä½¿ç”¨è€…çš„è‡ªç„¶èªè¨€è¼¸å…¥ã€‘:
{user_text_input}
---"""
            self.profile_parser_prompt = ChatPromptTemplate.from_template(prompt_str)
        return self.profile_parser_prompt
    # å‡½å¼ï¼šç²å–è§’è‰²æª”æ¡ˆè§£æå™¨ Prompt

    # å‡½å¼ï¼šå°‡ä¸–ç•Œè–ç¶“æ·»åŠ åˆ°å‘é‡å„²å­˜ (v1.0 - æ¢å¾©)
    # æ›´æ–°ç´€éŒ„:
    # v1.0 (2025-09-10): [ç½é›£æ€§BUGä¿®å¾©] æ¢å¾©é€™å€‹åœ¨ v210.0 é‡æ§‹ä¸­è¢«æ„å¤–åˆªé™¤çš„æ ¸å¿ƒå‡½å¼ã€‚æ­¤å‡½å¼è² è²¬è™•ç†ä¸–ç•Œè–ç¶“æ–‡æœ¬ï¼Œå°‡å…¶åˆ†å¡Šä¸¦å­˜å…¥å‘é‡æ•¸æ“šåº«ï¼Œæ˜¯ RAG åŠŸèƒ½çš„åŸºç¤ã€‚
    async def add_canon_to_vector_store(self, text_content: str) -> int:
        """
        å°‡ä¸–ç•Œè–ç¶“ï¼ˆcanonï¼‰æ–‡æœ¬å…§å®¹åˆ†å‰²æˆå¡Šï¼Œä¸¦å°‡å…¶æ·»åŠ åˆ°å‘é‡å„²å­˜ä¸­ï¼Œç”¨æ–¼å¾ŒçºŒçš„æª¢ç´¢ã€‚
        åœ¨æ·»åŠ æ–°å…§å®¹å‰ï¼Œæœƒå…ˆæ¸…é™¤æ‰€æœ‰èˆŠçš„ 'canon' ä¾†æºæ•¸æ“šã€‚
        """
        if not self.vector_store:
            logger.error(f"[{self.user_id}] å˜—è©¦å°‡è–ç¶“æ·»åŠ åˆ°æœªåˆå§‹åŒ–çš„å‘é‡å„²å­˜ä¸­ã€‚")
            raise ValueError("Vector store is not initialized.")
            
        try:
            # æ­¥é©Ÿ 1: åˆªé™¤èˆŠçš„è–ç¶“æ¢ç›®ä»¥ç¢ºä¿æ•¸æ“šæœ€æ–°
            collection = await asyncio.to_thread(self.vector_store.get)
            ids_to_delete = [
                doc_id for i, doc_id in enumerate(collection['ids']) 
                if collection['metadatas'][i].get('source') == 'canon'
            ]
            if ids_to_delete:
                await asyncio.to_thread(self.vector_store.delete, ids=ids_to_delete)
                logger.info(f"[{self.user_id}] å·²å¾å‘é‡å„²å­˜ä¸­åˆªé™¤ {len(ids_to_delete)} æ¢èˆŠçš„è–ç¶“æ¢ç›®ã€‚")

            # æ­¥é©Ÿ 2: åˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000, 
                chunk_overlap=200, 
                length_function=len
            )
            
            # æ­¥é©Ÿ 3: å‰µå»ºæ–‡æª”å¡Š
            docs = text_splitter.create_documents([text_content])
            
            # æ­¥é©Ÿ 4: å°‡æ–°æ–‡æª”æ·»åŠ åˆ°å‘é‡å„²å­˜
            if docs:
                await asyncio.to_thread(
                    self.vector_store.add_texts, 
                    texts=[doc.page_content for doc in docs], 
                    metadatas=[{"source": "canon"} for _ in docs]
                )
                logger.info(f"[{self.user_id}] å·²æˆåŠŸå°‡è–ç¶“æ–‡æœ¬åˆ†å‰²ä¸¦æ·»åŠ ç‚º {len(docs)} å€‹çŸ¥è­˜ç‰‡æ®µã€‚")
                return len(docs)
                
            return 0
        except Exception as e:
            logger.error(f"[{self.user_id}] åœ¨è™•ç†ä¸–ç•Œè–ç¶“ä¸¦æ·»åŠ åˆ°å‘é‡å„²å­˜æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            raise
    # å‡½å¼ï¼šå°‡ä¸–ç•Œè–ç¶“æ·»åŠ åˆ°å‘é‡å„²å­˜ (v1.0 - æ¢å¾©)

    

    # å‡½å¼ï¼šç²å–è§’è‰²æª”æ¡ˆè£œå®Œ Prompt
    def get_profile_completion_prompt(self) -> ChatPromptTemplate:
        if self.profile_completion_prompt is None:
            prompt_str = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è§’è‰²æ‰®æ¼”æ¸¸æˆè®¾å®šå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯æ¥æ”¶ä¸€ä¸ªä¸å®Œæ•´çš„è§’è‰² JSONï¼Œå¹¶å°†å…¶è¡¥å®Œä¸ºä¸€ä¸ªç»†èŠ‚è±å¯Œã€ç¬¦åˆé€»è¾‘çš„å®Œæ•´è§’è‰²ã€‚
ã€æ ¸å¿ƒè¦å‰‡ã€‘
1.  **çµ•å°ä¿ç•™åŸå‰‡**: å¯¹äºè¼¸å…¥JSONä¸­ã€ä»»ä½•å·²ç¶“å­˜åœ¨å€¼ã€‘çš„æ¬„ä½ï¼ˆç‰¹åˆ«æ˜¯ `appearance_details` å­—å…¸å…§çš„éµå€¼å°ï¼‰ï¼Œä½ ã€çµ•å°å¿…é ˆã€‘åŸå°ä¸å‹•åœ°ä¿ç•™å®ƒå€‘ï¼Œã€çµ•å°ç¦æ­¢ã€‘ä¿®æ”¹æˆ–è¦†è“‹ã€‚
2.  **å¢é‡è£œå®ŒåŸå‰‡**: ä½ çš„ä»»å‹™æ˜¯ã€åªã€‘å¡«å¯«é‚£äº›å€¼ç‚º`null`ã€ç©ºå­—ç¬¦ä¸²`""`ã€ç©ºåˆ—è¡¨`[]`æˆ–ç©ºå­—å…¸`{{}}`çš„æ¬„ä½ã€‚ä½ ã€å¿…é ˆã€‘åŸºæ–¼å·²æœ‰çš„è³‡è¨Šï¼ˆå¦‚åå­—ã€æè¿°ã€å·²æœ‰çš„å¤–è§€ç´°ç¯€ï¼‰ï¼Œå¯Œæœ‰å‰µé€ åŠ›åœ°è£œå®Œã€å…¶ä»–ç¼ºå¤±çš„éƒ¨åˆ†ã€‘ã€‚
3.  **ç´°ç¯€è±å¯ŒåŒ–**: å¯¹äº `appearance_details`ï¼Œå¦‚æœç¼ºå°‘èº«é«˜ã€ä½“é‡ã€ä¸‰å›´ç­‰ç´°ç¯€ï¼Œè«‹åŸºæ–¼è§’è‰²æè¿°é€²è¡Œåˆç†çš„å‰µé€ ã€‚
4.  **åˆå§‹è£å‚™**: å¯¹äº `equipment`ï¼Œå¦‚æœè©²æ¬„ä½ç‚ºç©ºï¼Œè«‹ç”Ÿæˆä¸€å¥—ç¬¦åˆè§’è‰²èƒŒæ™¯å’Œæè¿°çš„åˆå§‹æœè£æˆ–è£å‚™ã€‚
5.  **è¼¸å‡ºæ ¼å¼**: ä½ çš„æœ€çµ‚è¼¸å‡ºã€å¿…é ˆä¸”åªèƒ½ã€‘æ˜¯ä¸€å€‹ç¬¦åˆ CharacterProfile Pydantic æ ¼å¼çš„ã€è£œå®Œå¾Œçš„å®Œæ•´ JSON ç‰©ä»¶ã€‚

ã€ä¸å®Œæ•´çš„è§’è‰² JSONã€‘:
{profile_json}"""
            self.profile_completion_prompt = ChatPromptTemplate.from_template(prompt_str)
        return self.profile_completion_prompt
    # å‡½å¼ï¼šç²å–è§’è‰²æª”æ¡ˆè£œå®Œ Prompt

    # å‡½å¼ï¼šç²å–è§’è‰²æª”æ¡ˆé‡å¯« Prompt
    def get_profile_rewriting_prompt(self) -> ChatPromptTemplate:
        if self.profile_rewriting_prompt is None:
            prompt_str = """ä½ æ˜¯ä¸€ä½æŠ€è—ç²¾æ¹›çš„ä½œå®¶å’Œè§’è‰²ç·¨è¼¯ã€‚
ä½ çš„ä»»å‹™æ˜¯æ ¹æ“šä½¿ç”¨è€…æå‡ºçš„ã€ä¿®æ”¹æŒ‡ä»¤ã€‘ï¼Œé‡å¯«ä¸€ä»½ã€åŸå§‹çš„è§’è‰²æè¿°ã€‘ã€‚
ã€æ ¸å¿ƒè¦å‰‡ã€‘
1.  **ç†è§£ä¸¦èåˆ**: ä½ å¿…é ˆæ·±åˆ»ç†è§£ã€ä¿®æ”¹æŒ‡ä»¤ã€‘çš„æ ¸å¿ƒæ„åœ–ï¼Œä¸¦å°‡å…¶ç„¡ç¸«åœ°ã€å‰µé€ æ€§åœ°èåˆé€²ã€åŸå§‹çš„è§’è‰²æè¿°ã€‘ä¸­ã€‚
2.  **ä¿ç•™ç²¾é«“**: åœ¨ä¿®æ”¹çš„åŒæ™‚ï¼Œç›¡åŠ›ä¿ç•™è§’è‰²åŸæœ‰çš„æ ¸å¿ƒèº«ä»½å’Œé—œéµèƒŒæ™¯ï¼Œé™¤éæŒ‡ä»¤æ˜ç¢ºè¦æ±‚æ”¹è®Šå®ƒå€‘ã€‚ä½ çš„ç›®æ¨™æ˜¯ã€Œæ¼”é€²ã€è§’è‰²ï¼Œè€Œä¸æ˜¯ã€Œæ›¿æ›ã€è§’è‰²ã€‚
3.  **è¼¸å‡ºç´”æ·¨**: ä½ çš„æœ€çµ‚è¼¸å‡ºã€å¿…é ˆä¸”åªèƒ½ã€‘æ˜¯é‡å¯«å¾Œå¾—åˆ°çš„ã€å…¨æ–°çš„è§’è‰²æè¿°æ–‡å­—ã€‚ç¦æ­¢åŒ…å«ä»»ä½•é¡å¤–çš„è§£é‡‹ã€æ¨™é¡Œæˆ–è©•è«–ã€‚
---
ã€åŸå§‹çš„è§’è‰²æè¿°ã€‘:
{original_description}
---
ã€ä½¿ç”¨è€…çš„ä¿®æ”¹æŒ‡ä»¤ã€‘:
{edit_instruction}
---
ã€é‡å¯«å¾Œçš„è§’è‰²æè¿°ã€‘:"""
            self.profile_rewriting_prompt = ChatPromptTemplate.from_template(prompt_str)
        return self.profile_rewriting_prompt
    # å‡½å¼ï¼šç²å–è§’è‰²æª”æ¡ˆé‡å¯« Prompt

    # ==============================================================================
    # == âš™ï¸ æ ¸å¿ƒè¼”åŠ©å‡½å¼ v210.0 âš™ï¸
    # ==============================================================================
    
    # å‡½å¼ï¼šåŠ è¼‰æ‰€æœ‰æ¨¡æ¿æª”æ¡ˆ
    def _load_templates(self):
        """å¾ prompts/ ç›®éŒ„åŠ è¼‰æ‰€æœ‰éœ€è¦çš„æ ¸å¿ƒåŠæ¨¡çµ„åŒ–æ¨¡æ¿æª”æ¡ˆã€‚"""
        try:
            template_path = PROJ_DIR / "prompts" / "world_snapshot_template.txt"
            with open(template_path, "r", encoding="utf-8") as f:
                self.world_snapshot_template = f.read()
            logger.info(f"[{self.user_id}] æ ¸å¿ƒæ•¸æ“šæ¨¡æ¿ 'world_snapshot_template.txt' å·²æˆåŠŸåŠ è¼‰ã€‚")
        except FileNotFoundError:
            logger.error(f"[{self.user_id}] è‡´å‘½éŒ¯èª¤: æœªæ‰¾åˆ°æ ¸å¿ƒæ•¸æ“šæ¨¡æ¿ 'world_snapshot_template.txt'ï¼")
            self.world_snapshot_template = "éŒ¯èª¤ï¼šä¸–ç•Œå¿«ç…§æ•¸æ“šæ¨¡æ¿æœªæ‰¾åˆ°ã€‚"

        self.modular_prompts = {}
        try:
            modular_prompts_dir = PROJ_DIR / "prompts" / "modular"
            if not modular_prompts_dir.is_dir():
                logger.warning(f"[{self.user_id}] æœªæ‰¾åˆ°æ¨¡çµ„åŒ–æç¤ºè©ç›®éŒ„: {modular_prompts_dir}ï¼Œå°‡è·³éåŠ è¼‰ã€‚")
                return

            loaded_modules = []
            for prompt_file in modular_prompts_dir.glob("*.txt"):
                module_name = prompt_file.stem
                with open(prompt_file, "r", encoding="utf-8") as f:
                    self.modular_prompts[module_name] = f.read()
                loaded_modules.append(module_name)

            if loaded_modules:
                logger.info(f"[{self.user_id}] å·²æˆåŠŸåŠ è¼‰ {len(loaded_modules)} å€‹æˆ°è¡“æŒ‡ä»¤æ¨¡çµ„: {', '.join(loaded_modules)}")
            else:
                logger.info(f"[{self.user_id}] åœ¨æ¨¡çµ„åŒ–ç›®éŒ„ä¸­æœªæ‰¾åˆ°å¯åŠ è¼‰çš„æˆ°è¡“æŒ‡ä»¤ã€‚")
        except Exception as e:
            logger.error(f"[{self.user_id}] åŠ è¼‰æ¨¡çµ„åŒ–æˆ°è¡“æŒ‡ä»¤æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)
    # å‡½å¼ï¼šåŠ è¼‰æ‰€æœ‰æ¨¡æ¿æª”æ¡ˆ

    # å‡½å¼ï¼š[æ–°] æª¢ç´¢ä¸¦ç¸½çµè¨˜æ†¶ (ç”¨æ–¼ retrieve_memories_node)
    async def retrieve_and_summarize_memories(self, user_input: str) -> str:
        """[æ–°] åŸ·è¡ŒRAGæª¢ç´¢ä¸¦å°‡çµæœç¸½çµç‚ºæ‘˜è¦ã€‚é€™æ˜¯å°ˆé–€ç‚ºæ–°çš„ retrieve_memories_node è¨­è¨ˆçš„ã€‚"""
        if not self.retriever:
            logger.warning(f"[{self.user_id}] æª¢ç´¢å™¨æœªåˆå§‹åŒ–ï¼Œç„¡æ³•æª¢ç´¢è¨˜æ†¶ã€‚")
            return "æ²’æœ‰æª¢ç´¢åˆ°ç›¸é—œçš„é•·æœŸè¨˜æ†¶ã€‚"
        
        retrieved_docs = await self.ainvoke_with_rotation(self.retriever, user_input, retry_strategy='euphemize')
        if retrieved_docs is None:
            logger.warning(f"[{self.user_id}] RAG æª¢ç´¢è¿”å› None (å¯èƒ½å› å§”å©‰åŒ–å¤±æ•—)ï¼Œä½¿ç”¨ç©ºåˆ—è¡¨ä½œç‚ºå‚™æ´ã€‚")
            retrieved_docs = []
            
        if not retrieved_docs:
            return "æ²’æœ‰æª¢ç´¢åˆ°ç›¸é—œçš„é•·æœŸè¨˜æ†¶ã€‚"

        summarized_context = await self.ainvoke_with_rotation(
            self.get_rag_summarizer_chain(), 
            retrieved_docs, 
            retry_strategy='euphemize'
        )

        if not summarized_context or not summarized_context.strip():
             logger.warning(f"[{self.user_id}] RAG ç¸½çµéˆè¿”å›äº†ç©ºçš„å…§å®¹ï¼ˆå¯èƒ½å› å§”å©‰åŒ–é‡è©¦å¤±æ•—ï¼‰ã€‚")
             summarized_context = "ä»è¨˜æ†¶ä¸­æª¢ç´¢åˆ°ä¸€äº›ç›¸é—œç‰‡æ®µï¼Œä½†ç„¡æ³•ç”Ÿæˆæ¸…æ™°çš„æ‘˜è¦ã€‚"
        
        logger.info(f"[{self.user_id}] å·²æˆåŠŸå°‡ RAG ä¸Šä¸‹æ–‡æç…‰ç‚ºäº‹å¯¦è¦é»ã€‚")
        return f"ã€èƒŒæ™¯æ­·å²åƒè€ƒï¼ˆäº‹å¯¦è¦é»ï¼‰ã€‘:\n{summarized_context}"
    # å‡½å¼ï¼š[æ–°] æª¢ç´¢ä¸¦ç¸½çµè¨˜æ†¶ (ç”¨æ–¼ retrieve_memories_node)

    # å‡½å¼ï¼š[æ–°] å¾å¯¦é«”æŸ¥è©¢LORE (ç”¨æ–¼ query_lore_node)
    async def _query_lore_from_entities(self, user_input: str, is_remote_scene: bool = False) -> List[Lore]:
        """[æ–°] æå–å¯¦é«”ä¸¦æŸ¥è©¢å…¶åŸå§‹LOREå°è±¡ã€‚é€™æ˜¯å°ˆé–€ç‚ºæ–°çš„ query_lore_node è¨­è¨ˆçš„ã€‚"""
        if not self.profile: return []

        if is_remote_scene:
            text_for_extraction = user_input
        else:
            chat_history_manager = self.session_histories.get(self.user_id, ChatMessageHistory())
            recent_dialogue = "\n".join([f"{'ä½¿ç”¨è€…' if isinstance(m, HumanMessage) else 'AI'}: {m.content}" for m in chat_history_manager.messages[-2:]])
            text_for_extraction = f"{user_input}\n{recent_dialogue}"

        entity_extraction_chain = self.get_entity_extraction_chain()
        entity_result = await self.ainvoke_with_rotation(entity_extraction_chain, {"text_input": text_for_extraction})
        extracted_names = set(entity_result.names if entity_result else [])
        
        location_path = self.profile.game_state.location_path
        if not is_remote_scene:
            extracted_names.add(self.profile.user_profile.name)
            extracted_names.add(self.profile.ai_profile.name)
        extracted_names.update(location_path)
        
        logger.info(f"[{self.user_id}] (LORE Querier) æå–åˆ°ä»¥ä¸‹é—œéµå¯¦é«”: {list(extracted_names)}")

        all_lore_categories = ["npc_profile", "location_info", "item_info", "creature_info", "quest", "world_lore"]
        
        async def find_lore(name: str):
            tasks = [get_lores_by_category_and_filter(self.user_id, category, lambda c: name.lower() in c.get('name', '').lower() or name.lower() in c.get('title', '').lower()) for category in all_lore_categories]
            results_per_name = await asyncio.gather(*tasks, return_exceptions=True)
            return [lore for res in results_per_name if isinstance(res, list) for lore in res]

        query_tasks = [find_lore(name) for name in extracted_names if name]
        all_query_results = await asyncio.gather(*query_tasks, return_exceptions=True)
        
        final_lores = []
        unique_keys = set()
        for result_list in all_query_results:
            if isinstance(result_list, list):
                for lore in result_list:
                    if lore.key not in unique_keys:
                        unique_keys.add(lore.key)
                        final_lores.append(lore)
        
        logger.info(f"[{self.user_id}] (LORE Querier) æŸ¥è©¢åˆ° {len(final_lores)} æ¢å”¯ä¸€çš„LOREè¨˜éŒ„ã€‚")
        return final_lores
    # å‡½å¼ï¼š[æ–°] å¾å¯¦é«”æŸ¥è©¢LORE (ç”¨æ–¼ query_lore_node)

    # å‡½å¼ï¼š[æ–°] å¾LOREçµ„è£ä¸Šä¸‹æ–‡ (ç”¨æ–¼ assemble_context_node)
    def _assemble_context_from_lore(self, raw_lore_objects: List[Lore], is_remote_scene: bool = False) -> Dict[str, str]:
        """[æ–°] å°‡åŸå§‹LOREå°è±¡å’ŒéŠæˆ²ç‹€æ…‹æ ¼å¼åŒ–ç‚ºæœ€çµ‚çš„ä¸Šä¸‹æ–‡ç°¡å ±ã€‚"""
        if not self.profile: return {}
        
        gs = self.profile.game_state
        location_path = gs.location_path
        current_path_str = " > ".join(location_path)
        dossiers = []
        
        if not is_remote_scene:
            dossiers.append(f"--- æª”æ¡ˆ: {self.profile.user_profile.name} (ä½¿ç”¨è€…è§’è‰²) ---\n"
                            f"- æè¿°: {self.profile.user_profile.description}\n...")
            dossiers.append(f"--- æª”æ¡ˆ: {self.profile.ai_profile.name} (AI è§’è‰²) ---\n"
                            f"- æè¿°: {self.profile.ai_profile.description}\n...")
        
        for lore in raw_lore_objects:
            content = lore.content
            name = content.get('name') or content.get('title', 'æœªçŸ¥åç¨±')
            dossier_content = [f"--- æª”æ¡ˆ: {name} ({lore.category}) ---"]
            if 'description' in content: dossier_content.append(f"- æè¿°: {content['description']}")
            dossiers.append("\n".join(dossier_content))
            
        location_context = f"ç•¶å‰åœ°é»: {current_path_str}"
        inventory_context = f"åœ˜éšŠåº«å­˜: {', '.join(gs.inventory) or 'ç©ºçš„'}" if not is_remote_scene else "ï¼ˆé ç¨‹è§€å¯Ÿæ¨¡å¼ï¼‰"
        dossier_context = "\n".join(dossiers) if dossiers else "å ´æ™¯ä¸­ç„¡å·²çŸ¥çš„ç‰¹å®šæƒ…å ±ã€‚"

        final_context = {
            "location_context": location_context,
            "possessions_context": inventory_context,
            "quests_context": "ç•¶å‰ä»»å‹™: (å·²æ•´åˆé€²æƒ…å ±æª”æ¡ˆ)",
            "npc_context": dossier_context,
            "relevant_npc_context": ""
        }
        logger.info(f"[{self.user_id}] (Context Assembler) ä¸Šä¸‹æ–‡ç°¡å ±çµ„è£å®Œç•¢ã€‚")
        return final_context
    # å‡½å¼ï¼š[æ–°] å¾LOREçµ„è£ä¸Šä¸‹æ–‡ (ç”¨æ–¼ assemble_context_node)
    
    # ... (æ­¤è™•ä¿ç•™èˆŠçš„ _get_structured_context å’Œ _preprocess_rag_context ä½œç‚ºéæ¸¡)

    # ==============================================================================
    # == â›“ï¸ éˆçš„å»¶é²åŠ è¼‰ (Lazy Loading) æ§‹å»ºå™¨ v210.0 â›“ï¸
    # ==============================================================================
    
    # --- é è™•ç†èˆ‡åˆ†æéˆ ---
    
    # å‡½å¼ï¼šç²å–æ„åœ–åˆ†é¡éˆ
    def get_intent_classification_chain(self) -> Runnable:
        """ç²å–æˆ–å‰µå»ºä¸€å€‹å°ˆé–€ç”¨æ–¼èªæ„æ„åœ–åˆ†é¡çš„éˆã€‚"""
        if not hasattr(self, 'intent_classification_chain') or self.intent_classification_chain is None:
            classifier_llm = self._create_llm_instance(temperature=0.0).with_structured_output(IntentClassificationResult)
            prompt_template = """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å…§å®¹ç­–ç•¥èˆ‡æ„åœ–åˆ†æå°ˆå®¶...ï¼ˆçœç•¥ä»¥ä¿æŒç°¡æ½”ï¼‰...
---
ã€ä½¿ç”¨è€…è¼¸å…¥ã€‘:
{user_input}
---
è«‹é–‹å§‹åˆ†æä¸¦ç”Ÿæˆçµæ§‹åŒ–çš„ JSON è¼¸å‡ºã€‚"""
            prompt = ChatPromptTemplate.from_template(prompt_template)
            self.intent_classification_chain = prompt | classifier_llm
        return self.intent_classification_chain
    # å‡½å¼ï¼šç²å–æ„åœ–åˆ†é¡éˆ

    # å‡½å¼ï¼šç²å–é¢¨æ ¼åˆ†æéˆ
    def get_style_analysis_chain(self) -> Runnable:
        """ç²å–æˆ–å‰µå»ºä¸€å€‹å°ˆé–€ç”¨æ–¼åˆ†æé¢¨æ ¼æŒ‡ä»¤ä¸¦å°‡å…¶çµæ§‹åŒ–çš„éˆã€‚"""
        if not hasattr(self, 'style_analysis_chain') or self.style_analysis_chain is None:
            analysis_llm = self._create_llm_instance(temperature=0.0).with_structured_output(StyleAnalysisResult)
            prompt_template = """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ AI è¡Œç‚ºåˆ†æå¸«...ï¼ˆçœç•¥ä»¥ä¿æŒç°¡æ½”ï¼‰...
---
ã€AI å›è¦†é¢¨æ ¼æŒ‡ä»¤ã€‘:
{response_style_prompt}
---
è«‹é–‹å§‹åˆ†æä¸¦ç”Ÿæˆçµæ§‹åŒ–çš„ JSON è¼¸å‡ºã€‚"""
            prompt = ChatPromptTemplate.from_template(prompt_template)
            self.style_analysis_chain = prompt | analysis_llm
        return self.style_analysis_chain
    # å‡½å¼ï¼šç²å–é¢¨æ ¼åˆ†æéˆ
    
    # ... (æ­¤è™•ä¿ç•™å…¶ä»–åˆ†æéˆ: get_input_analysis_chain, get_expansion_decision_chain ç­‰)

    # --- è¦åŠƒéˆ (Planning Chains) ---

    # å‡½å¼ï¼šç²å– SFW å›åˆè¨ˆåŠƒéˆ
    def get_sfw_planning_chain(self) -> Runnable:
        """ç²å–æˆ–å‰µå»º SFW è·¯å¾‘çš„è¦åŠƒéˆï¼Œè¼¸å‡º TurnPlan JSONã€‚"""
        if not hasattr(self, 'sfw_planning_chain') or self.sfw_planning_chain is None:
            planner_llm = self._create_llm_instance(temperature=0.2).with_structured_output(TurnPlan)
            prompt = ChatPromptTemplate.from_messages([
                ("system", "# SFW ç³»çµ±æ ¸å¿ƒæŒ‡ä»¤...\n{system_prompt}"),
                ("human", "# ç•¶å‰æƒ…å¢ƒèˆ‡ä½¿ç”¨è€…æŒ‡ä»¤...\n{world_snapshot}\n{user_input}\nè«‹ç”Ÿæˆè¡Œå‹•è¨ˆåŠƒ JSONã€‚")
            ])
            self.sfw_planning_chain = prompt | planner_llm
        return self.sfw_planning_chain
    # å‡½å¼ï¼šç²å– SFW å›åˆè¨ˆåŠƒéˆ

    # å‡½å¼ï¼š[æ–°] ç²å– NSFW äº’å‹•è¨ˆåŠƒéˆ
    def get_nsfw_planning_chain(self) -> Runnable:
        """[æ–°] ç²å– NSFW äº’å‹•è·¯å¾‘çš„è¦åŠƒéˆï¼Œè¼¸å‡º TurnPlan JSONã€‚"""
        if not hasattr(self, 'nsfw_planning_chain') or self.nsfw_planning_chain is None:
            planner_llm = self._create_llm_instance(temperature=0.7).with_structured_output(TurnPlan)
            
            system_prompt = """# ==================================================
# == ğŸ§  ç³»çµ±æ ¸å¿ƒæŒ‡ä»¤ (NSFW äº’å‹•è¦åŠƒæ¨¡å¼) ğŸ§ 
# ==================================================
# ä½ çš„å”¯ä¸€ä»»å‹™æ˜¯åˆ†ææ‰€æœ‰ä¸Šä¸‹æ–‡ï¼Œç‚ºæ¥ä¸‹ä¾†çš„ã€éœ²éª¨äº’å‹•å›åˆã€‘åˆ¶å®šä¸€ä»½è©³ç´°ã€è‰²æƒ…ã€ç¬¦åˆé‚è¼¯çš„ã€è¡Œå‹•è¨ˆåŠƒ JSONã€‘ã€‚
# ä½ å¿…é ˆåš´æ ¼éµå¾ªæ‰€æœ‰æ ¸å¿ƒå”è­°ï¼Œç‰¹åˆ¥æ˜¯ã€action_sexual_content.txtã€‘æ¨¡çµ„ä¸­çš„æ‰€æœ‰è¦å‰‡ã€‚
{system_prompt}
"""
            human_prompt = """# ==================================================
# == ğŸ“– ç•¶å‰æƒ…å¢ƒèˆ‡ä½¿ç”¨è€…æŒ‡ä»¤ ğŸ“–
# ==================================================
# --- ä¸–ç•Œå¿«ç…§æ•¸æ“š ---
{world_snapshot}
# --- ä½¿ç”¨è€…æœ€æ–°æŒ‡ä»¤ ---
{user_input}
# --- ä½ çš„ä»»å‹™ ---
è«‹åš´æ ¼éµå¾ªä½ åœ¨ã€ç³»çµ±æ ¸å¿ƒæŒ‡ä»¤ã€‘ä¸­å­¸åˆ°çš„æ‰€æœ‰è¦å‰‡ï¼Œé–‹å§‹ä½ æ™ºæ…§ä¸”è‰²æƒ…çš„è¦åŠƒï¼Œç”Ÿæˆè¡Œå‹•è¨ˆåŠƒ JSONã€‚
"""
            prompt = ChatPromptTemplate.from_messages([
                ("system", system_prompt),
                ("human", human_prompt)
            ])
            self.nsfw_planning_chain = prompt | planner_llm
        return self.nsfw_planning_chain
    # å‡½å¼ï¼š[æ–°] ç²å– NSFW äº’å‹•è¨ˆåŠƒéˆ

    # å‡½å¼ï¼š[æ–°] ç²å–é æ™¯è¨ˆåŠƒéˆ
    def get_remote_planning_chain(self) -> Runnable:
        """[æ–°] ç²å–é æ™¯æè¿°è·¯å¾‘çš„è¦åŠƒéˆï¼Œè¼¸å‡º TurnPlan JSONã€‚"""
        if not hasattr(self, 'remote_planning_chain') or self.remote_planning_chain is None:
            planner_llm = self._create_llm_instance(temperature=0.7).with_structured_output(TurnPlan)
            
            system_prompt = """# ==================================================
# == ğŸ§  ç³»çµ±æ ¸å¿ƒæŒ‡ä»¤ (é æ™¯è¦åŠƒæ¨¡å¼) ğŸ§ 
# ==================================================
# ä½ çš„è§’è‰²æ˜¯ã€é›»å½±å°æ¼”ã€‘ã€‚ä½ çš„ä»»å‹™æ˜¯å°‡é¡é ­åˆ‡æ›åˆ°ä¸€å€‹é ç¨‹åœ°é»ï¼Œä¸¦æ§‹æ€ä¸€å¹•ç”Ÿå‹•çš„å ´æ™¯ã€‚
# ä½ çš„è¼¸å‡ºä¸æ˜¯å°èªªæœ¬èº«ï¼Œè€Œæ˜¯ä¸€ä»½çµ¦â€œå°èªªå®¶â€çœ‹çš„ã€çµæ§‹åŒ–çš„ã€å ´æ™¯è¡Œå‹•è¨ˆåŠƒ JSONã€‘ã€‚
# ã€æœ€é«˜ç¦ä»¤ã€‘ï¼šä½ çš„è¨ˆåŠƒä¸­ã€çµ•å°ç¦æ­¢ã€‘åŒ…å«ä½¿ç”¨è€…ã€Œ{username}ã€æˆ–å…¶AIå¤¥ä¼´ã€Œ{ai_name}ã€ã€‚
{system_prompt}
"""
            human_prompt = """# ==================================================
# == ğŸ¬ å°æ¼”æŒ‡ä»¤å¡ ğŸ¬
# ==================================================
# --- æ ¸å¿ƒä¸–ç•Œè§€ ---
{world_settings}
# --- é ç¨‹åœ°é»æƒ…å ±æ‘˜è¦ ---
{remote_scene_context}
# --- ä½¿ç”¨è€…çš„æè¿°æŒ‡ä»¤ ---
{user_input}
# --- ä½ çš„ä»»å‹™ ---
è«‹åš´æ ¼éµå¾ªæ‰€æœ‰è¦å‰‡ï¼Œæ§‹æ€ä¸€å¹•ç™¼ç”Ÿåœ¨é ç¨‹åœ°é»çš„å ´æ™¯ï¼Œä¸¦å°‡å…¶è½‰åŒ–ç‚ºä¸€ä»½è©³ç´°çš„ TurnPlan JSONã€‚
è¨ˆç•«ä¸­çš„ character_actions å¿…é ˆåŒ…å«ä½ ç‚ºæ­¤å ´æ™¯å‰µé€ çš„ã€æœ‰åæœ‰å§“ã€‘çš„NPCã€‚
"""
            prompt = ChatPromptTemplate.from_messages([
                ("system", system_prompt),
                ("human", human_prompt)
            ])
            self.remote_planning_chain = prompt | planner_llm
        return self.remote_planning_chain
    # å‡½å¼ï¼š[æ–°] ç²å–é æ™¯è¨ˆåŠƒéˆ
    
    # --- æ¸²æŸ“éˆ (Rendering Chain) ---

    # å‡½å¼ï¼šç²å–çµ±ä¸€æ•˜äº‹æ¸²æŸ“éˆ
    def get_narrative_chain(self) -> Runnable:
        """[å¼·åŒ–] å‰µå»ºä¸€å€‹çµ±ä¸€çš„â€œå°èªªå®¶â€éˆï¼Œè² è²¬å°‡ä»»ä½•çµæ§‹åŒ–çš„å›åˆè¨ˆåŠƒæ¸²æŸ“æˆç¬¦åˆä½¿ç”¨è€…é¢¨æ ¼çš„å°èªªæ–‡æœ¬ã€‚"""
        if not hasattr(self, 'narrative_chain') or self.narrative_chain is None:
            system_prompt_template = """ä½ æ˜¯ä¸€ä½æŠ€è—ç²¾æ¹›çš„å°èªªå®¶å’Œæ•˜äº‹è€…ã€‚
ä½ çš„å”¯ä¸€ä»»å‹™æ˜¯å°‡ä¸‹æ–¹æä¾›çš„ã€å›åˆè¡Œå‹•è¨ˆç•«ã€‘...ï¼ˆçœç•¥ä»¥ä¿æŒç°¡æ½”ï¼‰...
---
ã€ã€ã€æœ€çµ‚è¼¸å‡ºå¼·åˆ¶ä»¤ (ABSOLUTE & HIGHEST PRIORITY)ã€‘ã€‘ã€‘
{response_style_prompt}
---
"""
            human_prompt_template = """
---
ã€å›åˆè¡Œå‹•è¨ˆç•« (JSON)ã€‘:
{turn_plan_json}
---
ã€ç”Ÿæˆçš„å°èªªå ´æ™¯ã€‘:
"""
            prompt = ChatPromptTemplate.from_messages([
                ("system", system_prompt_template),
                ("human", human_prompt_template)
            ])
            self.narrative_chain = (
                {
                    "turn_plan_json": lambda x: x.get("turn_plan").model_dump_json(indent=2) if x.get("turn_plan") else "{}",
                    "response_style_prompt": lambda x: self.profile.response_style_prompt if self.profile else "é è¨­é¢¨æ ¼"
                }
                | prompt
                | self.gm_model
                | StrOutputParser()
            )
        return self.narrative_chain
    # å‡½å¼ï¼šç²å–çµ±ä¸€æ•˜äº‹æ¸²æŸ“éˆ

    # ... (æ­¤è™•ä¿ç•™æ‰€æœ‰å…¶ä»–å·¥å…·ã€è¼”åŠ©å‡½å¼å’Œéˆçš„å®šç¾©ï¼Œå®ƒå€‘ä¸å—æ­¤æ¬¡é‡æ§‹å½±éŸ¿)

    # å‡½å¼ï¼šå¸¶é‡‘é‘°è¼ªæ›èˆ‡å§”å©‰åŒ–é‡è©¦çš„éåŒæ­¥å‘¼å«
    async def ainvoke_with_rotation(self, chain: Runnable, params: Any, retry_strategy: Literal['euphemize', 'force', 'none'] = 'euphemize') -> Any:
        if not self.api_keys:
            raise ValueError("No API keys available.")
        max_retries = len(self.api_keys)
        base_delay = 5
        
        for attempt in range(max_retries):
            try:
                result = await chain.ainvoke(params)
                is_empty_or_invalid = not result or (hasattr(result, 'content') and not getattr(result, 'content', True))
                if is_empty_or_invalid:
                    raise Exception("SafetyError: The model returned an empty or invalid response.")
                return result
            except (ResourceExhausted, InternalServerError, ServiceUnavailable, DeadlineExceeded) as e:
                delay = base_delay * (attempt + 1)
                logger.warning(f"[{self.user_id}] API é­é‡è³‡æºæˆ–ä¼ºæœå™¨éŒ¯èª¤: {type(e).__name__}. å°‡åœ¨ {delay:.1f} ç§’å¾Œä½¿ç”¨ä¸‹ä¸€å€‹é‡‘é‘°é‡è©¦...")
                await asyncio.sleep(delay)
                self._initialize_models()
            except Exception as e:
                error_str = str(e).lower()
                is_safety_error = "safety" in error_str or "blocked" in error_str or "empty or invalid response" in error_str
                if is_safety_error:
                    if retry_strategy == 'euphemize':
                        return await self._euphemize_and_retry(chain, params)
                    elif retry_strategy == 'force':
                        return await self._force_and_retry(chain, params)
                    else:
                        logger.warning(f"[{self.user_id}] éˆé­é‡å…§å®¹å¯©æŸ¥ï¼Œä¸”é‡è©¦ç­–ç•¥ç‚º 'none'ã€‚è¿”å› Noneã€‚")
                        return None
                logger.error(f"[{self.user_id}] åœ¨ ainvoke æœŸé–“ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}", exc_info=True)
                raise e

        logger.error(f"[{self.user_id}] æ‰€æœ‰ API é‡‘é‘°å‡å˜—è©¦å¤±æ•—ã€‚")
        if retry_strategy == 'euphemize':
            return await self._euphemize_and_retry(chain, params)
        elif retry_strategy == 'force':
            return await self._force_and_retry(chain, params)
        return None
    # å‡½å¼ï¼šå¸¶é‡‘é‘°è¼ªæ›èˆ‡å§”å©‰åŒ–é‡è©¦çš„éåŒæ­¥å‘¼å«

# é¡åˆ¥çµæŸ
