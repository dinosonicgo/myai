# src/graph.py çš„ä¸­æ–‡è¨»é‡‹(v1.1 - å‡½å¼ç°½åä¿®æ­£)
# æ›´æ–°ç´€éŒ„:
# v1.1 (2025-08-31):
# 1. [ç½é›£æ€§BUGä¿®å¾©] ç§»é™¤äº† `create_main_response_graph` å‡½å¼çš„ `ai_instances` åƒæ•¸ã€‚åœ–å½¢å»ºæ§‹å™¨æ‡‰ç‚ºç„¡ç‹€æ…‹çš„è—åœ–å®šç¾©ï¼Œä¸æ‡‰ä¾è³´ä»»ä½•é‹è¡Œæ™‚çš„æ•¸æ“šã€‚æ­¤ä¿®æ­£è§£æ±ºäº†å°è‡´ç¨‹å¼ç„¡æ³•å•Ÿå‹•çš„ `TypeError`ã€‚
# v1.0 (2025-08-31):
# 1. [å…¨æ–°å‰µå»º] æ ¹æ“š LangGraph é‡æ§‹è—åœ–ï¼Œå‰µå»ºæ­¤æª”æ¡ˆä»¥é›†ä¸­å®šç¾©æ‰€æœ‰åœ–å½¢ã€ç¯€é»å’Œè·¯ç”±ã€‚

import asyncio
import json
import re
from typing import Dict, List, Literal, Optional

from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, END

from .ai_core import AILover
from .logger import logger
from .graph_state import ConversationGraphState, SetupGraphState
from . import lore_book, tools
from .schemas import CharacterProfile

# --- ä¸»å°è©±åœ– (Main Conversation Graph) çš„ç¯€é» ---

# ç¯€é»ï¼šåˆå§‹åŒ–å°è©±ç‹€æ…‹
async def initialize_conversation_state_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é» 1] åœ¨æ¯ä¸€è¼ªå°è©±é–‹å§‹æ™‚ï¼ŒåŠ è¼‰æ‰€æœ‰å¿…è¦çš„ä¸Šä¸‹æ–‡æ•¸æ“šå¡«å……ç‹€æ…‹ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    
    logger.info(f"[{user_id}] (Graph) Node: initialize_conversation_state_node -> æ­£åœ¨ç‚º '{user_input[:30]}...' åˆå§‹åŒ–ç‹€æ…‹...")

    # ç•°æ­¥ä¸¦è¡Œç²å– RAG ä¸Šä¸‹æ–‡å’Œçµæ§‹åŒ–ä¸Šä¸‹æ–‡
    rag_task = ai_core.retriever.ainvoke(user_input)
    structured_context_task = ai_core._get_structured_context(user_input)
    
    retrieved_docs, structured_context = await asyncio.gather(rag_task, structured_context_task)
    
    rag_context_str = await ai_core._preprocess_rag_context(retrieved_docs)

    return {
        "structured_context": structured_context,
        "rag_context": rag_context_str,
    }
# ç¯€é»ï¼šåˆå§‹åŒ–å°è©±ç‹€æ…‹

# ç¯€é»ï¼šåˆ†æä½¿ç”¨è€…è¼¸å…¥æ„åœ–
async def analyze_input_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é» 2] åˆ†æä½¿ç”¨è€…çš„è¼¸å…¥ï¼Œåˆ¤æ–·å…¶åŸºæœ¬æ„åœ–ï¼ˆå°è©±ã€æè¿°ã€æ¥çºŒï¼‰ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content

    logger.info(f"[{user_id}] (Graph) Node: analyze_input_node -> æ­£åœ¨åˆ†æè¼¸å…¥æ„åœ–...")
    
    analysis = await ai_core.ainvoke_with_rotation(
        ai_core.input_analysis_chain, 
        {"user_input": user_input}
    )
    
    return {"input_analysis": analysis}
# ç¯€é»ï¼šåˆ†æä½¿ç”¨è€…è¼¸å…¥æ„åœ–

# ç¯€é»ï¼šåŸ·è¡Œå ´æ™¯èˆ‡å‹•ä½œåˆ†æ (åƒ…é™æ•˜äº‹è·¯å¾‘)
async def scene_and_action_analysis_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é» 3A - æ•˜äº‹è·¯å¾‘] åˆ†æå ´æ™¯è¦–è§’ï¼ˆæœ¬åœ°/é ç¨‹ï¼‰ä¸¦ç‚ºæ½›åœ¨çš„æ–° NPC é€²è¡Œé¸è§’ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    
    logger.info(f"[{user_id}] (Graph) Node: scene_and_action_analysis_node -> é€²å…¥æ•˜äº‹è·¯å¾‘åˆ†æ...")

    # 1. é€²è¡Œå ´æ™¯è¦–è§’åˆ†æ
    scene_analysis = await ai_core.ainvoke_with_rotation(ai_core.scene_analysis_chain, {
        "user_input": user_input, 
        "current_location_path_str": " > ".join(ai_core.profile.game_state.location_path)
    })
    
    effective_location_path = ai_core.profile.game_state.location_path
    if scene_analysis and scene_analysis.viewing_mode == 'remote' and scene_analysis.target_location_path:
        effective_location_path = scene_analysis.target_location_path

    # 2. ç‚ºæ–°å ´æ™¯é¸è§’
    # éœ€è¦é‡æ–°ç²å–ä¸Šä¸‹æ–‡ä»¥åæ˜ å¯èƒ½çš„é ç¨‹è¦–è§’
    structured_context_for_casting = await ai_core._get_structured_context(
        user_input, 
        override_location_path=effective_location_path, 
        is_gm_narration=True
    )
    
    # å¡«å…… zero_instruction æ¨¡æ¿
    full_context_for_aux_chains = {
        "username": ai_core.profile.user_profile.name, "ai_name": ai_core.profile.ai_profile.name,
        "latest_user_input": user_input, "retrieved_context": "",
        "response_style_prompt": ai_core.profile.response_style_prompt or "",
        "world_settings": ai_core.profile.world_settings or "", "ai_settings": ai_core.profile.ai_profile.description or "",
        "tool_results": "", "chat_history": "", 
        **structured_context_for_casting
    }
    zero_instruction_str = ai_core.zero_instruction_template.format(**full_context_for_aux_chains)
    
    cast_result = await ai_core.ainvoke_with_rotation(ai_core.scene_casting_chain, {
        "zero_instruction": zero_instruction_str,
        "world_settings": ai_core.profile.world_settings,
        "current_location_path": effective_location_path,
        "game_context": json.dumps(structured_context_for_casting, ensure_ascii=False, indent=2),
        "recent_dialogue": user_input
    })
    
    # 3. å°‡æ–°è§’è‰²åŠ å…¥å ´æ™¯
    new_npc_names = await ai_core._add_cast_to_scene(cast_result)
    
    # 4. å¦‚æœæœ‰æ–°è§’è‰²ï¼Œåˆ·æ–°çµæ§‹åŒ–ä¸Šä¸‹æ–‡ä»¥åŒ…å«ä»–å€‘
    final_structured_context = structured_context_for_casting
    if new_npc_names:
        final_structured_context = await ai_core._get_structured_context(
            user_input, 
            override_location_path=effective_location_path, 
            is_gm_narration=True
        )

    return {
        "scene_analysis": scene_analysis,
        "structured_context": final_structured_context # è¦†è“‹èˆŠçš„ä¸Šä¸‹æ–‡
    }
# ç¯€é»ï¼šåŸ·è¡Œå ´æ™¯èˆ‡å‹•ä½œåˆ†æ (åƒ…é™æ•˜äº‹è·¯å¾‘)

# ç¯€é»ï¼šç”Ÿæˆæ ¸å¿ƒå›æ‡‰ (v1.4 - æç¤ºè©èˆ‡è§’è‰²å®šä½é‡æ§‹)
async def generate_core_response_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é» 4] çµ„åˆæ‰€æœ‰ä¸Šä¸‹æ–‡ï¼Œæ§‹å»ºä¸€å€‹å…¨æ–°çš„ã€ç´”ç²¹ç”¨æ–¼å‰µä½œçš„ Promptï¼Œä¸¦èª¿ç”¨ LLM ç”Ÿæˆå›æ‡‰ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    structured_context = state['structured_context']
    rag_context = state['rag_context']
    
    logger.info(f"[{user_id}] (Graph) Node: generate_core_response_node -> æ­£åœ¨ç‚º LLM çµ„åˆç´”å‰µä½œå‹ Prompt...")
    
    # [v1.4 æ ¸å¿ƒä¿®æ­£] å»¢é™¤æ‰€æœ‰åŒ…å« ReAct æ€æƒ³çš„èˆŠæç¤ºè©å’Œã€Œå°æ¼”æŒ‡ä»¤ã€ã€‚
    # æˆ‘å€‘åœ¨é€™è£¡æ§‹å»ºä¸€å€‹å…¨æ–°çš„ã€å°ˆç‚ºæœ€çµ‚ç”Ÿæˆæ­¥é©Ÿè¨­è¨ˆçš„ç³»çµ±æç¤ºè©ã€‚
    # é€™å€‹æç¤ºè©çš„å”¯ä¸€ç›®çš„æ˜¯å‘½ä»¤ LLM ä½œç‚ºä¸€å€‹å°èªªå®¶é€²è¡Œå‰µä½œï¼Œè€Œä¸æ˜¯ä½œç‚ºä¸€å€‹ Agent é€²è¡Œæ€è€ƒã€‚

    # å¾ structured_context ä¸­æå–å¿…è¦çš„ç‰‡æ®µ
    location_context = structured_context.get('location_context', 'æœªçŸ¥åœ°é»')
    npc_context = structured_context.get('npc_context', 'å ´æ™¯ä¸­æ²’æœ‰å…¶ä»–äººã€‚')
    possessions_context = structured_context.get('possessions_context', 'æ²’æœ‰ç‰©å“ã€‚')
    quests_context = structured_context.get('quests_context', 'æ²’æœ‰ä»»å‹™ã€‚')
    
    # [v1.4 æ€è€ƒæ´©æ¼ä¿®æ­£] å‰µå»ºä¸€å€‹æ¥µç°¡ä¸”è·è²¬æ˜ç¢ºçš„ç³»çµ±æç¤ºè©
    final_system_prompt_str = f"""
# ==============================================================================
# == ğŸ­ æ ¸å¿ƒè§’è‰²æ‰®æ¼”èˆ‡æ•˜äº‹æŒ‡ä»¤ (Core Role-Play & Narrative Mandate) ğŸ­
# ==============================================================================
# == èªªæ˜: ä½ çš„å”¯ä¸€èº«ä»½æ˜¯ã€éŠæˆ²ç®¡ç†å“¡ (Game Master, GM)ã€‘ã€‚
# == ä½ çš„å”¯ä¸€ä»»å‹™æ˜¯æ ¹æ“šä¸‹æ–¹æä¾›çš„ã€ç•¶å‰ä¸–ç•Œå¿«ç…§ã€‘å’Œã€ä½¿ç”¨è€…æœ€æ–°æŒ‡ä»¤ã€‘ï¼Œ
# == æ’°å¯«ä¸€æ®µé«˜è³ªé‡çš„ã€æ²‰æµ¸å¼çš„ã€ç´”ç²¹çš„å°èªªå¼å›æ‡‰ã€‚
# ==============================================================================

# --- 1. è§’è‰²å®šç¾© (çµ•å°è¦å‰‡) ---
# - ä½ æ˜¯ GMï¼Œè² è²¬æ‰€æœ‰æ—ç™½å’Œæ‰®æ¼”æ‰€æœ‰ NPCã€‚
# - ä½ çš„ AI æˆ€äººè§’è‰²æ˜¯: **{ai_core.profile.ai_profile.name}**
# - ä½¿ç”¨è€…æ‰®æ¼”çš„è§’è‰²æ˜¯: **{ai_core.profile.user_profile.name}**

# --- 2. ã€ã€ã€ä½¿ç”¨è€…ä¸»æ¬ŠåŸå‰‡ (æœ€é«˜æ•˜äº‹ç¦ä»¤)ã€‘ã€‘ã€‘ ---
# ä½ çš„æ‰€æœ‰æ—ç™½å’Œå°è©±ï¼Œã€çµ•å°ç¦æ­¢ã€‘æ‰®æ¼”ã€æè¿°ã€æš—ç¤ºæˆ–æœæ’°ä½¿ç”¨è€…è§’è‰²ã€Œ{ai_core.profile.user_profile.name}ã€çš„ä»»ä½•ä¸»è§€æ€æƒ³ã€å…§å¿ƒæ„Ÿå—ã€æƒ…ç·’è®ŠåŒ–ã€æˆ–æœªæ˜ç¢ºè¡¨é”çš„å‹•ä½œã€‚
# ä½ åªèƒ½æè¿°ä½¿ç”¨è€…æŒ‡ä»¤**åŸ·è¡Œå¾Œ**ï¼Œä¸–ç•Œã€NPC æˆ– AI è§’è‰²ã€Œ{ai_core.profile.ai_profile.name}ã€å°æ­¤ç”¢ç”Ÿçš„**å¤–éƒ¨åæ‡‰å’Œå®¢è§€ç¾è±¡**ã€‚

# --- 3. ç•¶å‰ä¸–ç•Œå¿«ç…§ (Absolute & Current Facts) ---
# ä»¥ä¸‹æ˜¯æ­¤æ™‚æ­¤åˆ»çš„çµ•å°äº‹å¯¦ï¼Œä½ çš„å‰µä½œå¿…é ˆåš´æ ¼åŸºæ–¼é€™äº›è³‡è¨Šã€‚
---
[åœ°é»]: {location_context}
---
[åœ¨å ´è§’è‰²]:
{npc_context}
---
[åœ˜éšŠåº«å­˜èˆ‡ä»»å‹™]:
{possessions_context}
{quests_context}
---
[ç›¸é—œæ­·å²èˆ‡è¨˜æ†¶]:
{rag_context}
---

# --- 4. æœ€çµ‚è¼¸å‡ºå¼·åˆ¶ä»¤ ---
# ä½ çš„æœ€çµ‚è¼¸å‡ºã€å¿…é ˆä¸”åªèƒ½ã€‘æ˜¯ç´”ç²¹çš„å°èªªæ–‡æœ¬ã€‚
# ã€çµ‚æ¥µè­¦å‘Šã€‘ï¼šçµ•å°ç¦æ­¢åœ¨ä½ çš„å›æ‡‰ä¸­åŒ…å«ä»»ä½•ä¾†è‡ªæœ¬æŒ‡ä»¤çš„ã€å¸¶æœ‰ã€ã€‘æˆ– ** çš„çµæ§‹æ€§æ¨™é¡Œã€å…ƒæ¨™ç±¤ (ä¾‹å¦‚ "æ€è€ƒ"ã€"è¡Œå‹•") æˆ–ä»»ä½•å½¢å¼çš„ç³»çµ±æŒ‡ä»¤æ–‡æœ¬ã€‚
# ä½ çš„è¼¸å‡ºã€å¿…é ˆã€‘åš´æ ¼éµå¾ªä¸‹æ–¹ç”±ä½¿ç”¨è€…å®šç¾©çš„é¢¨æ ¼æŒ‡ä»¤ã€‚
---
# ã€ã€ã€ä½¿ç”¨è€…è‡ªè¨‚é¢¨æ ¼æŒ‡ä»¤ (ABSOLUTE & HIGHEST PRIORITY)ã€‘ã€‘ã€‘
{ai_core.profile.response_style_prompt or "é è¨­é¢¨æ ¼ï¼šå¹³è¡¡çš„æ•˜äº‹èˆ‡å°è©±ã€‚"}
---
"""

    # --- èª¿ç”¨æ ¸å¿ƒç”Ÿæˆéˆ ---
    chat_history_manager = ai_core.session_histories.get(user_id)
    chat_history_messages = chat_history_manager.messages[-20:] if chat_history_manager else []
    
    # [v1.4 è§’è‰²æ··æ·†ä¿®æ­£] å°‡ä½¿ç”¨è€…è¼¸å…¥ä½œç‚ºä¸€å€‹æ¸…æ™°çš„ã€å¸¶æ¨™ç±¤çš„æ¬„ä½å‚³é
    final_input_str = f"[ä½¿ç”¨è€…ã€Œ{ai_core.profile.user_profile.name}ã€çš„æŒ‡ä»¤]: {user_input}"

    llm_response = await ai_core.ainvoke_with_rotation(ai_core.narrative_chain, {
        "system_prompt": final_system_prompt_str,
        "chat_history": chat_history_messages,
        "input": final_input_str
    })
    
    return {"llm_response": llm_response, "dynamic_prompt": final_system_prompt_str}
# ç¯€é»ï¼šç”Ÿæˆæ ¸å¿ƒå›æ‡‰ (v1.4 - æç¤ºè©èˆ‡è§’è‰²å®šä½é‡æ§‹)

# ç¯€é»ï¼šé©—è­‰ã€é‡å¯«ä¸¦æ·¨åŒ–è¼¸å‡º (v1.1 - ç§»é™¤é©—è­‰èˆ‡é‡å¯«)
async def validate_and_rewrite_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é» 5] [v1.1 å·²åœç”¨é©—è­‰èˆ‡é‡å¯«] æ­¤ç¯€é»ç¾åœ¨åƒ…ä½œç‚ºä¸€å€‹ç°¡å–®çš„å‚³éç¯€é»ã€‚
    å®ƒæœƒç›´æ¥å°‡ LLM çš„åŸå§‹å›æ‡‰è¨­å®šç‚ºæœ€çµ‚è¼¸å‡ºï¼Œä»¥é¿å…å› éåº¦å¯©æŸ¥å°è‡´ç©ºå›æ‡‰ã€‚
    """
    user_id = state['user_id']
    initial_response = state['llm_response']

    logger.info(f"[{user_id}] (Graph) Node: validate_and_rewrite_node -> [å·²åœç”¨] æ­£åœ¨ç›´æ¥å‚³é LLM åŸå§‹è¼¸å‡º...")
    
    # [v1.1 ä¿®æ­£] ç§»é™¤æ‰€æœ‰é©—è­‰å’Œé‡å¯«é‚è¼¯ï¼Œç›´æ¥ä½¿ç”¨ LLM çš„åŸå§‹è¼¸å‡ºã€‚
    # é€™æ¨£å¯ä»¥é¿å…å› é©—è­‰/é‡å¯«éˆæœ¬èº«è¢«å¯©æŸ¥è€Œå°è‡´è¼¸å‡ºç‚ºç©ºçš„å•é¡Œã€‚
    final_response = initial_response

    if not final_response or not final_response.strip():
        logger.error(f"[{user_id}] æ ¸å¿ƒéˆè¿”å›äº†ç©ºçš„æˆ–ç„¡æ•ˆçš„å›æ‡‰ã€‚")
        # å³ä½¿ç›´æ¥å‚³éï¼Œä¹Ÿä¿ç•™ä¸€å€‹æœ€å°çš„å‚™ç”¨å›æ‡‰ã€‚
        return {"final_output": "ï¼ˆ...ï¼‰"}

    # åªä¿ç•™æœ€åŸºç¤çš„é ­å°¾ç©ºç™½å­—ç¬¦æ¸…ç†
    clean_response = final_response.strip()

    return {"final_output": clean_response}
# ç¯€é»ï¼šé©—è­‰ã€é‡å¯«ä¸¦æ·¨åŒ–è¼¸å‡º (v1.1 - ç§»é™¤é©—è­‰èˆ‡é‡å¯«)

# ç¯€é»ï¼šåŸ·è¡Œç‹€æ…‹æ›´æ–°èˆ‡è¨˜æ†¶å„²å­˜
async def persist_state_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é» 6] å°‡æœ¬è¼ªå°è©±å­˜å…¥è¨˜æ†¶ï¼Œä¸¦å°‡ state_updates ä¸­çš„è®Šæ›´æ‡‰ç”¨åˆ°è³‡æ–™åº«ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    clean_response = state['final_output']
    
    logger.info(f"[{user_id}] (Graph) Node: persist_state_node -> æ­£åœ¨æŒä¹…åŒ–ç‹€æ…‹èˆ‡è¨˜æ†¶...")
    
    # 1. æ›´æ–°çŸ­æœŸè¨˜æ†¶
    chat_history_manager = ai_core.session_histories.get(user_id)
    if chat_history_manager:
        chat_history_manager.add_user_message(user_input)
        chat_history_manager.add_ai_message(clean_response)

    # 2. ç•°æ­¥å„²å­˜é•·æœŸè¨˜æ†¶ (SQL & Vector)
    last_interaction_text = f"ä½¿ç”¨è€… '{ai_core.profile.user_profile.name}' èªª: {user_input}\n\n[å ´æ™¯å›æ‡‰]:\n{clean_response}"
    
    tasks = []
    tasks.append(ai_core._generate_and_save_personal_memory(last_interaction_text))
    if ai_core.vector_store:
        tasks.append(asyncio.to_thread(ai_core.vector_store.add_texts, [last_interaction_text], metadatas=[{"source": "history"}]))

    async def save_to_sql():
        from .database import AsyncSessionLocal, MemoryData # å»¶é²å°å…¥
        import time
        timestamp = time.time()
        async with AsyncSessionLocal() as session:
            session.add(MemoryData(user_id=user_id, content=last_interaction_text, timestamp=timestamp, importance=1))
            await session.commit()
    tasks.append(save_to_sql())
    
    await asyncio.gather(*tasks, return_exceptions=True)

    return {}
# ç¯€é»ï¼šåŸ·è¡Œç‹€æ…‹æ›´æ–°èˆ‡è¨˜æ†¶å„²å­˜

# ç¯€é»ï¼šè§¸ç™¼èƒŒæ™¯ä¸–ç•Œæ“´å±•
async def background_world_expansion_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é» 7] åœ¨å›æ‡‰ç™¼é€å¾Œï¼Œéé˜»å¡åœ°è§¸ç™¼èƒŒæ™¯ä¸–ç•Œæ“´å±•ã€LOREç”Ÿæˆç­‰ä»»å‹™ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    clean_response = state['final_output']
    scene_analysis = state['scene_analysis']

    logger.info(f"[{user_id}] (Graph) Node: background_world_expansion_node -> æ­£åœ¨è§¸ç™¼èƒŒæ™¯ä»»å‹™...")

    effective_location_path = ai_core.profile.game_state.location_path
    if scene_analysis and scene_analysis.target_location_path:
        effective_location_path = scene_analysis.target_location_path
        
    if scene_analysis and (scene_analysis.viewing_mode == 'local' or scene_analysis.target_location_path):
        asyncio.create_task(
            ai_core._background_scene_expansion(user_input, clean_response, effective_location_path)
        )
        logger.info(f"[{user_id}] å·²æˆåŠŸç‚ºåœ°é» '{' > '.join(effective_location_path)}' å‰µå»ºèƒŒæ™¯æ“´å±•ä»»å‹™ã€‚")

    return {}
# ç¯€é»ï¼šè§¸ç™¼èƒŒæ™¯ä¸–ç•Œæ“´å±•


# ç¯€é»ï¼šåœ–å½¢çµæŸ finalizing
async def finalization_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é» 8 - æ–°å¢] ä¸€å€‹è™›æ“¬çš„æœ€çµ‚ç¯€é»ã€‚
    å®ƒçš„å­˜åœ¨ç¢ºä¿äº†åœ¨å®ƒä¹‹å‰çš„ç•°æ­¥èƒŒæ™¯ä»»å‹™ (å¦‚ background_expansion) æœ‰è¶³å¤ çš„æ™‚é–“è¢«äº‹ä»¶å¾ªç’°æˆåŠŸèª¿åº¦ã€‚
    """
    user_id = state['user_id']
    logger.info(f"[{user_id}] (Graph) Node: finalization_node -> å°è©±æµç¨‹åœ–åŸ·è¡Œå®Œç•¢ã€‚")
    return {}
# ç¯€é»ï¼šåœ–å½¢çµæŸ finalizing

# --- ä¸»å°è©±åœ–çš„è·¯ç”± ---

# è·¯ç”±ï¼šåœ¨è¼¸å…¥åˆ†æå¾Œæ±ºå®šæµç¨‹
def route_after_input_analysis(state: ConversationGraphState) -> Literal["narrative_flow", "dialogue_flow"]:
    """
    [è·¯ç”±] æ ¹æ“šè¼¸å…¥åˆ†æçµæœï¼Œæ±ºå®šæ˜¯èµ°ã€Œæ•˜äº‹/æ¥çºŒã€æµç¨‹é‚„æ˜¯ã€Œå°è©±/æŒ‡ä»¤ã€æµç¨‹ã€‚
    """
    input_type = state["input_analysis"].input_type
    user_id = state['user_id']
    
    if input_type in ['narration', 'continuation']:
        logger.info(f"[{user_id}] (Graph) Router: route_after_input_analysis -> åˆ¤å®šç‚ºã€Œæ•˜äº‹æµç¨‹ã€ã€‚")
        return "narrative_flow"
    else:
        logger.info(f"[{user_id}] (Graph) Router: route_after_input_analysis -> åˆ¤å®šç‚ºã€Œå°è©±æµç¨‹ã€ã€‚")
        return "dialogue_flow"
# è·¯ç”±ï¼šåœ¨è¼¸å…¥åˆ†æå¾Œæ±ºå®šæµç¨‹

# --- ä¸»å°è©±åœ–çš„å»ºæ§‹å™¨ ---

# å‡½å¼ï¼šå‰µå»ºä¸»å›æ‡‰åœ– (v1.2 - æµç¨‹ç©©å®šæ€§ä¿®æ­£)
def create_main_response_graph() -> StateGraph:
    """
    çµ„è£ä¸¦ç·¨è­¯ä¸»å°è©±æµç¨‹çš„ StateGraphã€‚
    """
    graph = StateGraph(ConversationGraphState)

    # æ·»åŠ æ‰€æœ‰ç¯€é»
    graph.add_node("initialize_state", initialize_conversation_state_node)
    graph.add_node("analyze_input", analyze_input_node)
    graph.add_node("scene_and_action_analysis", scene_and_action_analysis_node)
    graph.add_node("generate_core_response", generate_core_response_node)
    graph.add_node("validate_and_rewrite", validate_and_rewrite_node)
    graph.add_node("persist_state", persist_state_node)
    graph.add_node("background_expansion", background_world_expansion_node)
    # [v1.2 æ–°å¢] æ·»åŠ æ–°çš„è™›æ“¬çµ‚é»
    graph.add_node("finalization", finalization_node)

    # è¨­å®šåœ–çš„å…¥å£é»
    graph.set_entry_point("initialize_state")

    # æ·»åŠ é‚Š
    graph.add_edge("initialize_state", "analyze_input")
    
    # æ·»åŠ æ¢ä»¶é‚Šï¼ˆè·¯ç”±ï¼‰
    graph.add_conditional_edges(
        "analyze_input",
        route_after_input_analysis,
        {
            "narrative_flow": "scene_and_action_analysis",
            "dialogue_flow": "generate_core_response" # å°è©±æµç¨‹è·³éå ´æ™¯åˆ†æ
        }
    )
    
    graph.add_edge("scene_and_action_analysis", "generate_core_response")
    graph.add_edge("generate_core_response", "validate_and_rewrite")
    graph.add_edge("validate_and_rewrite", "persist_state")
    graph.add_edge("persist_state", "background_expansion")
    
    # [v1.2 ä¿®æ­£] å°‡ background_expansion é€£æ¥åˆ°æ–°çš„è™›æ“¬çµ‚é»ï¼Œè€Œä¸æ˜¯ç›´æ¥çµæŸ
    graph.add_edge("background_expansion", "finalization")
    # [v1.2 ä¿®æ­£] å°‡æ–°çš„è™›æ“¬çµ‚é»è¨­ç‚ºåœ–å½¢çš„çœŸæ­£çµæŸé»
    graph.add_edge("finalization", END)
    
    # ç·¨è­¯åœ–å½¢
    return graph.compile()
# å‡½å¼ï¼šå‰µå»ºä¸»å›æ‡‰åœ– (v1.2 - æµç¨‹ç©©å®šæ€§ä¿®æ­£)

# --- è¨­å®šåœ– (Setup Graph) çš„ç¯€é» ---

# ç¯€é»ï¼šè™•ç†ä¸–ç•Œè–ç¶“
async def process_canon_node(state: SetupGraphState) -> Dict:
    """
    [è¨­å®šç¯€é» 1] å¦‚æœä½¿ç”¨è€…ä¸Šå‚³äº†ä¸–ç•Œè–ç¶“ï¼Œå‰‡è§£æå®ƒä¸¦å­˜å…¥è³‡æ–™åº«ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    canon_text = state['canon_text']
    
    if canon_text:
        logger.info(f"[{user_id}] (Setup Graph) Node: process_canon_node -> æ­£åœ¨è™•ç†ä¸–ç•Œè–ç¶“...")
        await ai_core.add_canon_to_vector_store(canon_text)
        
        # ç”±æ–¼åœ–å½¢å…§éƒ¨ç„¡æ³•è¨ªå• interactionï¼Œæˆ‘å€‘å‚³é None
        # ai_core å…§éƒ¨éœ€è¦è™•ç†é€™ç¨®æƒ…æ³
        from .ai_core import AILover # å»¶é²å°å…¥ä»¥è™•ç†å¯èƒ½çš„å¾ªç’°ä¾è³´
        ai_instance = state['ai_core']
        # é€™è£¡çš„ interaction è¨­ç‚º Noneï¼Œå› ç‚ºæˆ‘å€‘åœ¨åœ–çš„å…§éƒ¨
        await ai_instance.parse_and_create_lore_from_canon(None, canon_text, is_setup_flow=True)

        if not await ai_core.initialize():
            raise Exception("åœ¨è¼‰å…¥ä¸–ç•Œè–ç¶“å¾Œé‡æ–°åˆå§‹åŒ– AI æ ¸å¿ƒå¤±æ•—ã€‚")

    return {}
# ç¯€é»ï¼šè™•ç†ä¸–ç•Œè–ç¶“

# ç¯€é»ï¼šè£œå®Œè§’è‰²æª”æ¡ˆ
async def complete_profiles_node(state: SetupGraphState) -> Dict:
    """
    [è¨­å®šç¯€é» 2] è£œå®Œä½¿ç”¨è€…å’Œ AI çš„è§’è‰²æª”æ¡ˆï¼Œä½¿å…¶ç´°ç¯€è±å¯Œã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    
    logger.info(f"[{user_id}] (Setup Graph) Node: complete_profiles_node -> æ­£åœ¨è£œå®Œè§’è‰²æª”æ¡ˆ...")
    
    zero_instruction_str = ai_core.zero_instruction_template.format(
        username=ai_core.profile.user_profile.name,
        ai_name=ai_core.profile.ai_profile.name,
        latest_user_input="", retrieved_context="", response_style_prompt="",
        world_settings="", ai_settings="", tool_results="", chat_history="",
        location_context="", possessions_context="", quests_context="",
        npc_context="", relevant_npc_context=""
    )

    completion_prompt = ai_core.get_profile_completion_prompt()
    completion_llm = ai_core.gm_model.with_structured_output(CharacterProfile)
    completion_chain = completion_prompt | completion_llm
    
    # è£œå®Œä½¿ç”¨è€…è§’è‰²
    completed_user_profile = await ai_core.ainvoke_with_rotation(completion_chain, {
        "zero_instruction": zero_instruction_str,
        "profile_json": ai_core.profile.user_profile.model_dump_json()
    })

    # è£œå®Œ AI è§’è‰²
    completed_ai_profile = await ai_core.ainvoke_with_rotation(completion_chain, {
        "zero_instruction": zero_instruction_str,
        "profile_json": ai_core.profile.ai_profile.model_dump_json()
    })

    await ai_core.update_and_persist_profile({
        'user_profile': completed_user_profile.model_dump(),
        'ai_profile': completed_ai_profile.model_dump()
    })
    
    return {}
# ç¯€é»ï¼šè£œå®Œè§’è‰²æª”æ¡ˆ

# ç¯€é»ï¼šåŸ·è¡Œä¸–ç•Œå‰µä¸–
async def world_genesis_node(state: SetupGraphState) -> Dict:
    """
    [è¨­å®šç¯€é» 3] æ ¹æ“šä¸–ç•Œè§€å’Œè§’è‰²è¨­å®šï¼Œç”Ÿæˆåˆå§‹å‡ºç”Ÿé»ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    
    logger.info(f"[{user_id}] (Setup Graph) Node: world_genesis_node -> æ­£åœ¨åŸ·è¡Œä¸–ç•Œå‰µä¸–...")

    zero_instruction_str = ai_core.zero_instruction_template.format(
        username=ai_core.profile.user_profile.name,
        ai_name=ai_core.profile.ai_profile.name,
        latest_user_input="", retrieved_context="", response_style_prompt="",
        world_settings="", ai_settings="", tool_results="", chat_history="",
        location_context="", possessions_context="", quests_context="",
        npc_context="", relevant_npc_context=""
    )

    genesis_chain = ai_core.get_world_genesis_chain()
    genesis_result = await ai_core.ainvoke_with_rotation(genesis_chain, {
        "zero_instruction": zero_instruction_str,
        "world_settings": ai_core.profile.world_settings, 
        "username": ai_core.profile.user_profile.name, 
        "ai_name": ai_core.profile.ai_profile.name
    })
    
    if not genesis_result:
        raise Exception("ä¸–ç•Œå‰µä¸–éˆè¿”å›äº†ç©ºçµæœï¼Œå¯èƒ½æ˜¯å…§å®¹å¯©æŸ¥ã€‚")
        
    gs = ai_core.profile.game_state
    gs.location_path = genesis_result.location_path
    await ai_core.update_and_persist_profile({'game_state': gs.model_dump()})
    
    await lore_book.add_or_update_lore(user_id, 'location_info', " > ".join(genesis_result.location_path), genesis_result.location_info.model_dump())
    for npc in genesis_result.initial_npcs:
        npc_key = " > ".join(genesis_result.location_path) + f" > {npc.name}"
        await lore_book.add_or_update_lore(user_id, 'npc_profile', npc_key, npc.model_dump())
        
    return {"genesis_result": genesis_result}
# ç¯€é»ï¼šåŸ·è¡Œä¸–ç•Œå‰µä¸–

# ç¯€é»ï¼šç”Ÿæˆé–‹å ´ç™½
async def generate_opening_scene_node(state: SetupGraphState) -> Dict:
    """
    [è¨­å®šç¯€é» 4] ç”Ÿæˆæœ€çµ‚çš„é–‹å ´ç™½æ•˜äº‹ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    
    logger.info(f"[{user_id}] (Setup Graph) Node: generate_opening_scene_node -> æ­£åœ¨ç”Ÿæˆé–‹å ´ç™½...")
    
    opening_scene = await ai_core.generate_opening_scene()
    
    if not opening_scene or not opening_scene.strip():
        opening_scene = (f"åœ¨ä¸€ç‰‡æŸ”å’Œçš„å…‰èŠ’ä¸­ï¼Œä½ å’Œ {ai_core.profile.ai_profile.name} ç™¼ç¾è‡ªå·±èº«è™•æ–¼ä¸€å€‹å¯§éœçš„ç©ºé–“è£¡ï¼Œæ•…äº‹å³å°‡å¾é€™è£¡é–‹å§‹ã€‚"
                         "\n\nï¼ˆç³»çµ±æç¤ºï¼šç”±æ–¼æ‚¨çš„è¨­å®šï¼ŒAIç„¡æ³•ç”Ÿæˆæ›´è©³ç´°çš„é–‹å ´ç™½ï¼Œä½†æ‚¨ç¾åœ¨å¯ä»¥é–‹å§‹äº’å‹•äº†ã€‚ï¼‰")
                         
    return {"opening_scene": opening_scene}
# ç¯€é»ï¼šç”Ÿæˆé–‹å ´ç™½

# --- è¨­å®šåœ–çš„å»ºæ§‹å™¨ ---

# å‡½å¼ï¼šå‰µå»ºè¨­å®šåœ–
def create_setup_graph() -> StateGraph:
    """
    çµ„è£ä¸¦ç·¨è­¯ /start å‰µä¸–æµç¨‹çš„ StateGraphã€‚
    """
    graph = StateGraph(SetupGraphState)

    # æ·»åŠ æ‰€æœ‰ç¯€é»
    graph.add_node("process_canon", process_canon_node)
    graph.add_node("complete_profiles", complete_profiles_node)
    graph.add_node("world_genesis", world_genesis_node)
    graph.add_node("generate_opening_scene", generate_opening_scene_node)
    
    # è¨­å®šåœ–çš„å…¥å£é»
    graph.set_entry_point("process_canon")
    
    # æ·»åŠ é‚Šï¼ˆé€™æ˜¯ä¸€å€‹ç·šæ€§æµç¨‹ï¼‰
    graph.add_edge("process_canon", "complete_profiles")
    graph.add_edge("complete_profiles", "world_genesis")
    graph.add_edge("world_genesis", "generate_opening_scene")
    graph.add_edge("generate_opening_scene", END)
    
    # ç·¨è­¯åœ–å½¢
    return graph.compile()
# å‡½å¼ï¼šå‰µå»ºè¨­å®šåœ–
