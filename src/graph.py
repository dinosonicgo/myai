# src/graph.py çš„ä¸­æ–‡è¨»é‡‹(v5.2 - å®‰å…¨ä¸Šä¸‹æ–‡ç®¡ç†)
# æ›´æ–°ç´€éŒ„:
# v5.2 (2025-09-02): [é‡å¤§æ¶æ§‹é‡æ§‹ - å¥å£¯æ€§] é‡æ§‹äº† `tool_execution_node`ï¼Œå¼•å…¥äº† `try...finally` çµæ§‹ã€‚æ­¤ä¿®æ”¹ç¢ºä¿äº†ç„¡è«–å·¥å…·åŸ·è¡ŒæˆåŠŸèˆ‡å¦ï¼Œå…±äº«çš„ `tool_context` éƒ½æœƒè¢«ã€çµ•å°å¯é åœ°ã€‘æ¸…ç†ã€‚é€™å¾æ ¹æœ¬ä¸Šè§£æ±ºäº†å› ç•°å¸¸å°è‡´ä¸Šä¸‹æ–‡ç‹€æ…‹æ´©æ¼åˆ°å¾ŒçºŒå°è©±ä¸­çš„æ½›åœ¨é¢¨éšªï¼Œæ¥µå¤§åœ°æé«˜äº†ç³»çµ±çš„ç©©å®šæ€§ã€‚
# v5.1 (2025-09-02): [é‡å¤§æ¶æ§‹é‡æ§‹ - æµç¨‹ç°¡åŒ–] ç§»é™¤äº† `assemble_world_snapshot_node` ä¸¦å°‡å…¶è·è²¬åˆä½µé€² `planning_node`ã€‚
# v5.0 (2025-09-02): [é‡å¤§æ¶æ§‹é‡æ§‹ - åŸ·è¡Œåˆ†é›¢] å¼•å…¥äº† `tool_execution_node`ï¼Œå®Œæˆäº†â€œæ€è€ƒ->åŸ·è¡Œ->å¯«ä½œâ€çš„é–‰ç’°ã€‚

import sys
print(f"[DEBUG] graph.py loaded from: {__file__}", file=sys.stderr)
import asyncio
import json
import re
from typing import Dict, List, Literal, Optional

from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, END

from .ai_core import AILover
from .logger import logger
from .graph_state import ConversationGraphState, SetupGraphState
from . import lore_book, tools
from .schemas import CharacterProfile, TurnPlan
# [v5.2 æ–°å¢] å°å…¥å…±äº«çš„å·¥å…·ä¸Šä¸‹æ–‡
from .tool_context import tool_context

# --- ä¸»å°è©±åœ– (Main Conversation Graph) çš„ç¯€é» ---

# å‡½å¼ï¼šåˆå§‹åŒ–å°è©±ç‹€æ…‹
async def initialize_conversation_state_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é» 1] åœ¨æ¯ä¸€è¼ªå°è©±é–‹å§‹æ™‚ï¼ŒåŠ è¼‰æ‰€æœ‰å¿…è¦çš„ä¸Šä¸‹æ–‡æ•¸æ“šå¡«å……ç‹€æ…‹ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: initialize_conversation_state_node -> æ­£åœ¨ç‚º '{user_input[:30]}...' åˆå§‹åŒ–ç‹€æ…‹...")
    rag_task = ai_core.retriever.ainvoke(user_input)
    structured_context_task = ai_core._get_structured_context(user_input)
    retrieved_docs, structured_context = await asyncio.gather(rag_task, structured_context_task)
    rag_context_str = await ai_core._preprocess_rag_context(retrieved_docs)
    return {"structured_context": structured_context, "rag_context": rag_context_str}
# å‡½å¼ï¼šåˆå§‹åŒ–å°è©±ç‹€æ…‹

# å‡½å¼ï¼šåˆ†æä½¿ç”¨è€…è¼¸å…¥æ„åœ–
async def analyze_input_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é» 2] åˆ†æä½¿ç”¨è€…çš„è¼¸å…¥ï¼Œåˆ¤æ–·å…¶åŸºæœ¬æ„åœ–ï¼ˆå°è©±ã€æè¿°ã€æ¥çºŒï¼‰ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: analyze_input_node -> æ­£åœ¨åˆ†æè¼¸å…¥æ„åœ–...")
    analysis = await ai_core.ainvoke_with_rotation(ai_core.input_analysis_chain, {"user_input": user_input})
    return {"input_analysis": analysis}
# å‡½å¼ï¼šåˆ†æä½¿ç”¨è€…è¼¸å…¥æ„åœ–

# å‡½å¼ï¼šåŸ·è¡Œå ´æ™¯èˆ‡å‹•ä½œåˆ†æ (v3.0 - æ³¨å…¥é¸è§’ä¸Šä¸‹æ–‡)
# æ›´æ–°ç´€éŒ„:
# v3.0 (2025-09-03): [é‡å¤§é‚è¼¯å‡ç´š] éµä»ç”¨æˆ·åé¦ˆå’Œæ—¥å¿—åˆ†æï¼Œé‡æ„äº†æ­¤èŠ‚ç‚¹çš„æ‰§è¡Œæµç¨‹ã€‚ç°åœ¨ï¼Œåœ¨è°ƒç”¨ `scene_casting_chain` ä¹‹å‰ï¼Œä¼šå…ˆè°ƒç”¨ `_get_structured_context` æ¥è·å–åŒ…å«ã€å½“å‰æ‰€æœ‰å·²çŸ¥NPCã€‘çš„å®Œæ•´åœºæ™¯ä¸Šä¸‹æ–‡ï¼Œå¹¶å°†å…¶æ³¨å…¥åˆ°é€‰è§’é“¾ä¸­ã€‚è¿™ä¸ºé€‰è§’é“¾æä¾›äº†é¿å…é‡å¤åˆ›é€ è§’è‰²çš„å…³é”®åˆ¤æ–­ä¾æ®ï¼Œæ—¨åœ¨ä»æ ¹æœ¬ä¸Šè§£å†³æ— é™ç”Ÿæˆç›¸ä¼¼ NPC çš„é—®é¢˜ã€‚
# v1.1 (2025-09-02): [ç½é›£æ€§BUGä¿®å¾©] ç§»é™¤äº†åœ¨èª¿ç”¨ `_get_structured_context` æ™‚å‚³éçš„éæ™‚åƒæ•¸ã€‚
async def scene_and_action_analysis_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é» 3A - æ•˜äº‹è·¯å¾‘] åˆ†æå ´æ™¯è¦–è§’ï¼ˆæœ¬åœ°/é ç¨‹ï¼‰ä¸¦ç‚ºæ½›åœ¨çš„æ–° NPC é€²è¡Œé¸è§’ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: scene_and_action_analysis_node -> é€²å…¥æ•˜äº‹è·¯å¾‘åˆ†æ...")
    
    current_location_path = []
    if ai_core.profile and ai_core.profile.game_state:
        current_location_path = ai_core.profile.game_state.location_path
    
    scene_analysis = await ai_core.ainvoke_with_rotation(ai_core.scene_analysis_chain, {
        "user_input": user_input, 
        "current_location_path_str": " > ".join(current_location_path)
    })
    
    effective_location_path = current_location_path
    if scene_analysis and scene_analysis.viewing_mode == 'remote' and scene_analysis.target_location_path:
        effective_location_path = scene_analysis.target_location_path
        
    # [v3.0 æ ¸å¿ƒä¿®æ­£] å…ˆç²å–ä¸€æ¬¡å®Œæ•´çš„ä¸Šä¸‹æ–‡ï¼Œæä¾›çµ¦é¸è§’éˆ
    structured_context_for_casting = await ai_core._get_structured_context(
        user_input, 
        override_location_path=effective_location_path
    )
    game_context_for_casting = json.dumps(structured_context_for_casting, ensure_ascii=False, indent=2)
    world_settings_for_casting = ai_core.profile.world_settings if ai_core.profile else ""

    # [v3.0 æ ¸å¿ƒä¿®æ­£] å°‡ç²å–åˆ°çš„ä¸Šä¸‹æ–‡æ³¨å…¥é¸è§’éˆ
    cast_result = await ai_core.ainvoke_with_rotation(ai_core.scene_casting_chain, {
        "world_settings": world_settings_for_casting,
        "current_location_path": effective_location_path, 
        "game_context": game_context_for_casting, # <--- æ³¨å…¥ä¸Šä¸‹æ–‡
        "recent_dialogue": user_input
    })
    
    new_npc_names = await ai_core._add_cast_to_scene(cast_result)
    
    final_structured_context = structured_context_for_casting
    if new_npc_names:
        # å¦‚æœå‰µå»ºäº†æ–°NPCï¼Œå†æ¬¡ç²å–ä¸Šä¸‹æ–‡ä»¥åŒ…å«ä»–å€‘ï¼Œç¢ºä¿å¾ŒçºŒæµç¨‹èƒ½æ„ŸçŸ¥åˆ°æ–°è§’è‰²
        final_structured_context = await ai_core._get_structured_context(
            user_input, 
            override_location_path=effective_location_path
        )
        
    return {"scene_analysis": scene_analysis, "structured_context": final_structured_context}
# å‡½å¼ï¼šåŸ·è¡Œå ´æ™¯èˆ‡å‹•ä½œåˆ†æ (v3.0 - æ³¨å…¥é¸è§’ä¸Šä¸‹æ–‡)

# å‡½å¼ï¼šåŸ·è¡Œå›åˆè¦åŠƒ (v1.2 - å‚³éé¢¨æ ¼æŒ‡ä»¤)
# æ›´æ–°ç´€éŒ„:
# v1.2 (2025-09-02): [ç½é›£æ€§BUGä¿®å¾©] é‡æ§‹æ­¤ç¯€é»ï¼Œä½¿å…¶ç¾åœ¨è² è²¬å¾ ai_core.profile ä¸­æ˜ç¢ºè®€å– `response_style_prompt`ï¼Œä¸¦å°‡å…¶ä½œç‚ºä¸€å€‹é—œéµåƒæ•¸å‚³éçµ¦ `planning_chain`ã€‚é€™ç¢ºä¿äº†â€œæ€è€ƒâ€ç¯€é»èƒ½å¤ æ„ŸçŸ¥åˆ°ä½¿ç”¨è€…çš„é¢¨æ ¼è¦æ±‚ï¼Œå¾è€Œåˆ¶å®šå‡ºåŒ…å«æ­£ç¢ºå…ƒç´ ï¼ˆå¦‚å°è©±ï¼‰çš„è¡Œå‹•è¨ˆåŠƒï¼Œå¾¹åº•è§£æ±ºäº† AI å¿½ç•¥é¢¨æ ¼æŒ‡ä»¤çš„å•é¡Œã€‚
# v1.1 (2025-09-02): [æ¶æ§‹é‡æ§‹] å°‡ä¸Šä¸‹æ–‡çµ„åˆçš„è·è²¬åˆä½µé€²æ­¤ç¯€é»ã€‚
async def planning_node(state: ConversationGraphState) -> Dict[str, TurnPlan]:
    """
    [ç¯€é» 4] æ–°æ¶æ§‹çš„æ ¸å¿ƒâ€œæ€è€ƒâ€ç¯€é»ã€‚çµ„åˆä¸Šä¸‹æ–‡å¿«ç…§ï¼Œä¸¦èª¿ç”¨ planning_chain ç”Ÿæˆçµæ§‹åŒ–çš„è¡Œå‹•è¨ˆåŠƒã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    
    # æ­¥é©Ÿ 1: çµ„åˆä¸–ç•Œå¿«ç…§
    logger.info(f"[{user_id}] (Graph) Node: planning_node -> æ­£åœ¨æ ¼å¼åŒ–ä¸–ç•Œå¿«ç…§ä¸¦ç”Ÿæˆè¡Œå‹•è¨ˆåŠƒ...")
    context_dict = {
        "world_settings": ai_core.profile.world_settings or "æœªè¨­å®š",
        "ai_settings": ai_core.profile.ai_profile.description or "æœªè¨­å®š",
        "retrieved_context": state['rag_context'],
        **state['structured_context']
    }
    world_snapshot = ai_core.world_snapshot_template.format(**context_dict)
    
    # æ­¥é©Ÿ 2: [v1.2 æ–°å¢] ç²å–é¢¨æ ¼æŒ‡ä»¤
    response_style_prompt = ai_core.profile.response_style_prompt or "é è¨­é¢¨æ ¼ï¼šå¹³è¡¡çš„æ•˜äº‹èˆ‡å°è©±ã€‚"

    # æ­¥é©Ÿ 3: åŸ·è¡Œè¦åŠƒï¼Œä¸¦å‚³å…¥é¢¨æ ¼æŒ‡ä»¤
    if not ai_core.planning_chain:
        raise ValueError("Planning chain is not initialized.")
    plan = await ai_core.ainvoke_with_rotation(ai_core.planning_chain, {
        "username": ai_core.profile.user_profile.name,
        "ai_name": ai_core.profile.ai_profile.name,
        "world_snapshot": world_snapshot,
        "user_input": user_input,
        "response_style_prompt": response_style_prompt
    })

    return {"turn_plan": plan, "world_snapshot": world_snapshot}
# å‡½å¼ï¼šåŸ·è¡Œå›åˆè¦åŠƒ (v1.2 - å‚³éé¢¨æ ¼æŒ‡ä»¤)

# å‡½å¼ï¼šåŸ·è¡Œå·¥å…·èª¿ç”¨ (v1.1 - å®‰å…¨ä¸Šä¸‹æ–‡ç®¡ç†)
async def tool_execution_node(state: ConversationGraphState) -> Dict[str, str]:
    """
    [ç¯€é» 5] æ–°æ¶æ§‹çš„æ ¸å¿ƒâ€œåŸ·è¡Œâ€ç¯€é»ã€‚åœ¨å®‰å…¨çš„ä¸Šä¸‹æ–‡ä¸­åŸ·è¡Œè¨ˆåŠƒä¸­çš„æ‰€æœ‰å·¥å…·èª¿ç”¨ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    plan = state['turn_plan']
    logger.info(f"[{user_id}] (Graph) Node: tool_execution_node -> æ­£åœ¨åŸ·è¡Œè¡Œå‹•è¨ˆåŠƒä¸­çš„å·¥å…·...")
    
    if not plan:
        return {"tool_results": "ç³»çµ±äº‹ä»¶ï¼šå› è¡Œå‹•è¨ˆåŠƒç‚ºç©ºï¼ŒæœªåŸ·è¡Œä»»ä½•å·¥å…·ã€‚"}
    
    # [v5.2 æ ¸å¿ƒä¿®æ­£] ä½¿ç”¨ try...finally ç¢ºä¿ä¸Šä¸‹æ–‡è¢«çµ•å°å¯é åœ°æ¸…ç†
    try:
        results_summary = await ai_core._execute_planned_actions(plan)
    except Exception as e:
        logger.error(f"[{user_id}] (Graph) Node: tool_execution_node -> åœ¨åŸ·è¡Œå·¥å…·æ™‚ç™¼ç”Ÿæœªæ•ç²çš„ç•°å¸¸: {e}", exc_info=True)
        results_summary = f"ç³»çµ±äº‹ä»¶ï¼šå·¥å…·åŸ·è¡Œæ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}"
    finally:
        # ç„¡è«–æˆåŠŸæˆ–å¤±æ•—ï¼Œéƒ½å¿…é ˆæ¸…ç†ä¸Šä¸‹æ–‡ï¼Œé˜²æ­¢ç‹€æ…‹æ´©æ¼
        tool_context.set_context(None, None)
        logger.info(f"[{user_id}] (Graph) Node: tool_execution_node -> å·¥å…·ä¸Šä¸‹æ–‡å·²æ¸…ç†ã€‚")

    return {"tool_results": results_summary}
# å‡½å¼ï¼šåŸ·è¡Œå·¥å…·èª¿ç”¨ (v1.1 - å®‰å…¨ä¸Šä¸‹æ–‡ç®¡ç†)

# å‡½å¼ï¼šç”Ÿæˆæ•˜äº‹æ–‡æœ¬ (v2.0 - å¢åŠ å¯¹æ‹’ç»æ‰§è¡Œçš„å¤„ç†é€»è¾‘)
# æ›´æ–°ç´€éŒ„:
# v2.0 (2025-09-03): [é‡å¤§æ™ºèƒ½å‡ç´š] æ–°å¢äº†å¯¹è¡ŒåŠ¨è®¡åˆ’ä¸­ `execution_rejection_reason` å­—æ®µçš„å¤„ç†é€»è¾‘ã€‚å¦‚æœè¯¥å­—æ®µå­˜åœ¨ï¼Œæœ¬èŠ‚ç‚¹å°†ä¸å†æ¸²æŸ“å¸¸è§„çš„å°è¯´åœºæ™¯ï¼Œè€Œæ˜¯ç›´æ¥å°† AI ç»™å‡ºçš„â€œæ‹’ç»æ‰§è¡Œçš„åˆç†è§£é‡Šâ€ä½œä¸ºæœ€ç»ˆè¾“å‡ºã€‚è¿™ä½¿å¾— AI èƒ½å¤Ÿæ™ºèƒ½åœ°å›åº”ä¸åˆé€»è¾‘çš„ç”¨æˆ·æŒ‡ä»¤ï¼Œæ˜¯å®ç°â€œæ™ºæ…§å‹ GMâ€çš„å…³é”®ä¸€æ­¥ã€‚
async def narrative_node(state: ConversationGraphState) -> Dict[str, str]:
    """
    [ç¯€é» 6] æ–°æ¶æ§‹çš„æ ¸å¿ƒâ€œå¯«ä½œâ€ç¯€é»ã€‚æ¥æ”¶çµæ§‹åŒ–çš„è¡Œå‹•è¨ˆåŠƒå’Œå·¥å…·åŸ·è¡Œçµæœï¼Œä¸¦å°‡å…¶æ¸²æŸ“æˆçº¯ç²¹çš„å°èªªæ–‡æœ¬ï¼Œæˆ–ç›´æ¥è¾“å‡º AI çš„åˆç†è§£é‡Šã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    turn_plan = state['turn_plan']
    tool_results = state['tool_results']
    logger.info(f"[{user_id}] (Graph) Node: narrative_node -> æ­£åœ¨å¤„ç†è¡ŒåŠ¨è®¡åˆ’...")

    if not turn_plan:
        logger.error(f"[{user_id}] å™äº‹èŠ‚ç‚¹æ¥æ”¶åˆ°ç©ºçš„è¡ŒåŠ¨è®¡åˆ’ï¼Œæ— æ³•ç”Ÿæˆå›åº”ã€‚")
        return {"llm_response": "ï¼ˆç³»ç»Ÿé”™è¯¯ï¼šæœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„è¡ŒåŠ¨è®¡åˆ’ã€‚ï¼‰"}

    # [v2.0 æ ¸å¿ƒä¿®æ­£] æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ‹’ç»æ‰§è¡Œçš„ç†ç”±
    if turn_plan.execution_rejection_reason:
        logger.info(f"[{user_id}] (Graph) Node: narrative_node -> æ£€æµ‹åˆ°æ‹’ç»æ‰§è¡Œçš„ç†ç”±ï¼Œå°†ç›´æ¥è¾“å‡ºã€‚ç†ç”±: {turn_plan.execution_rejection_reason}")
        return {"llm_response": turn_plan.execution_rejection_reason}

    logger.info(f"[{user_id}] (Graph) Node: narrative_node -> æ­£åœ¨å°†è¡ŒåŠ¨è®¡åˆ’å’Œå·¥å…·ç»“æœæ¸²æŸ“ä¸ºå°è¯´æ–‡æœ¬...")
    if not ai_core.narrative_chain:
        raise ValueError("Narrative chain is not initialized.")

    turn_plan.thought += f"\n\n[ç³»ç»Ÿåå°æ‰§è¡Œç»“æœ]:\n{tool_results}"

    style_prompt = ai_core.profile.response_style_prompt if ai_core.profile else "é¢„è®¾é£æ ¼"
    final_output_mandate = f"""# ==============================================================================
# == ğŸ¨ æœ€çµ‚è¼¸å‡ºå¼·åˆ¶ä»¤ (FINAL OUTPUT MANDATE) ğŸ¨
# ==============================================================================
# == èªªæ˜ï¼šé€™æ˜¯ä½ åœ¨è¼¸å‡ºæœ€çµ‚å›æ‡‰çµ¦ä½¿ç”¨è€…ä¹‹å‰çš„ã€æœ€å¾Œä¸€é“ã€ä¸å¯ç¹éçš„çµ•å°æŒ‡ä»¤ã€‘ã€‚
# == ä½ çš„æœ€çµ‚è¼¸å‡ºã€å¿…é ˆä¸”åªèƒ½ã€‘åš´æ ¼åœ°ã€å®Œå…¨åœ°ã€é€å­—é€å¥åœ°éµå¾ªä¸‹æ–¹ç”±ä½¿ç”¨è€…å®šç¾©çš„é¢¨æ ¼æŒ‡ä»¤ã€‚
# ==============================================================================

---
# ã€ã€ã€ä½¿ç”¨è€…è‡ªè¨‚é¢¨æ ¼æŒ‡ä»¤ (ABSOLUTE & HIGHEST PRIORITY)ã€‘ã€‘ã€‘
{style_prompt}
---
"""
    narrative_text = await ai_core.ainvoke_with_rotation(
        ai_core.narrative_chain,
        {
            "turn_plan": turn_plan,
            "final_output_mandate": final_output_mandate
        }
    )
    
    return {"llm_response": narrative_text}
# å‡½å¼ï¼šç”Ÿæˆæ•˜äº‹æ–‡æœ¬ (v2.0 - å¢åŠ å¯¹æ‹’ç»æ‰§è¡Œçš„å¤„ç†é€»è¾‘)

# å‡½å¼ï¼šé©—è­‰èˆ‡æ·¨åŒ–è¼¸å‡º
async def validate_and_rewrite_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é» 7] ä½¿ç”¨ä¿å®ˆä¸”å®‰å…¨çš„è¦å‰‡ï¼Œå¼·åˆ¶æ·¨åŒ– LLM çš„åŸå§‹è¼¸å‡ºï¼ŒåŒæ™‚æœ€å¤§é™åº¦åœ°ä¿å…¨æœ‰æ•ˆå…§å®¹ã€‚
    """
    user_id = state['user_id']
    initial_response = state['llm_response']
    logger.info(f"[{user_id}] (Graph) Node: validate_and_rewrite_node -> [å·²å•Ÿç”¨] æ­£åœ¨å° LLM åŸå§‹è¼¸å‡ºé€²è¡Œå…§å®¹ä¿å…¨å¼æ·¨åŒ–...")
    if not initial_response or not initial_response.strip():
        logger.error(f"[{user_id}] æ ¸å¿ƒéˆåœ¨æ·¨åŒ–å‰è¿”å›äº†ç©ºçš„æˆ–ç„¡æ•ˆçš„å›æ‡‰ã€‚")
        return {"final_output": "ï¼ˆ...ï¼‰"}
    clean_response = initial_response
    clean_response = re.sub(r'ï¼ˆ(æ€è€ƒ|è¡Œå‹•|è‡ªæˆ‘è§€å¯Ÿ)\s*[:ï¼š\s\S]*?ï¼‰', '', clean_response)
    clean_response = re.sub(r'^\s*(æ—ç™½|å°è©±)\s*[:ï¼š]\s*', '', clean_response, flags=re.MULTILINE)
    if 'æ—ç™½:' in clean_response or 'å°è©±:' in clean_response:
        logger.warning(f"[{user_id}] æª¢æ¸¬åˆ°éæ¨™æº–æ ¼å¼çš„æ¨™ç±¤æ´©æ¼ï¼Œå•Ÿå‹•å‚™æ´æ¸…ç†ã€‚")
        clean_response = clean_response.replace('æ—ç™½:', '').replace('å°è©±:', '')
        clean_response = clean_response.replace('æ—ç™½ï¼š', '').replace('å°è©±ï¼š', '')
    final_response = clean_response.strip()
    if not final_response:
        logger.warning(f"[{user_id}] LLM åŸå§‹è¼¸å‡ºåœ¨æ·¨åŒ–å¾Œç‚ºç©ºã€‚åŸå§‹è¼¸å‡ºç‚º: '{initial_response[:200]}...'")
        return {"final_output": "ï¼ˆ...ï¼‰"}
    return {"final_output": final_response}
# å‡½å¼ï¼šé©—è­‰èˆ‡æ·¨åŒ–è¼¸å‡º

# å‡½å¼ï¼šåŸ·è¡Œç‹€æ…‹æ›´æ–°èˆ‡è¨˜æ†¶å„²å­˜
async def persist_state_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é» 8] å°‡æœ¬è¼ªå°è©±å­˜å…¥è¨˜æ†¶ï¼Œä¸¦å°‡ state_updates ä¸­çš„è®Šæ›´æ‡‰ç”¨åˆ°è³‡æ–™åº«ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    clean_response = state['final_output']
    logger.info(f"[{user_id}] (Graph) Node: persist_state_node -> æ­£åœ¨æŒä¹…åŒ–ç‹€æ…‹èˆ‡è¨˜æ†¶...")
    if clean_response and clean_response != "ï¼ˆ...ï¼‰":
        chat_history_manager = ai_core.session_histories.get(user_id)
        if chat_history_manager:
            chat_history_manager.add_user_message(user_input)
            chat_history_manager.add_ai_message(clean_response)
        last_interaction_text = f"ä½¿ç”¨è€… '{ai_core.profile.user_profile.name}' èªª: {user_input}\n\n[å ´æ™¯å›æ‡‰]:\n{clean_response}"
        tasks = []
        tasks.append(ai_core._generate_and_save_personal_memory(last_interaction_text))
        if ai_core.vector_store:
            tasks.append(asyncio.to_thread(ai_core.vector_store.add_texts, [last_interaction_text], metadatas=[{"source": "history"}]))
        async def save_to_sql():
            from .database import AsyncSessionLocal, MemoryData
            import time
            timestamp = time.time()
            async with AsyncSessionLocal() as session:
                session.add(MemoryData(user_id=user_id, content=last_interaction_text, timestamp=timestamp, importance=1))
                await session.commit()
        tasks.append(save_to_sql())
        await asyncio.gather(*tasks, return_exceptions=True)
    return {}
# å‡½å¼ï¼šåŸ·è¡Œç‹€æ…‹æ›´æ–°èˆ‡è¨˜æ†¶å„²å­˜

# å‡½å¼ï¼šè§¸ç™¼èƒŒæ™¯ä¸–ç•Œæ“´å±•
async def background_world_expansion_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é» 9] åœ¨å›æ‡‰ç™¼é€å¾Œï¼Œéé˜»å¡åœ°è§¸ç™¼èƒŒæ™¯ä¸–ç•Œæ“´å±•ã€LOREç”Ÿæˆç­‰ä»»å‹™ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    clean_response = state['final_output']
    scene_analysis = state['scene_analysis']
    logger.info(f"[{user_id}] (Graph) Node: background_world_expansion_node -> æ­£åœ¨è§¸ç™¼èƒŒæ™¯ä»»å‹™...")
    effective_location_path = ai_core.profile.game_state.location_path
    if scene_analysis and scene_analysis.target_location_path:
        effective_location_path = scene_analysis.target_location_path
    if scene_analysis and (scene_analysis.viewing_mode == 'local' or scene_analysis.target_location_path):
        if clean_response and clean_response != "ï¼ˆ...ï¼‰":
            asyncio.create_task(ai_core._background_scene_expansion(user_input, clean_response, effective_location_path))
            logger.info(f"[{user_id}] å·²æˆåŠŸç‚ºåœ°é» '{' > '.join(effective_location_path)}' å‰µå»ºèƒŒæ™¯æ“´å±•ä»»å‹™ã€‚")
    return {}
# å‡½å¼ï¼šè§¸ç™¼èƒŒæ™¯ä¸–ç•Œæ“´å±•

# å‡½å¼ï¼šåœ–å½¢çµæŸ finalizing
async def finalization_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é» 10] ä¸€å€‹è™›æ“¬çš„æœ€çµ‚ç¯€é»ï¼Œç¢ºä¿æ‰€æœ‰ç•°æ­¥èƒŒæ™¯ä»»å‹™éƒ½è¢«æˆåŠŸèª¿åº¦ã€‚
    """
    user_id = state['user_id']
    logger.info(f"[{user_id}] (Graph) Node: finalization_node -> å°è©±æµç¨‹åœ–åŸ·è¡Œå®Œç•¢ã€‚")
    return {}
# å‡½å¼ï¼šåœ–å½¢çµæŸ finalizing

# --- ä¸»å°è©±åœ–çš„è·¯ç”± ---

# å‡½å¼ï¼šåœ¨è¼¸å…¥åˆ†æå¾Œæ±ºå®šæµç¨‹
def route_after_input_analysis(state: ConversationGraphState) -> Literal["narrative_flow", "dialogue_flow"]:
    input_type = state["input_analysis"].input_type
    user_id = state['user_id']
    if input_type in ['narration', 'continuation']:
        logger.info(f"[{user_id}] (Graph) Router: route_after_input_analysis -> åˆ¤å®šç‚ºã€Œæ•˜äº‹æµç¨‹ã€ã€‚")
        return "narrative_flow"
    else:
        logger.info(f"[{user_id}] (Graph) Router: route_after_input_analysis -> åˆ¤å®šç‚ºã€Œå°è©±æµç¨‹ã€ã€‚")
        return "dialogue_flow"
# å‡½å¼ï¼šåœ¨è¼¸å…¥åˆ†æå¾Œæ±ºå®šæµç¨‹

# --- ä¸»å°è©±åœ–çš„å»ºæ§‹å™¨ ---

# å‡½å¼ï¼šå‰µå»ºä¸»å›æ‡‰åœ– (v5.3 - ä¿®å¾©èƒŒæ™¯æ“´å±•è§¸ç™¼)
# æ›´æ–°ç´€éŒ„:
# v5.3 (2025-09-02): [ç½é›£æ€§BUGä¿®å¾©] å¾¹åº•é‡æ§‹äº†åœ–å½¢çš„æ‹“æ’²çµæ§‹ã€‚èˆŠçµæ§‹åœ¨â€œå°è©±æµç¨‹â€ä¸­æœƒè·³é `scene_and_action_analysis_node`ï¼Œå°è‡´ `scene_analysis` ç‹€æ…‹ç‚ºç©ºï¼Œå¾è€Œä½¿ `background_world_expansion_node` æ°¸é ç„¡æ³•è§¸ç™¼èƒŒæ™¯ä»»å‹™ã€‚æ–°çµæ§‹å°‡ `scene_and_action_analysis_node` æå‡ç‚ºæ‰€æœ‰æµç¨‹çš„å¿…ç¶“ç¯€é»ï¼Œç¢ºä¿äº†èƒŒæ™¯ä¸–ç•Œæ“´å±•åŠŸèƒ½åœ¨æ¯ä¸€æ¬¡å°è©±å¾Œéƒ½èƒ½è¢«å¯é åœ°è§¸ç™¼ã€‚
# v5.2 (2025-09-02): [é‡å¤§æ¶æ§‹é‡æ§‹ - å¥å£¯æ€§] åœ¨ `tool_execution_node` ä¸­å¼•å…¥äº† `try...finally` çµæ§‹ï¼Œç¢ºä¿å·¥å…·ä¸Šä¸‹æ–‡çš„çµ•å°æ¸…ç†ã€‚
def create_main_response_graph() -> StateGraph:
    """
    çµ„è£ä¸¦ç·¨è­¯ä¸»å°è©±æµç¨‹çš„ StateGraphã€‚
    """
    graph = StateGraph(ConversationGraphState)

    graph.add_node("initialize_state", initialize_conversation_state_node)
    graph.add_node("analyze_input", analyze_input_node)
    graph.add_node("scene_and_action_analysis", scene_and_action_analysis_node)
    graph.add_node("planning", planning_node)
    graph.add_node("tool_execution", tool_execution_node)
    graph.add_node("narrative", narrative_node)
    graph.add_node("validate_and_rewrite", validate_and_rewrite_node)
    graph.add_node("persist_state", persist_state_node)
    graph.add_node("background_expansion", background_world_expansion_node)
    graph.add_node("finalization", finalization_node)

    graph.set_entry_point("initialize_state")

    graph.add_edge("initialize_state", "analyze_input")
    
    # [v5.3 ä¿®æ­£] ä¸å†ä½¿ç”¨æ¢ä»¶è·¯ç”±ï¼Œanalyze_input çµ±ä¸€æŒ‡å‘ scene_and_action_analysis
    graph.add_edge("analyze_input", "scene_and_action_analysis")
    
    # [v5.3 ä¿®æ­£] scene_and_action_analysis æˆç‚º planning ä¹‹å‰çš„å¿…ç¶“ç¯€é»
    graph.add_edge("scene_and_action_analysis", "planning")
    
    graph.add_edge("planning", "tool_execution")
    graph.add_edge("tool_execution", "narrative")
    graph.add_edge("narrative", "validate_and_rewrite")
    graph.add_edge("validate_and_rewrite", "persist_state")
    graph.add_edge("persist_state", "background_expansion")
    graph.add_edge("background_expansion", "finalization")
    graph.add_edge("finalization", END)
    
    return graph.compile()
# å‡½å¼ï¼šå‰µå»ºä¸»å›æ‡‰åœ– (v5.3 - ä¿®å¾©èƒŒæ™¯æ“´å±•è§¸ç™¼)

# --- è¨­å®šåœ– (Setup Graph) çš„ç¯€é» (ä¿æŒä¸è®Š) ---
async def process_canon_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    canon_text = state['canon_text']
    if canon_text:
        logger.info(f"[{user_id}] (Setup Graph) Node: process_canon_node -> æ­£åœ¨è™•ç†ä¸–ç•Œè–ç¶“...")
        await ai_core.add_canon_to_vector_store(canon_text)
        await ai_core.parse_and_create_lore_from_canon(None, canon_text, is_setup_flow=True)
        if not await ai_core.initialize():
            raise Exception("åœ¨è¼‰å…¥ä¸–ç•Œè–ç¶“å¾Œé‡æ–°åˆå§‹åŒ– AI æ ¸å¿ƒå¤±æ•—ã€‚")
    return {}
async def complete_profiles_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    logger.info(f"[{user_id}] (Setup Graph) Node: complete_profiles_node -> æ­£åœ¨è£œå®Œè§’è‰²æª”æ¡ˆ...")
    completion_prompt = ai_core.get_profile_completion_prompt()
    completion_llm = ai_core.gm_model.with_structured_output(CharacterProfile)
    completion_chain = completion_prompt | completion_llm
    completed_user_profile = await ai_core.ainvoke_with_rotation(completion_chain, {"profile_json": ai_core.profile.user_profile.model_dump_json()})
    completed_ai_profile = await ai_core.ainvoke_with_rotation(completion_chain, {"profile_json": ai_core.profile.ai_profile.model_dump_json()})
    await ai_core.update_and_persist_profile({'user_profile': completed_user_profile.model_dump(), 'ai_profile': completed_ai_profile.model_dump()})
    return {}
async def world_genesis_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    logger.info(f"[{user_id}] (Setup Graph) Node: world_genesis_node -> æ­£åœ¨åŸ·è¡Œä¸–ç•Œå‰µä¸–...")
    genesis_chain = ai_core.get_world_genesis_chain()
    genesis_result = await ai_core.ainvoke_with_rotation(genesis_chain, {"world_settings": ai_core.profile.world_settings, "username": ai_core.profile.user_profile.name, "ai_name": ai_core.profile.ai_profile.name})
    if not genesis_result:
        raise Exception("ä¸–ç•Œå‰µä¸–éˆè¿”å›äº†ç©ºçµæœï¼Œå¯èƒ½æ˜¯å…§å®¹å¯©æŸ¥ã€‚")
    gs = ai_core.profile.game_state
    gs.location_path = genesis_result.location_path
    await ai_core.update_and_persist_profile({'game_state': gs.model_dump()})
    await lore_book.add_or_update_lore(user_id, 'location_info', " > ".join(genesis_result.location_path), genesis_result.location_info.model_dump())
    for npc in genesis_result.initial_npcs:
        npc_key = " > ".join(genesis_result.location_path) + f" > {npc.name}"
        await lore_book.add_or_update_lore(user_id, 'npc_profile', npc_key, npc.model_dump())
    return {"genesis_result": genesis_result}
async def generate_opening_scene_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    logger.info(f"[{user_id}] (Setup Graph) Node: generate_opening_scene_node -> æ­£åœ¨ç”Ÿæˆé–‹å ´ç™½...")
    opening_scene = await ai_core.generate_opening_scene()
    if not opening_scene or not opening_scene.strip():
        opening_scene = (f"åœ¨ä¸€ç‰‡æŸ”å’Œçš„å…‰èŠ’ä¸­ï¼Œä½ å’Œ {ai_core.profile.ai_profile.name} ç™¼ç¾è‡ªå·±èº«è™•æ–¼ä¸€å€‹å¯§éœçš„ç©ºé–“è£¡ï¼Œæ•…äº‹å³å°‡å¾é€™è£¡é–‹å§‹ã€‚"
                         "\n\nï¼ˆç³»çµ±æç¤ºï¼šç”±æ–¼æ‚¨çš„è¨­å®šï¼ŒAIç„¡æ³•ç”Ÿæˆæ›´è©³ç´°çš„é–‹å ´ç™½ï¼Œä½†æ‚¨ç¾åœ¨å¯ä»¥é–‹å§‹äº’å‹•äº†ã€‚ï¼‰")
    return {"opening_scene": opening_scene}
def create_setup_graph() -> StateGraph:
    graph = StateGraph(SetupGraphState)
    graph.add_node("process_canon", process_canon_node)
    graph.add_node("complete_profiles", complete_profiles_node)
    graph.add_node("world_genesis", world_genesis_node)
    graph.add_node("generate_opening_scene", generate_opening_scene_node)
    graph.set_entry_point("process_canon")
    graph.add_edge("process_canon", "complete_profiles")
    graph.add_edge("complete_profiles", "world_genesis")
    graph.add_edge("world_genesis", "generate_opening_scene")
    graph.add_edge("generate_opening_scene", END)
    return graph.compile()
