# src/graph.py çš„ä¸­æ–‡è¨»é‡‹(v19.0 - LORE çµ±ä¸€æ¶æ§‹æœ€çµ‚ç‰ˆ)
# æ›´æ–°ç´€éŒ„:
# v19.0 (2025-09-06): [ç½é›£æ€§BUGä¿®å¾©] æ ¹æ“šä½¿ç”¨è€…â€œLOREæ‡‰ç‚ºç¨ç«‹ç¯€é»â€çš„æ ¸å¿ƒæŒ‡æ‘˜ï¼Œå°åœ–çš„æ‹“æ’²é€²è¡Œäº†æœ€çµ‚çš„ã€æ ¹æœ¬æ€§çš„é‡æ§‹ã€‚
#    1. [å‰µå»ºé€šç”¨é è™•ç†æ¨¡çµ„] å°‡æ„åœ–åˆ†é¡ä¹‹å¾Œã€æœ€çµ‚ç”Ÿæˆä¹‹å‰çš„ LORE ç›¸é—œç¯€é»ï¼ˆåˆå§‹åŒ–ã€åˆ†æã€æ±ºç­–ã€æ“´å±•ï¼‰é‡æ§‹ç‚ºä¸€å€‹æ‰€æœ‰è·¯å¾‘ï¼ˆSFW/NSFWï¼‰éƒ½å¿…é ˆç¶“éçš„â€œé€šç”¨é è™•ç†æ¨¡çµ„â€ã€‚
#    2. [æ–°å¢æœ€çµ‚ç”Ÿæˆè·¯ç”±å™¨] å‰µå»ºäº†æ–°çš„ `route_to_final_generator` è·¯ç”±å™¨ã€‚å®ƒæœƒåœ¨æ‰€æœ‰LOREé è™•ç†å®Œæˆå¾Œï¼Œæ‰æ ¹æ“šæœ€åˆçš„æ„åœ–åˆ†é¡ï¼Œå°‡æµç¨‹åˆ†ç™¼åˆ°å„è‡ªçš„å°ˆç”¨ç”Ÿæˆç¯€é»ã€‚
#    3. [å¯¦ç¾æ¶æ§‹çµ±ä¸€] æ­¤ä¿®æ”¹å¾æ ¹æœ¬ä¸Šçµ±ä¸€äº† SFW å’Œ NSFW è·¯å¾‘çš„ LORE è™•ç†æµç¨‹ï¼Œç¢ºä¿äº†ç³»çµ±è¡Œç‚ºçš„ä¸€è‡´æ€§ï¼Œå¾¹åº•è§£æ±ºäº†å› æ¶æ§‹åˆ†è£‚å°è‡´çš„ LORE ç›¸é—œçš„æ‰€æœ‰é ‘å›ºå•é¡Œã€‚
# v18.0 (2025-09-06): [ç½é›£æ€§BUGä¿®å¾©] å¼•å…¥äº†å°ˆç”¨çš„ `lore_expansion_node`ã€‚

import sys
print(f"[DEBUG] graph.py loaded from: {__file__}", file=sys.stderr)
import asyncio
import json
import re
from typing import Dict, List, Literal, Optional

from langchain_core.messages import HumanMessage
from langchain_community.chat_message_histories import ChatMessageHistory
from langgraph.graph import StateGraph, END

from .ai_core import AILover
from .logger import logger
from .graph_state import ConversationGraphState, SetupGraphState
from . import lore_book, tools
from .schemas import (CharacterProfile, TurnPlan, ExpansionDecision, 
                      UserInputAnalysis, SceneAnalysisResult, SceneCastingResult, 
                      WorldGenesisResult, IntentClassificationResult, StyleAnalysisResult)
from .tool_context import tool_context

# --- ä¸»å°è©±åœ– (Main Conversation Graph) çš„ç¯€é» ---

async def classify_intent_node(state: ConversationGraphState) -> Dict:
    """åœ–çš„å…¥å£é»ï¼Œå”¯ä¸€è·è²¬æ˜¯å°åŸå§‹è¼¸å…¥é€²è¡Œæ„åœ–åˆ†é¡ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: classify_intent_node -> æ­£åœ¨å° '{user_input[:30]}...' é€²è¡Œæ„åœ–åˆ†é¡...")
    
    classification_chain = ai_core.get_intent_classification_chain()
    classification_result = await ai_core.ainvoke_with_rotation(
        classification_chain,
        {"user_input": user_input},
        retry_strategy='none'
    )
    
    if not classification_result:
        logger.warning(f"[{user_id}] (Graph) æ„åœ–åˆ†é¡éˆå¤±æ•—ï¼Œå•Ÿå‹•å®‰å…¨å‚™æ´ï¼Œé è¨­ç‚º SFWã€‚")
        classification_result = IntentClassificationResult(intent_type='sfw', reasoning="å®‰å…¨å‚™æ´ï¼šåˆ†é¡éˆå¤±æ•—ã€‚")
        
    return {"intent_classification": classification_result}

async def initialize_conversation_state_node(state: ConversationGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: initialize_conversation_state_node [é€šç”¨] -> æ­£åœ¨ç‚º '{user_input[:30]}...' åˆå§‹åŒ–ç‹€æ…‹...")
    
    rag_task = ai_core.ainvoke_with_rotation(ai_core.retriever, user_input, retry_strategy='euphemize')
    structured_context_task = ai_core._get_structured_context(user_input)
    
    retrieved_docs, structured_context = await asyncio.gather(rag_task, structured_context_task)
    
    if retrieved_docs is None:
        logger.warning(f"[{user_id}] RAG æª¢ç´¢è¿”å› None (å¯èƒ½å› å§”å©‰åŒ–å¤±æ•—)ï¼Œä½¿ç”¨ç©ºåˆ—è¡¨ä½œç‚ºå‚™æ´ã€‚")
        retrieved_docs = []
        
    rag_context_str = await ai_core._preprocess_rag_context(retrieved_docs)
    return {"structured_context": structured_context, "rag_context": rag_context_str}

async def analyze_input_node(state: ConversationGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: analyze_input_node [é€šç”¨] -> æ­£åœ¨åˆ†æè¼¸å…¥æ„åœ–...")
    analysis = await ai_core.ainvoke_with_rotation(
        ai_core.get_input_analysis_chain(), 
        {"user_input": user_input},
        retry_strategy='euphemize'
    )
    if not analysis:
        logger.warning(f"[{user_id}] (Graph) è¼¸å…¥åˆ†æéˆå§”å©‰åŒ–é‡è©¦å¤±æ•—ï¼Œå•Ÿå‹•å®‰å…¨å‚™æ´ã€‚")
        analysis = UserInputAnalysis(
            input_type='dialogue_or_command', 
            summary_for_planner=user_input, 
            narration_for_turn=""
        )
    return {"input_analysis": analysis}

async def expansion_decision_node(state: ConversationGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: expansion_decision_node [é€šç”¨] -> æ­£åœ¨åˆ¤æ–·æ˜¯å¦éœ€è¦æ“´å±•LORE...")
    chat_history_manager = ai_core.session_histories.get(user_id, ChatMessageHistory())
    recent_dialogue = "\n".join([f"{'ä½¿ç”¨è€…' if isinstance(m, HumanMessage) else 'AI'}: {m.content}" for m in chat_history_manager.messages[-6:]])
    decision = await ai_core.ainvoke_with_rotation(
        ai_core.get_expansion_decision_chain(), 
        {"user_input": user_input, "recent_dialogue": recent_dialogue},
        retry_strategy='euphemize'
    )
    if not decision:
        logger.warning(f"[{user_id}] (Graph) LOREæ“´å±•æ±ºç­–éˆå§”å©‰åŒ–é‡è©¦å¤±æ•—ï¼Œå•Ÿå‹•å®‰å…¨å‚™æ´ã€‚")
        decision = ExpansionDecision(
            should_expand=False,
            reasoning="å®‰å…¨å‚™æ´ï¼šæ±ºç­–éˆæœªèƒ½è¿”å›æœ‰æ•ˆçµæœã€‚"
        )
    logger.info(f"[{user_id}] (Graph) LOREæ“´å±•æ±ºç­–: {decision.should_expand}ã€‚ç†ç”±: {decision.reasoning}")
    return {"expansion_decision": decision}

async def lore_expansion_node(state: ConversationGraphState) -> Dict:
    """å°ˆç”¨çš„LOREæ“´å±•ä¸­å¿ƒã€‚è² è²¬åŒæ­¥åœ°é€²è¡Œé¸è§’å’Œå ´æ™¯ç´°åŒ–ï¼Œä¸¦ç«‹å³åˆ·æ–°ä¸Šä¸‹æ–‡ç‹€æ…‹ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    current_location_path = ai_core.profile.game_state.location_path if ai_core.profile else []
    logger.info(f"[{user_id}] (Graph) Node: lore_expansion_node [é€šç”¨] -> æ­£åœ¨ç‚ºå ´æ™¯é€²è¡ŒåŒæ­¥LOREæ“´å±•...")

    logger.info(f"[{user_id}] (LOREæ“´å±•) ...æ­¥é©Ÿ 1/2: åŸ·è¡Œå ´æ™¯é¸è§’...")
    game_context_for_casting = json.dumps(state.get('structured_context', {}), ensure_ascii=False, indent=2)
    cast_result = await ai_core.ainvoke_with_rotation(
        ai_core.get_scene_casting_chain(),
        {
            "world_settings": ai_core.profile.world_settings or "",
            "current_location_path": current_location_path, 
            "game_context": game_context_for_casting,
            "recent_dialogue": user_input
        },
        retry_strategy='euphemize'
    )
    if cast_result:
        await ai_core._add_cast_to_scene(cast_result)
    else:
         logger.warning(f"[{user_id}] (LOREæ“´å±•) å ´æ™¯é¸è§’éˆå§”å©‰åŒ–é‡è©¦å¤±æ•—ï¼Œæœ¬è¼ªè·³éé¸è§’ã€‚")

    logger.info(f"[{user_id}] (LOREæ“´å±•) ...æ­¥é©Ÿ 2/2: åŸ·è¡Œå ´æ™¯ç´°åŒ–...")
    await ai_core._background_scene_expansion(user_input, "", current_location_path)

    logger.info(f"[{user_id}] (LOREæ“´å±•) ...LOREæ“´å±•å®Œæˆï¼Œæ­£åœ¨åˆ·æ–°çµæ§‹åŒ–ä¸Šä¸‹æ–‡...")
    final_structured_context = await ai_core._get_structured_context(user_input, override_location_path=current_location_path)
    
    return {"structured_context": final_structured_context}

async def scene_and_action_analysis_node(state: ConversationGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: scene_and_action_analysis_node [SFW Path] -> æ­£åœ¨é€²è¡Œå ´æ™¯è¦–è§’åˆ†æ...")
    current_location_path = ai_core.profile.game_state.location_path if ai_core.profile else []
    scene_analysis = await ai_core.ainvoke_with_rotation(
        ai_core.get_scene_analysis_chain(),
        {"user_input": user_input, "current_location_path_str": " > ".join(current_location_path)},
        retry_strategy='euphemize'
    )
    if not scene_analysis:
        logger.warning(f"[{user_id}] (Graph) å ´æ™¯åˆ†æéˆå§”å©‰åŒ–é‡è©¦å¤±æ•—ï¼Œå•Ÿå‹•å®‰å…¨å‚™æ´ã€‚")
        scene_analysis = SceneAnalysisResult(
            viewing_mode='local', 
            reasoning='å®‰å…¨å‚™æ´ï¼šå ´æ™¯åˆ†æéˆå¤±æ•—ã€‚', 
            action_summary=user_input
        )
    return {"scene_analysis": scene_analysis}

async def style_analysis_node(state: ConversationGraphState) -> Dict:
    """åˆ†æç”¨æˆ¶çš„é¢¨æ ¼æŒ‡ä»¤ï¼Œä¸¦å°‡å…¶è½‰åŒ–ç‚ºçµ¦è¦åŠƒå™¨çš„çµæ§‹åŒ–ç¡¬æ€§æŒ‡ä»¤ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: style_analysis_node [SFW Path] -> æ­£åœ¨åˆ†æå›æ‡‰é¢¨æ ¼...")
    
    style_analysis_chain = ai_core.get_style_analysis_chain()
    style_result = await ai_core.ainvoke_with_rotation(
        style_analysis_chain,
        {
            "user_input": user_input,
            "response_style_prompt": ai_core.profile.response_style_prompt or "é è¨­é¢¨æ ¼"
        },
        retry_strategy='euphemize'
    )
    
    if not style_result:
        logger.warning(f"[{user_id}] (Graph) é¢¨æ ¼åˆ†æéˆå§”å©‰åŒ–é‡è©¦å¤±æ•—ï¼Œå•Ÿå‹•å®‰å…¨å‚™æ´ã€‚")
        style_result = StyleAnalysisResult(
            dialogue_requirement="AIè§’è‰²å¿…é ˆè‡³å°‘èªªä¸€å¥ç¬¦åˆå…¶æ€§æ ¼å’Œæƒ…å¢ƒçš„è©±",
            narration_level="ä¸­ç­‰",
            proactive_suggestion="å¯ä»¥å˜—è©¦æè¿°å‘¨åœçš„ç’°å¢ƒä¾†å›æ‡‰ã€‚"
        )
        
    return {"style_analysis": style_result}

async def planning_node(state: ConversationGraphState) -> Dict[str, TurnPlan]:
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    style_analysis = state['style_analysis']
    logger.info(f"[{user_id}] (Graph) Node: planning_node [SFW Path] -> æ­£åœ¨æ ¹æ“šå…·é«”é¢¨æ ¼æŒ‡ä»¤é€²è¡Œè¦åŠƒ...")
    
    planning_system_prompt_template = """
# ==============================================================================
# == ğŸ§  ç³»çµ±æ ¸å¿ƒæŒ‡ä»¤ (è¦åŠƒæ¨¡å¼) ğŸ§ 
# ==============================================================================
# èªªæ˜ï¼šä½ æ˜¯ä¸€ä½æ“æœ‰æ¥µé«˜æ™ºæ…§å’Œå‰µé€ åŠ›çš„éŠæˆ²ç®¡ç†å¤§å¸«ï¼ˆGMï¼‰ã€‚ä½ çš„ä»»å‹™æ˜¯åˆ†ææ‰€æœ‰
#       ä¸Šä¸‹æ–‡ï¼Œç‚ºæ¥ä¸‹ä¾†çš„å›åˆåˆ¶å®šä¸€ä»½è©³ç´°ã€åˆç†çš„ã€è¡Œå‹•è¨ˆåŠƒ JSONã€‘ã€‚
#
# **ã€ã€ã€æœ€é«˜è¦åŠƒåŸå‰‡ï¼šçµ•å°éµå®ˆé¢¨æ ¼æŒ‡ä»¤ã€‘ã€‘ã€‘**
# ä½ çš„é¦–è¦ä¸”æœ€é«˜å„ªå…ˆç´šçš„ä»»å‹™æ˜¯ï¼Œç”Ÿæˆä¸€å€‹**åš´æ ¼ä¸”å®Œå…¨**æ»¿è¶³ä¸‹æ–¹ã€å…·é«”é¢¨æ ¼æŒ‡ä»¤ã€‘çš„ JSON è¨ˆç•«ã€‚
# é€™äº›æŒ‡ä»¤ä¸æ˜¯å»ºè­°ï¼Œè€Œæ˜¯ä½ å¿…é ˆåŸ·è¡Œçš„**ç¡¬æ€§ç´„æŸ**ã€‚
# ------------------------------------------------------------------------------
# **ã€å…·é«”é¢¨æ ¼æŒ‡ä»¤ (ç¡¬æ€§ç´„æŸ)ã€‘**
# - **å°è©±è¦æ±‚**: {dialogue_requirement}
# - **æ—ç™½è©³ç´°åº¦**: {narration_level}
# - **å¯é¸è¡Œå‹•å»ºè­°**: {proactive_suggestion}
# ------------------------------------------------------------------------------
{system_prompt}
"""
    style_driven_prompt = planning_system_prompt_template.format(
        dialogue_requirement=style_analysis.dialogue_requirement,
        narration_level=style_analysis.narration_level,
        proactive_suggestion=style_analysis.proactive_suggestion or "ç„¡",
        system_prompt=ai_core.profile.one_instruction or ""
    )

    structured_context = state.get('structured_context', {})
    full_context_dict = {
        "username": ai_core.profile.user_profile.name,
        "ai_name": ai_core.profile.ai_profile.name,
        "response_style_prompt": ai_core.profile.response_style_prompt or "é è¨­é¢¨æ ¼",
        "world_settings": ai_core.profile.world_settings or "æœªè¨­å®š",
        "ai_settings": ai_core.profile.ai_profile.description or "æœªè¨­å®š",
        "retrieved_context": state['rag_context'],
        **structured_context
    }
    def safe_format(template: str, data: dict) -> str:
        for key, value in data.items():
            template = template.replace(f"{{{key}}}", str(value))
        return template
    
    final_system_prompt = safe_format(style_driven_prompt, full_context_dict)
    world_snapshot = safe_format(ai_core.world_snapshot_template, full_context_dict)
    
    params_for_chain = {
        "system_prompt": final_system_prompt,
        "world_snapshot": world_snapshot,
        "user_input": user_input,
    }
    
    plan = await ai_core.ainvoke_with_rotation(
        ai_core.get_planning_chain(), 
        params_for_chain,
        retry_strategy='euphemize'
    )
    
    if not plan:
        logger.error(f"[{user_id}] SFW è¦åŠƒéˆå³ä½¿åœ¨å§”å©‰åŒ–å¾Œä¹Ÿæœ€çµ‚å¤±æ•—ã€‚")
        plan = TurnPlan(thought="å®‰å…¨å‚™æ´ï¼šè¦åŠƒéˆå¤±æ•—ã€‚", character_actions=[
            CharacterAction(
                character_name=ai_core.profile.ai_profile.name,
                reasoning="è¦åŠƒéˆå¤±æ•—ï¼Œéœ€è¦çµ¦å‡ºä¸€å€‹å®‰å…¨çš„å‚™ç”¨å›æ‡‰ã€‚",
                dialogue="æŠ±æ­‰ï¼Œä¸»äººï¼Œæˆ‘çš„æ€ç·’æœ‰äº›æ··äº‚ï¼Œå¯ä»¥è«‹æ‚¨æ›ä¸€ç¨®æ–¹å¼èªªå—ï¼Ÿ"
            )
        ])
    return {"turn_plan": plan}

async def generate_nsfw_response_node(state: ConversationGraphState) -> Dict[str, str]:
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: generate_nsfw_response_node [NSFW Path] -> æ­£åœ¨ç›´æ¥ç”Ÿæˆã€äº’å‹•å¼ã€‘NSFW å›æ‡‰...")
    structured_context = state.get('structured_context', {})
    full_context_dict = {
        "username": ai_core.profile.user_profile.name,
        "ai_name": ai_core.profile.ai_profile.name,
        "response_style_prompt": ai_core.profile.response_style_prompt or "é è¨­é¢¨æ ¼",
        "world_settings": ai_core.profile.world_settings or "æœªè¨­å®š",
        "ai_settings": ai_core.profile.ai_profile.description or "æœªè¨­å®š",
        "retrieved_context": state.get('rag_context', "ï¼ˆNSFW è·¯å¾‘ä¸åŸ·è¡Œæ·±åº¦è¨˜æ†¶æª¢ç´¢ï¼‰"),
        **structured_context
    }
    world_snapshot = ai_core.world_snapshot_template.format(**full_context_dict)

    response_text = await ai_core.ainvoke_with_rotation(
        ai_core.get_direct_nsfw_chain(),
        {"world_snapshot": world_snapshot, "user_input": user_input},
        retry_strategy='force'
    )
    if not response_text:
        response_text = "ï¼ˆAI åœ¨è™•ç†æ‚¨çš„è«‹æ±‚æ™‚é­é‡äº†ä¸å¯æ¢å¾©çš„å…§å®¹å®‰å…¨é™åˆ¶ï¼Œè«‹å˜—è©¦èª¿æ•´æ‚¨çš„æŒ‡ä»¤ã€‚ï¼‰"
    return {"llm_response": response_text}

async def remote_scene_generation_node(state: ConversationGraphState) -> Dict[str, str]:
    user_id = state['user_id']
    ai_core = state['ai_core']
    scene_analysis = state['scene_analysis']
    if not (scene_analysis and scene_analysis.target_location_path):
        logger.error(f"[{user_id}] é€²å…¥äº† remote_scene_generation_nodeï¼Œä½† scene_analysis ä¸­æ²’æœ‰ target_location_pathã€‚")
        return {"llm_response": "ï¼ˆç³»çµ±éŒ¯èª¤ï¼šç„¡æ³•ç¢ºå®šè¦è§€å¯Ÿçš„é ç¨‹ç›®æ¨™ã€‚ï¼‰"}
    target_path = scene_analysis.target_location_path
    logger.info(f"[{user_id}] (Graph) Node: remote_scene_generation_node [SFW Path] -> æ­£åœ¨ç‚ºé ç¨‹åœ°é» '{' > '.join(target_path)}' ç”Ÿæˆã€SFWã€‘å ´æ™¯...")
    remote_context = await ai_core._get_structured_context(
        user_input="", 
        override_location_path=target_path
    )
    remote_scene_context_str = "\n".join([f"ã€{k.replace('_context', '').title()}ã€‘\n{v}" for k, v in remote_context.items()])
    scene_text = await ai_core.ainvoke_with_rotation(
        ai_core.get_remote_scene_generator_chain(),
        {
            "response_style_prompt": ai_core.profile.response_style_prompt or "é è¨­é¢¨æ ¼ï¼šå¹³è¡¡çš„æ•˜äº‹èˆ‡å°è©±ã€‚",
            "world_settings": ai_core.profile.world_settings or "æœªè¨­å®š",
            "remote_scene_context": remote_scene_context_str,
        },
        retry_strategy='euphemize'
    )
    if not scene_text:
        scene_text = "ï¼ˆç”±æ–¼å…§å®¹é™åˆ¶ï¼Œç„¡æ³•ç”Ÿæˆé ç¨‹å ´æ™¯çš„è©³ç´°æè¿°ã€‚ï¼‰"
    return {"llm_response": scene_text}

async def remote_nsfw_scene_generator_node(state: ConversationGraphState) -> Dict[str, str]:
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: remote_nsfw_scene_generator_node [NSFW Path] -> æ­£åœ¨ç”Ÿæˆã€é ç¨‹NSFWã€‘å ´æ™¯...")
    remote_context = await ai_core._get_structured_context(user_input)
    remote_scene_context_str = "\n".join([f"ã€{k.replace('_context', '').title()}ã€‘\n{v}" for k, v in remote_context.items()])
    scene_text = await ai_core.ainvoke_with_rotation(
        ai_core.get_remote_nsfw_scene_generator_chain(),
        {
            "user_input": user_input,
            "world_settings": ai_core.profile.world_settings or "æœªè¨­å®š",
            "remote_scene_context": remote_scene_context_str,
            "response_style_prompt": ai_core.profile.response_style_prompt or "é è¨­é¢¨æ ¼ï¼šå¹³è¡¡çš„æ•˜äº‹èˆ‡å°è©±ã€‚",
            "username": ai_core.profile.user_profile.name,
            "ai_name": ai_core.profile.ai_profile.name,
        },
        retry_strategy='force'
    )
    if not scene_text:
        scene_text = "ï¼ˆç”±æ–¼å…§å®¹é™åˆ¶ï¼ŒAIç„¡æ³•ç”Ÿæˆæ‚¨æ‰€è¦æ±‚çš„é ç¨‹å ´æ™¯çš„è©³ç´°æè¿°ã€‚ï¼‰"
    return {"llm_response": scene_text}

async def tool_execution_node(state: ConversationGraphState) -> Dict[str, str]:
    user_id = state['user_id']
    ai_core = state['ai_core']
    plan = state['turn_plan']
    logger.info(f"[{user_id}] (Graph) Node: tool_execution_node [SFW Path] -> æ­£åœ¨åŸ·è¡Œè¡Œå‹•è¨ˆåŠƒä¸­çš„å·¥å…·...")
    if not plan or not plan.character_actions:
        return {"tool_results": "ç³»çµ±äº‹ä»¶ï¼šç„¡ä»»ä½•å·¥å…·è¢«èª¿ç”¨ã€‚"}
    try:
        results_summary = await ai_core._execute_planned_actions(plan)
    except Exception as e:
        logger.error(f"[{user_id}] (Graph) Node: tool_execution_node -> åœ¨åŸ·è¡Œå·¥å…·æ™‚ç™¼ç”Ÿæœªæ•ç²çš„ç•°å¸¸: {e}", exc_info=True)
        results_summary = f"ç³»çµ±äº‹ä»¶ï¼šå·¥å…·åŸ·è¡Œæ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}"
    finally:
        tool_context.set_context(None, None)
        logger.info(f"[{user_id}] (Graph) Node: tool_execution_node -> å·¥å…·ä¸Šä¸‹æ–‡å·²æ¸…ç†ã€‚")
    return {"tool_results": results_summary}

async def narrative_node(state: ConversationGraphState) -> Dict[str, str]:
    user_id = state['user_id']
    ai_core = state['ai_core']
    turn_plan = state['turn_plan']
    tool_results = state['tool_results']
    logger.info(f"[{user_id}] (Graph) Node: narrative_node [SFW Path] -> æ­£åœ¨å¤„ç†è¡ŒåŠ¨è®¡åˆ’...")
    if not turn_plan:
        logger.error(f"[{user_id}] å™äº‹èŠ‚ç‚¹æ¥æ”¶åˆ°ç©ºçš„è¡ŒåŠ¨è®¡åˆ’ï¼Œæ— æ³•ç”Ÿæˆå›åº”ã€‚")
        return {"llm_response": "ï¼ˆç³»ç»Ÿé”™è¯¯ï¼šæœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„è¡ŒåŠ¨è®¡åˆ’ã€‚ï¼‰"}
    if turn_plan.execution_rejection_reason:
        logger.info(f"[{user_id}] (Graph) Node: narrative_node -> æ£€æµ‹åˆ°æ‹’ç»æ‰§è¡Œçš„ç†ç”±ï¼Œå°†ç›´æ¥è¾“å‡ºã€‚ç†ç”±: {turn_plan.execution_rejection_reason}")
        return {"llm_response": turn_plan.execution_rejection_reason}
    logger.info(f"[{user_id}] (Graph) Node: narrative_node -> æ­£åœ¨å°†è¡ŒåŠ¨è®¡åˆ’å’Œå·¥å…·ç»“æœæ¸²æŸ“ä¸ºå°è¯´æ–‡æœ¬...")
    turn_plan.thought += f"\n\n[ç³»ç»Ÿåå°æ‰§è¡Œç»“æœ]:\n{tool_results}"
    narrative_text = await ai_core.ainvoke_with_rotation(
        ai_core.get_narrative_chain(),
        {"turn_plan": turn_plan},
        retry_strategy='force'
    )
    if not narrative_text:
        narrative_text = "ï¼ˆAI åœ¨å°‡è¨ˆåŠƒè½‰åŒ–ç‚ºæ•…äº‹æ™‚é­é‡äº†å…§å®¹å®‰å…¨é™åˆ¶ã€‚ï¼‰"
    return {"llm_response": narrative_text}

async def validate_and_rewrite_node(state: ConversationGraphState) -> Dict:
    user_id = state['user_id']
    initial_response = state['llm_response']
    logger.info(f"[{user_id}] (Graph) Node: validate_and_rewrite_node -> æ­£åœ¨å° LLM åŸå§‹è¼¸å‡ºé€²è¡Œå…§å®¹ä¿å…¨å¼æ·¨åŒ–...")
    if not initial_response or not initial_response.strip():
        logger.error(f"[{user_id}] æ ¸å¿ƒéˆåœ¨æ·¨åŒ–å‰è¿”å›äº†ç©ºçš„æˆ–ç„¡æ•ˆçš„å›æ‡‰ã€‚")
        return {"final_output": "ï¼ˆ...ï¼‰"}
    clean_response = initial_response
    clean_response = re.sub(r'ï¼ˆ(æ€è€ƒ|è¡Œå‹•|è‡ªæˆ‘è§€å¯Ÿ)\s*[:ï¼š\s\S]*?ï¼‰', '', clean_response)
    clean_response = re.sub(r'^\s*(æ—ç™½|å°è©±)\s*[:ï¼š]\s*', '', clean_response, flags=re.MULTILINE)
    if 'æ—ç™½:' in clean_response or 'å°è©±:' in clean_response:
        logger.warning(f"[{user_id}] æª¢æ¸¬åˆ°éæ¨™æº–æ ¼å¼çš„æ¨™ç±¤æ´©æ¼ï¼Œå•Ÿå‹•å‚™æ´æ¸…ç†ã€‚")
        clean_response = clean_response.replace('æ—ç™½:', '').replace('å°è©±:', '')
        clean_response = clean_response.replace('æ—ç™½ï¼š', '').replace('å°è©±ï¼š', '')
    final_response = clean_response.strip()
    if not final_response:
        logger.warning(f"[{user_id}] LLM åŸå§‹è¼¸å‡ºåœ¨æ·¨åŒ–å¾Œç‚ºç©ºã€‚åŸå§‹è¼¸å‡ºç‚º: '{initial_response[:200]}...'")
        return {"final_output": "ï¼ˆ...ï¼‰"}
    return {"final_output": final_response}

async def persist_state_node(state: ConversationGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    clean_response = state['final_output']
    logger.info(f"[{user_id}] (Graph) Node: persist_state_node -> æ­£åœ¨æŒä¹…åŒ–ç‹€æ…‹èˆ‡è¨˜æ†¶...")
    if clean_response and clean_response != "ï¼ˆ...ï¼‰":
        chat_history_manager = ai_core.session_histories.get(user_id)
        if chat_history_manager:
            chat_history_manager.add_user_message(user_input)
            chat_history_manager.add_ai_message(clean_response)
        last_interaction_text = f"ä½¿ç”¨è€… '{ai_core.profile.user_profile.name}' èªª: {user_input}\n\n[å ´æ™¯å›æ‡‰]:\n{clean_response}"
        tasks = []
        tasks.append(ai_core._generate_and_save_personal_memory(last_interaction_text))
        if ai_core.vector_store:
            tasks.append(asyncio.to_thread(ai_core.vector_store.add_texts, [last_interaction_text], metadatas=[{"source": "history"}]))
        async def save_to_sql():
            from .database import AsyncSessionLocal, MemoryData
            import time
            timestamp = time.time()
            async with AsyncSessionLocal() as session:
                session.add(MemoryData(user_id=user_id, content=last_interaction_text, timestamp=timestamp, importance=1))
                await session.commit()
        tasks.append(save_to_sql())
        await asyncio.gather(*tasks, return_exceptions=True)
    return {}

async def finalization_node(state: ConversationGraphState) -> Dict:
    user_id = state['user_id']
    logger.info(f"[{user_id}] (Graph) Node: finalization_node -> å°è©±æµç¨‹åœ–åŸ·è¡Œå®Œç•¢ã€‚")
    return {}

# --- ä¸»å°è©±åœ–çš„è·¯ç”± ---

async def route_to_final_generator(state: ConversationGraphState) -> Literal["sfw_path", "nsfw_interactive_path", "nsfw_descriptive_path"]:
    """åœ¨æ‰€æœ‰é€šç”¨é è™•ç†å®Œæˆå¾Œï¼Œæ ¹æ“šæ„åœ–åˆ†é¡å°‡æµç¨‹åˆ†ç™¼åˆ°æœ€çµ‚çš„ç”Ÿæˆå™¨ã€‚"""
    intent = state['intent_classification'].intent_type
    user_id = state['user_id']
    logger.info(f"[{user_id}] (Graph) Router: æœ€çµ‚ç”Ÿæˆè·¯ç”±å™¨æ ¹æ“šæ„åœ– '{intent}' é€²è¡Œåˆ†ç™¼ã€‚")
    if intent == 'nsfw_interactive':
        return "nsfw_interactive_path"
    elif intent == 'nsfw_descriptive':
        return "nsfw_descriptive_path"
    else: # 'sfw'
        return "sfw_path"

def route_expansion_decision(state: ConversationGraphState) -> Literal["expand_lore", "continue_without_expansion"]:
    """æ ¹æ“šLOREæ“´å±•æ±ºç­–ï¼Œæ±ºå®šæ˜¯å¦é€²å…¥å°ˆç”¨çš„LOREæ“´å±•ç¯€é»ã€‚"""
    user_id = state['user_id']
    should_expand = state.get("expansion_decision")
    if should_expand and should_expand.should_expand:
        logger.info(f"[{user_id}] (Graph) Router: LOREæ“´å±•æ±ºç­–ç‚ºæ˜¯ï¼Œé€²å…¥ lore_expansion_nodeã€‚")
        return "expand_lore"
    else:
        logger.info(f"[{user_id}] (Graph) Router: LOREæ“´å±•æ±ºç­–ç‚ºå¦ï¼Œè·³é LORE æ“´å±•ã€‚")
        return "continue_without_expansion"

def route_viewing_mode(state: ConversationGraphState) -> Literal["remote_scene", "local_scene"]:
    """æ ¹æ“šè¦–è§’åˆ†æçµæœï¼Œæ±ºå®šæ˜¯ç”Ÿæˆé ç¨‹å ´æ™¯é‚„æ˜¯ç¹¼çºŒæœ¬åœ°æµç¨‹ã€‚"""
    user_id = state['user_id']
    scene_analysis = state.get("scene_analysis")
    if scene_analysis and scene_analysis.viewing_mode == 'remote':
        logger.info(f"[{user_id}] (Graph) Router: è¦–è§’åˆ†æç‚ºé ç¨‹ï¼Œé€²å…¥ remote_scene_generationã€‚")
        return "remote_scene"
    else:
        logger.info(f"[{user_id}] (Graph) Router: è¦–è§’åˆ†æç‚ºæœ¬åœ°ï¼Œç¹¼çºŒä¸»æµç¨‹ã€‚")
        return "local_scene"

# --- ä¸»å°è©±åœ–çš„å»ºæ§‹å™¨ ---

# å‡½å¼ï¼šå‰µå»ºä¸»å›æ‡‰åœ– (v19.0 - LORE çµ±ä¸€æ¶æ§‹æœ€çµ‚ç‰ˆ)
def create_main_response_graph() -> StateGraph:
    graph = StateGraph(ConversationGraphState)
    
    # --- 1. è¨»å†Šæ‰€æœ‰ç¯€é» ---
    graph.add_node("classify_intent", classify_intent_node)
    
    # é€šç”¨é è™•ç†ç¯€é»
    graph.add_node("initialize_state", initialize_conversation_state_node)
    graph.add_node("analyze_input", analyze_input_node)
    graph.add_node("expansion_decision", expansion_decision_node)
    graph.add_node("lore_expansion", lore_expansion_node)
    
    # SFW å°ˆç”¨è·¯å¾‘ç¯€é»
    graph.add_node("scene_and_action_analysis", scene_and_action_analysis_node)
    graph.add_node("style_analysis", style_analysis_node)
    graph.add_node("remote_scene_generation", remote_scene_generation_node)
    graph.add_node("planning", planning_node)
    graph.add_node("tool_execution", tool_execution_node)
    graph.add_node("narrative", narrative_node)
    
    # NSFW å°ˆç”¨è·¯å¾‘ç¯€é»
    graph.add_node("generate_nsfw_response", generate_nsfw_response_node)
    graph.add_node("remote_nsfw_scene_generation", remote_nsfw_scene_generator_node)
    
    # å…±åŒæ”¶å°¾ç¯€é»
    graph.add_node("validate_and_rewrite", validate_and_rewrite_node)
    graph.add_node("persist_state", persist_state_node)
    graph.add_node("finalization", finalization_node)

    # --- 2. å®šç¾©åœ–çš„æ‹“æ’²çµæ§‹ ---
    
    graph.set_entry_point("classify_intent")
    
    # [v19.0 æ ¸å¿ƒä¿®æ­£] å»ºç«‹çµ±ä¸€çš„é è™•ç†æµç¨‹
    graph.add_edge("classify_intent", "initialize_state")
    graph.add_edge("initialize_state", "analyze_input")
    graph.add_edge("analyze_input", "expansion_decision")
    graph.add_conditional_edges(
        "expansion_decision",
        route_expansion_decision,
        {
            "expand_lore": "lore_expansion",
            "continue_without_expansion": "route_to_final_generator" # è·³éæ“´å±•ï¼Œç›´æ¥é€²å…¥æœ€çµ‚è·¯ç”±
        }
    )
    graph.add_edge("lore_expansion", "route_to_final_generator") # æ“´å±•å®Œæˆå¾Œï¼Œä¹Ÿé€²å…¥æœ€çµ‚è·¯ç”±

    # [v19.0 æ ¸å¿ƒä¿®æ­£] å‰µå»ºæ–°çš„æœ€çµ‚ç”Ÿæˆè·¯ç”±å™¨
    graph.add_node("route_to_final_generator", route_to_final_generator) # è¨»å†Šè·¯ç”±å™¨ç¯€é»æœ¬èº«
    graph.add_conditional_edges(
        "route_to_final_generator",
        route_to_final_generator, # ä½¿ç”¨è·¯ç”±å‡½å¼
        {
            "sfw_path": "scene_and_action_analysis",
            "nsfw_interactive_path": "generate_nsfw_response",
            "nsfw_descriptive_path": "remote_nsfw_scene_generation"
        }
    )
    
    # å®šç¾© SFW è·¯å¾‘çš„å…§éƒ¨æµç¨‹
    graph.add_conditional_edges(
        "scene_and_action_analysis",
        route_viewing_mode,
        {
            "remote_scene": "remote_scene_generation",
            "local_scene": "style_analysis"
        }
    )
    graph.add_edge("style_analysis", "planning")
    graph.add_edge("planning", "tool_execution")
    graph.add_edge("tool_execution", "narrative")
    
    # å°‡æ‰€æœ‰ç”Ÿæˆè·¯å¾‘çš„çµ‚é»åŒ¯åˆåˆ°é©—è­‰ç¯€é»
    graph.add_edge("generate_nsfw_response", "validate_and_rewrite")
    graph.add_edge("remote_nsfw_scene_generation", "validate_and_rewrite")
    graph.add_edge("remote_scene_generation", "validate_and_rewrite")
    graph.add_edge("narrative", "validate_and_rewrite")
    
    # é€£æ¥å…±åŒçš„æ”¶å°¾æµç¨‹
    graph.add_edge("validate_and_rewrite", "persist_state")
    graph.add_edge("persist_state", "finalization")
    graph.add_edge("finalization", END)
    
    return graph.compile()
# å‡½å¼ï¼šå‰µå»ºä¸»å›æ‡‰åœ– (v19.0 - LORE çµ±ä¸€æ¶æ§‹æœ€çµ‚ç‰ˆ)

# --- è¨­å®šåœ– (Setup Graph) çš„ç¯€é» ---
async def process_canon_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    canon_text = state['canon_text']
    if canon_text:
        await ai_core.add_canon_to_vector_store(canon_text)
        await ai_core.parse_and_create_lore_from_canon(None, canon_text, is_setup_flow=True)
    return {}

async def complete_profiles_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    logger.info(f"[{user_id}] (Setup Graph) Node: complete_profiles_node -> æ­£åœ¨è£œå®Œè§’è‰²æª”æ¡ˆ...")
    completion_chain = ai_core.get_profile_completion_chain()
    if not ai_core.profile:
        logger.error(f"[{user_id}] åœ¨ complete_profiles_node ä¸­ ai_core.profile ç‚ºç©ºï¼Œç„¡æ³•ç¹¼çºŒã€‚")
        return {}
    completed_user_profile = await ai_core.ainvoke_with_rotation(completion_chain, {"profile_json": ai_core.profile.user_profile.model_dump_json()}, retry_strategy='euphemize')
    completed_ai_profile = await ai_core.ainvoke_with_rotation(completion_chain, {"profile_json": ai_core.profile.ai_profile.model_dump_json()}, retry_strategy='euphemize')
    update_payload = {}
    if completed_user_profile:
        update_payload['user_profile'] = completed_user_profile.model_dump()
    if completed_ai_profile:
        update_payload['ai_profile'] = completed_ai_profile.model_dump()
    if update_payload:
        await ai_core.update_and_persist_profile(update_payload)
    return {}

async def world_genesis_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    genesis_chain = ai_core.get_world_genesis_chain()
    genesis_result = await ai_core.ainvoke_with_rotation(genesis_chain, {"world_settings": ai_core.profile.world_settings, "username": ai_core.profile.user_profile.name, "ai_name": ai_core.profile.ai_profile.name}, retry_strategy='force')
    if not genesis_result:
        raise Exception("ä¸–ç•Œå‰µä¸–éˆè¿”å›äº†ç©ºçµæœï¼Œå¯èƒ½æ˜¯å…§å®¹å¯©æŸ¥ã€‚")
    gs = ai_core.profile.game_state
    gs.location_path = genesis_result.location_path
    await ai_core.update_and_persist_profile({'game_state': gs.model_dump()})
    await lore_book.add_or_update_lore(user_id, 'location_info', " > ".join(genesis_result.location_path), genesis_result.location_info.model_dump())
    for npc in genesis_result.initial_npcs:
        npc_key = " > ".join(genesis_result.location_path) + f" > {npc.name}"
        await ai_core.db_add_or_update_lore(user_id, 'npc_profile', npc_key, npc.model_dump())
    return {"genesis_result": genesis_result}

async def generate_opening_scene_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    opening_scene = await ai_core.generate_opening_scene()
    if not opening_scene or not opening_scene.strip():
        opening_scene = (f"åœ¨ä¸€ç‰‡æŸ”å’Œçš„å…‰èŠ’ä¸­ï¼Œä½ å’Œ {ai_core.profile.ai_profile.name} ç™¼ç¾è‡ªå·±èº«è™•æ–¼ä¸€å€‹å¯§éœçš„ç©ºé–“è£¡...")
    return {"opening_scene": opening_scene}

def create_setup_graph() -> StateGraph:
    graph = StateGraph(SetupGraphState)
    graph.add_node("process_canon", process_canon_node)
    graph.add_node("complete_profiles", complete_profiles_node)
    graph.add_node("world_genesis", world_genesis_node)
    graph.add_node("generate_opening_scene", generate_opening_scene_node)
    graph.set_entry_point("process_canon")
    graph.add_edge("process_canon", "complete_profiles")
    graph.add_edge("complete_profiles", "world_genesis")
    graph.add_edge("world_genesis", "generate_opening_scene")
    graph.add_edge("generate_opening_scene", END)
    return graph.compile()
# å‡½å¼ï¼šå‰µå»ºè¨­å®šåœ–
