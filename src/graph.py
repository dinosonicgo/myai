# src/graph.py çš„ä¸­æ–‡è¨»é‡‹(v22.2 - æœ€ç»ˆå®Œæ•´æ€§ä¿®å¤)
# æ›´æ–°ç´€éŒ„:
# v22.2 (2025-09-22): [ç½é›£æ€§BUGä¿®å¾©] æ¢å¤äº†åœ¨ v19.1 ä¿®å¤ä¸­è¢«æ„å¤–è¦†ç›–åˆ é™¤çš„ `direct_nsfw_node` å‡½å¼çš„å®šä¹‰ã€‚æ­¤ä¿®æ”¹ç¡®ä¿äº†å›¾ä¸­æ‰€æœ‰è¢«å¼•ç”¨çš„èŠ‚ç‚¹ï¼ˆåŒ…æ‹¬ `direct_nsfw_node` å’Œ `purification_node`ï¼‰éƒ½æ‹¥æœ‰å…¶å¯¹åº”çš„å‡½æ•°å®žçŽ°ï¼Œä»Žè€Œå½»åº•è§£å†³æ‰€æœ‰ NameError å¯åŠ¨å¤±è´¥é—®é¢˜ã€‚
# v22.1 (2025-09-22): [ç½é›£æ€§BUGä¿®å¾©] æ¢å¤äº†åœ¨ v16.0 ä¸­è¢«é”™è¯¯ç§»é™¤çš„ `purification_node` å‡½å¼çš„å®šä¹‰ã€‚
# v22.0 (2025-09-22): [ç½é›£æ€§BUGä¿®å¾©] è§£å†³äº†å› é‡å‘½åæ¸²æŸ“èŠ‚ç‚¹å¯¼è‡´çš„ NameErrorã€‚
import sys
print(f"[DEBUG] graph.py loaded from: {__file__}", file=sys.stderr)
import asyncio
import json
import re
from typing import Dict, List, Literal, Optional, Any

from langchain_core.messages import HumanMessage
from langchain_community.chat_message_histories import ChatMessageHistory
from langgraph.graph import StateGraph, END

from .ai_core import AILover
from .logger import logger
from .graph_state import ConversationGraphState, SetupGraphState
from . import lore_book, tools
from .schemas import (CharacterProfile, TurnPlan, ExpansionDecision, 
                      UserInputAnalysis, SceneAnalysisResult, SceneCastingResult, 
                      WorldGenesisResult, IntentClassificationResult, StyleAnalysisResult,
                      CharacterQuantificationResult)
from .tool_context import tool_context

# --- ä¸»å°è©±åœ– (Main Conversation Graph) çš„ç¯€é»ž ---

async def classify_intent_node(state: ConversationGraphState) -> Dict:
    """[1] åœ–çš„å…¥å£é»žï¼Œå°è¼¸å…¥è¿›è¡Œæ„å›¾åˆ†ç±»ï¼Œå¹¶èƒ½å¤„ç†å»¶ç»­æ€§æŒ‡ä»¤ä»¥ç»§æ‰¿æŒä¹…åŒ–çš„çŠ¶æ€ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    
    logger.info(f"[{user_id}] (Graph|1) Node: classify_intent -> æ­£åœ¨é€²è¡Œåˆæ­¥è¼¸å…¥é¡žåž‹åˆ†æž...")
    input_analysis_chain = ai_core.get_input_analysis_chain()
    input_analysis_result = await ai_core.ainvoke_with_rotation(
        input_analysis_chain,
        {"user_input": user_input},
        retry_strategy='euphemize'
    )
    
    if input_analysis_result and input_analysis_result.input_type == 'continuation':
        if ai_core.profile and ai_core.profile.game_state.last_intent_type:
            last_intent_type = ai_core.profile.game_state.last_intent_type
            logger.info(f"[{user_id}] (Graph|1) æª¢æ¸¬åˆ°å»¶ç»­æ€§æŒ‡ä»¤ï¼Œå·²å¾žã€æŒä¹…åŒ– GameStateã€‘ç¹¼æ‰¿æ„å›¾: '{last_intent_type}'")
            
            inherited_intent = IntentClassificationResult(
                intent_type=last_intent_type,
                reasoning=f"å¾žæŒä¹…åŒ–ç‹€æ…‹ç¹¼æ‰¿äº†ä¸Šä¸€è¼ªçš„ '{last_intent_type}' æ„åœ–ã€‚"
            )
            return {
                "intent_classification": inherited_intent,
                "input_analysis": input_analysis_result
            }
        else:
            logger.warning(f"[{user_id}] (Graph|1) æª¢æ¸¬åˆ°å»¶ç»­æ€§æŒ‡ä»¤ï¼Œä½† GameState ä¸­æ²’æœ‰æ„å›¾å¯ä¾›ç»§æ‰¿ï¼Œå°†æŒ‰å¸¸è§„æµç¨‹å¤„ç†ã€‚")

    logger.info(f"[{user_id}] (Graph|1) æ­£åœ¨å¯¹å…·ä½“æŒ‡ä»¤ '{user_input[:30]}...' é€²è¡Œæ„åœ–åˆ†é¡ž...")
    classification_chain = ai_core.get_intent_classification_chain()
    classification_result = await ai_core.ainvoke_with_rotation(
        classification_chain,
        {"user_input": user_input},
        retry_strategy='euphemize'
    )
    
    if not classification_result:
        logger.warning(f"[{user_id}] (Graph|1) æ„åœ–åˆ†é¡žéˆå¤±æ•—ï¼Œå•Ÿå‹•å®‰å…¨å‚™æ´ï¼Œé è¨­ç‚º SFWã€‚")
        classification_result = IntentClassificationResult(intent_type='sfw', reasoning="å®‰å…¨å‚™æ´ï¼šåˆ†é¡žéˆå¤±æ•—ã€‚")
        
    return {
        "intent_classification": classification_result,
        "input_analysis": input_analysis_result
    }

async def retrieve_memories_node(state: ConversationGraphState) -> Dict:
    """[2] å°ˆç”¨è¨˜æ†¶æª¢ç´¢ç¯€é»žï¼ŒåŸ·è¡ŒRAGæ“ä½œã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input_for_retrieval = state['messages'][-1].content
    
    logger.info(f"[{user_id}] (Graph|2) Node: retrieve_memories -> æ­£åœ¨åŸºæ–¼åŽŸå§‹æŸ¥è©¢ '{user_input_for_retrieval[:30]}...' æª¢ç´¢ç›¸é—œé•·æœŸè¨˜æ†¶...")
    
    rag_context_str = await ai_core.retrieve_and_summarize_memories(user_input_for_retrieval)
    return {"rag_context": rag_context_str}

async def query_lore_node(state: ConversationGraphState) -> Dict:
    """[3] å°ˆç”¨LOREæŸ¥è©¢ç¯€é»žï¼Œå¾žè³‡æ–™åº«ç²å–èˆ‡ç•¶å‰è¼¸å…¥å’Œã€æ•´å€‹å ´æ™¯ã€‘ç›¸é—œçš„æ‰€æœ‰ã€éžä¸»è§’ã€‘LOREå°è±¡ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph|3) Node: query_lore -> æ­£åœ¨åŸ·è¡Œã€ä¸Šä¸‹æ–‡å„ªå…ˆã€‘çš„LOREæŸ¥è©¢...")

    if not ai_core.profile:
        logger.error(f"[{user_id}] (LORE Querier) ai_core.profile æœªåŠ è¼‰ï¼Œç„¡æ³•æŸ¥è©¢LOREã€‚")
        return {"raw_lore_objects": []}

    gs = ai_core.profile.game_state
    
    effective_location_path: List[str]
    if gs.viewing_mode == 'remote' and gs.remote_target_path:
        effective_location_path = gs.remote_target_path
    else:
        effective_location_path = gs.location_path
    
    logger.info(f"[{user_id}] (LORE Querier) å·²éŽ–å®šæœ‰æ•ˆå ´æ™¯: {' > '.join(effective_location_path)}")

    lores_in_scene = await lore_book.get_lores_by_category_and_filter(
        user_id,
        'npc_profile',
        lambda c: c.get('location_path') == effective_location_path
    )
    logger.info(f"[{user_id}] (LORE Querier) åœ¨æœ‰æ•ˆå ´æ™¯ä¸­æ‰¾åˆ° {len(lores_in_scene)} ä½å¸¸é§NPCã€‚")

    is_remote = gs.viewing_mode == 'remote'
    lores_from_input = await ai_core._query_lore_from_entities(user_input, is_remote_scene=is_remote)
    logger.info(f"[{user_id}] (LORE Querier) å¾žä½¿ç”¨è€…è¼¸å…¥ä¸­æå–ä¸¦æŸ¥è©¢åˆ° {len(lores_from_input)} æ¢ç›¸é—œLOREã€‚")

    final_lores_map = {lore.key: lore for lore in lores_in_scene}
    for lore in lores_from_input:
        if lore.key not in final_lores_map:
            final_lores_map[lore.key] = lore
            
    protected_names = {
        ai_core.profile.user_profile.name.lower(),
        ai_core.profile.ai_profile.name.lower()
    }
    
    filtered_lores_list = []
    for lore in final_lores_map.values():
        lore_name = lore.content.get('name', '').lower()
        if lore_name not in protected_names:
            filtered_lores_list.append(lore)
        else:
            logger.warning(f"[{user_id}] (LORE Querier) å·²éŽæ¿¾æŽ‰èˆ‡æ ¸å¿ƒä¸»è§’åŒåçš„LOREè¨˜éŒ„: '{lore.content.get('name')}'")

    logger.info(f"[{user_id}] (LORE Querier) ç¶“éŽä¸Šä¸‹æ–‡å„ªå…ˆåˆä½µèˆ‡éŽæ¿¾å¾Œï¼Œå…±éŽ–å®š {len(filtered_lores_list)} æ¢LOREä½œç‚ºæœ¬å›žåˆä¸Šä¸‹æ–‡ã€‚")
    
    return {"raw_lore_objects": filtered_lores_list}

async def perceive_and_set_view_node(state: ConversationGraphState) -> Dict:
    """ä¸€å€‹çµ±ä¸€çš„ç¯€é»žï¼Œè² è²¬åˆ†æžå ´æ™¯ã€æ ¹æ“šæ„åœ–è¨­å®šè¦–è§’ã€ä¸¦æŒä¹…åŒ–ç‹€æ…‹ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    intent = state['intent_classification'].intent_type
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: perceive_and_set_view -> æ­£åœ¨åŸºæ–¼æ„åœ– '{intent}' çµ±ä¸€è™•ç†æ„ŸçŸ¥èˆ‡è¦–è§’...")

    if not ai_core.profile:
        return {"scene_analysis": SceneAnalysisResult(viewing_mode='local', reasoning='éŒ¯èª¤ï¼šAI profile æœªåŠ è¼‰ã€‚', action_summary=user_input)}

    gs = ai_core.profile.game_state
    new_viewing_mode = gs.viewing_mode
    new_target_path = gs.remote_target_path

    if 'descriptive' in intent:
        logger.info(f"[{user_id}] (View Mode) æª¢æ¸¬åˆ°æè¿°æ€§æ„åœ–ï¼Œæº–å‚™é€²å…¥/æ›´æ–°é ç¨‹è¦–è§’ã€‚")
        
        scene_context_lores = [lore.content for lore in state.get('raw_lore_objects', []) if lore.category == 'npc_profile']
        scene_context_json_str = json.dumps(scene_context_lores, ensure_ascii=False, indent=2)
        
        location_chain = ai_core.get_contextual_location_chain()
        location_result = await ai_core.ainvoke_with_rotation(
            location_chain, 
            {
                "user_input": user_input,
                "world_settings": ai_core.profile.world_settings or "æœªè¨­å®š",
                "scene_context_json": scene_context_json_str
            }
        )
        
        extracted_path = location_result.location_path if location_result else None
        
        if extracted_path:
            new_viewing_mode = 'remote'
            new_target_path = extracted_path
        else:
            logger.warning(f"[{user_id}] (Perception Hub) æè¿°æ€§æ„åœ–æœªèƒ½æŽ¨æ–·å‡ºæœ‰æ•ˆåœ°é»žï¼Œå°‡å›žé€€åˆ°æœ¬åœ°æ¨¡å¼ã€‚")
            new_viewing_mode = 'local'
            new_target_path = None
            
    else:
        new_viewing_mode = 'local'
        new_target_path = None

    if gs.viewing_mode != new_viewing_mode or gs.remote_target_path != new_target_path:
        gs.viewing_mode = new_viewing_mode
        gs.remote_target_path = new_target_path
        await ai_core.update_and_persist_profile({'game_state': gs.model_dump()})
        logger.info(f"[{user_id}] (Perception Hub) GameState å·²æ›´æ–°: mode={gs.viewing_mode}, path={gs.remote_target_path}")
    else:
        logger.info(f"[{user_id}] (Perception Hub) GameState ç„¡éœ€æ›´æ–°ã€‚")

    scene_analysis = SceneAnalysisResult(
        viewing_mode=gs.viewing_mode,
        reasoning=f"åŸºæ–¼æ„åœ– '{intent}' çš„çµ±ä¸€æ„ŸçŸ¥çµæžœã€‚",
        target_location_path=gs.remote_target_path,
        focus_entity=None,
        action_summary=user_input
    )
    
    return {"scene_analysis": scene_analysis, "structured_context": ai_core._assemble_context_from_lore(state['raw_lore_objects'], is_remote_scene=(gs.viewing_mode == 'remote'))}

async def expansion_decision_node(state: ConversationGraphState) -> Dict:
    """[5] LOREæ“´å±•æ±ºç­–ç¯€é»žï¼ŒåŸºæ–¼å ´æ™¯ä¸­æ˜¯å¦å·²æœ‰åˆé©è§’è‰²ä¾†åšæ±ºå®šã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    raw_lore_objects = state.get('raw_lore_objects', [])
    logger.info(f"[{user_id}] (Graph|5) Node: expansion_decision -> æ­£åœ¨åŸºæ–¼èªžæ„åŒ¹é…ï¼Œåˆ¤æ–·æ˜¯å¦æ“´å±•...")
    
    lightweight_lore_for_decision = []
    for lore in raw_lore_objects:
        if lore.category == 'npc_profile':
            content = lore.content
            lightweight_lore_for_decision.append({
                "name": content.get("name"),
                "gender": content.get("gender"),
                "description": content.get("description")
            })

    lore_json_str = json.dumps(lightweight_lore_for_decision, ensure_ascii=False, indent=2)
    
    logger.info(f"[{user_id}] (Graph|5) æ³¨å…¥æ±ºç­–éˆçš„ã€è¼•é‡åŒ–ã€‘ç¾æœ‰è§’è‰²JSON:\n{lore_json_str}")

    examples_str = """
- **æƒ…å¢ƒ 1**: 
    - ç¾æœ‰è§’è‰²JSON: `[{"name": "æµ·å¦–åŸ", "description": "ä¸€ä½è²©è³£æ´»é­šçš„å¥³æ€§æ€§ç¥žæ•™å¾’..."}]`
    - ä½¿ç”¨è€…è¼¸å…¥: `ç¹¼çºŒæè¿°é‚£å€‹è³£é­šçš„å¥³äºº`
    - **ä½ çš„æ±ºç­–**: `should_expand: false` (ç†ç”±æ‡‰é¡žä¼¼æ–¼: å ´æ™¯ä¸­å·²å­˜åœ¨ç¬¦åˆ 'è³£é­šçš„å¥³äºº' æè¿°çš„è§’è‰² (ä¾‹å¦‚ 'æµ·å¦–åŸ')ï¼Œæ‡‰å„ªå…ˆèˆ‡å…¶äº’å‹•ã€‚)
- **æƒ…å¢ƒ 2**:
    - ç¾æœ‰è§’è‰²JSON: `[{"name": "æµ·å¦–åŸ", "description": "ä¸€ä½å¥³æ€§æ€§ç¥žæ•™å¾’..."}]`
    - ä½¿ç”¨è€…è¼¸å…¥: `é€™æ™‚ä¸€å€‹è¡›å…µèµ°äº†éŽä¾†`
    - **ä½ çš„æ±ºç­–**: `should_expand: true` (ç†ç”±æ‡‰é¡žä¼¼æ–¼: å ´æ™¯ä¸­ç¼ºä¹èƒ½å¤ æ‰®æ¼” 'è¡›å…µ' çš„è§’è‰²ï¼Œéœ€è¦å‰µå»ºæ–°è§’è‰²ä»¥éŸ¿æ‡‰æŒ‡ä»¤ã€‚)
"""

    decision_chain = ai_core.get_expansion_decision_chain()
    decision = await ai_core.ainvoke_with_rotation(
        decision_chain, 
        {
            "user_input": user_input, 
            "existing_characters_json": lore_json_str,
            "examples": examples_str
        },
        retry_strategy='euphemize'
    )

    if not decision:
        logger.warning(f"[{user_id}] (Graph|5) LOREæ“´å±•æ±ºç­–éˆå¤±æ•—ï¼Œå®‰å…¨å‚™æ´ç‚ºä¸æ“´å±•ã€‚")
        decision = ExpansionDecision(should_expand=False, reasoning="å®‰å…¨å‚™æ´ï¼šæ±ºç­–éˆå¤±æ•—ã€‚")
    
    logger.info(f"[{user_id}] (Graph|5) LOREæ“´å±•æ±ºç­–: {decision.should_expand}ã€‚ç†ç”±: {decision.reasoning}")
    return {"expansion_decision": decision}

async def character_quantification_node(state: ConversationGraphState) -> Dict:
    """[6A.1] å°‡æ¨¡ç³Šçš„ç¾¤é«”æè¿°è½‰åŒ–ç‚ºå…·é«”çš„è§’è‰²åˆ—è¡¨ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph|6A.1) Node: character_quantification -> æ­£åœ¨é‡åŒ–è¼¸å…¥ä¸­çš„è§’è‰²...")

    quantification_chain = ai_core.get_character_quantification_chain()
    quantification_result = await ai_core.ainvoke_with_rotation(
        quantification_chain,
        {"user_input": user_input},
        retry_strategy='euphemize'
    )

    if not quantification_result or not quantification_result.character_descriptions:
        logger.warning(f"[{user_id}] (Graph|6A.1) è§’è‰²é‡åŒ–éˆå¤±æ•—æˆ–è¿”å›žç©ºåˆ—è¡¨ï¼ŒLOREæ“´å±•å°‡è¢«è·³éŽã€‚")
        return {"quantified_character_list": []}
    
    logger.info(f"[{user_id}] (Graph|6A.1) è§’è‰²é‡åŒ–æˆåŠŸï¼Œè­˜åˆ¥å‡º {len(quantification_result.character_descriptions)} å€‹å¾…å‰µå»ºè§’è‰²ã€‚")
    return {"quantified_character_list": quantification_result.character_descriptions}

async def lore_expansion_node(state: ConversationGraphState) -> Dict:
    """[6A.2] å°ˆç”¨çš„LOREæ“´å±•åŸ·è¡Œç¯€é»žï¼Œç‚ºé‡åŒ–å¾Œçš„è§’è‰²åˆ—è¡¨å‰µå»ºæª”æ¡ˆã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    existing_lores = state.get('raw_lore_objects', [])
    quantified_character_list = state.get('quantified_character_list', [])
    
    logger.info(f"[{user_id}] (Graph|6A.2) Node: lore_expansion -> æ­£åœ¨ç‚º {len(quantified_character_list)} å€‹é‡åŒ–è§’è‰²åŸ·è¡Œé¸è§’...")
    
    if not quantified_character_list:
        logger.info(f"[{user_id}] (Graph|6A.2) é‡åŒ–è§’è‰²åˆ—è¡¨ç‚ºç©ºï¼Œè·³éŽLOREæ“´å±•ã€‚")
        planning_subjects = [lore.content for lore in existing_lores if lore.category == 'npc_profile']
        return {"planning_subjects": planning_subjects}

    if not ai_core.profile:
        logger.error(f"[{user_id}] (Graph|6A.2) ai_core.profile æœªåŠ è¼‰ï¼Œè·³éŽ LORE æ“´å±•ã€‚")
        return {}

    gs = ai_core.profile.game_state
    effective_location_path = gs.remote_target_path if gs.viewing_mode == 'remote' and gs.remote_target_path else gs.location_path

    cast_result = await ai_core.ainvoke_with_rotation(
        ai_core.get_scene_casting_chain(),
        {
            "world_settings": ai_core.profile.world_settings or "", 
            "current_location_path": effective_location_path,
            "character_descriptions_list": quantified_character_list
        },
        retry_strategy='euphemize'
    )
    
    if cast_result and cast_result.implied_location:
        location_info = cast_result.implied_location
        base_path = [gs.location_path[0]] if gs.location_path else ["æœªçŸ¥å€åŸŸ"]
        new_location_path = base_path + [location_info.name]
        lore_key = " > ".join(new_location_path)
        
        await lore_book.add_or_update_lore(user_id, 'location_info', lore_key, location_info.model_dump())
        logger.info(f"[{user_id}] (Scene Anchor) å·²æˆåŠŸç‚ºå ´æ™¯éŒ¨å®šä¸¦å‰µå»ºæ–°åœ°é»žLORE: '{lore_key}'")
        
        gs.viewing_mode = 'remote'
        gs.remote_target_path = new_location_path
        await ai_core.update_and_persist_profile({'game_state': gs.model_dump()})
        logger.info(f"[{user_id}] (Scene Anchor) GameState å·²å¼·åˆ¶æ›´æ–°ç‚ºé ç¨‹è¦–è§’ï¼Œç›®æ¨™: {new_location_path}")

    planning_subjects = [lore.content for lore in existing_lores if lore.category == 'npc_profile']
    
    if cast_result and (cast_result.newly_created_npcs or cast_result.supporting_cast):
        created_names = await ai_core._add_cast_to_scene(cast_result)
        logger.info(f"[{user_id}] (Graph|6A.2) é¸è§’å®Œæˆï¼Œå‰µå»ºäº† {len(created_names)} ä½æ–°è§’è‰²: {', '.join(created_names)}.")
        
        if created_names:
            newly_created_lores = await lore_book.get_lores_by_category_and_filter(user_id, 'npc_profile', lambda c: c.get('name') in created_names)
            if newly_created_lores:
                planning_subjects.extend([lore.content for lore in newly_created_lores])
    
    logger.info(f"[{user_id}] (Graph|6A.2) å·²å°‡ {len(planning_subjects)} ä½è§’è‰² (æ–°èˆŠåˆä½µ) æˆåŠŸç¶å®šç‚ºæœ¬å›žåˆçš„è¦åŠƒä¸»é«”ã€‚")
    return {"planning_subjects": planning_subjects}

async def sfw_planning_node(state: ConversationGraphState) -> Dict[str, TurnPlan]:
    """[7A] SFWè·¯å¾‘å°ˆç”¨è¦åŠƒå™¨ï¼Œç”Ÿæˆçµæ§‹åŒ–è¡Œå‹•è¨ˆåŠƒã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph|7A) Node: sfw_planning -> æ­£åœ¨åŸºæ–¼æŒ‡ä»¤ '{user_input[:50]}...' ç”ŸæˆSFWè¡Œå‹•è¨ˆåŠƒ...")

    if not ai_core.profile:
        return {"turn_plan": TurnPlan(execution_rejection_reason="éŒ¯èª¤ï¼šAI profile æœªåŠ è¼‰ï¼Œç„¡æ³•è¦åŠƒã€‚")}

    planning_subjects_raw = state.get('planning_subjects')
    if planning_subjects_raw is None:
        lore_objects = state.get('raw_lore_objects', [])
        planning_subjects_raw = [lore.content for lore in lore_objects if lore.category == 'npc_profile']
    planning_subjects_json = json.dumps(planning_subjects_raw, ensure_ascii=False, indent=2)

    gs = ai_core.profile.game_state
    chat_history_str = _get_formatted_chat_history(ai_core, user_id)

    full_context_dict = {
        'username': ai_core.profile.user_profile.name,
        'ai_name': ai_core.profile.ai_profile.name,
        'world_settings': ai_core.profile.world_settings or "æœªè¨­å®š",
        'ai_settings': ai_core.profile.ai_profile.description or "æœªè¨­å®š",
        'retrieved_context': state.get('rag_context', ''),
        'possessions_context': state.get('structured_context', {}).get('possessions_context', ''),
        'quests_context': state.get('structured_context', {}).get('quests_context', ''),
        'location_context': state.get('structured_context', {}).get('location_context', ''),
        'npc_context': "(å·²æ£„ç”¨ï¼Œè«‹åƒè€ƒ planning_subjects_json)",
        'relevant_npc_context': "(å·²æ£„ç”¨ï¼Œè«‹åƒè€ƒ planning_subjects_json)",
        'player_location': " > ".join(gs.location_path),
        'viewing_mode': gs.viewing_mode,
        'remote_target_path_str': " > ".join(gs.remote_target_path) if gs.remote_target_path else "æœªæŒ‡å®š",
    }
    world_snapshot = ai_core.world_snapshot_template.format(**full_context_dict)
    
    plan = await ai_core.ainvoke_with_rotation(
        ai_core.get_sfw_planning_chain(), 
        {
            "system_prompt": ai_core.profile.one_instruction, 
            "response_style_prompt": ai_core.profile.response_style_prompt or "é è¨­é¢¨æ ¼",
            "world_snapshot": world_snapshot, 
            "chat_history": chat_history_str,
            "planning_subjects_json": planning_subjects_json,
            "user_input": user_input,
        },
        retry_strategy='euphemize'
    )
    if not plan:
        plan = TurnPlan(execution_rejection_reason="å®‰å…¨å‚™æ´ï¼šSFWè¦åŠƒéˆå¤±æ•—ã€‚")
    return {"turn_plan": plan}

async def remote_sfw_planning_node(state: ConversationGraphState) -> Dict[str, TurnPlan]:
    """[7D] SFW æè¿°è·¯å¾‘å°ˆç”¨è¦åŠƒå™¨ï¼Œç”Ÿæˆé æ™¯å ´æ™¯çš„çµæ§‹åŒ–è¡Œå‹•è¨ˆåŠƒã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph|7D) Node: remote_sfw_planning -> æ­£åœ¨åŸºæ–¼æŒ‡ä»¤ '{user_input[:50]}...' ç”Ÿæˆé ç¨‹SFWå ´æ™¯è¨ˆåŠƒ...")

    if not ai_core.profile:
        return {"turn_plan": TurnPlan(execution_rejection_reason="éŒ¯èª¤ï¼šAI profile æœªåŠ è¼‰ï¼Œç„¡æ³•è¦åŠƒã€‚")}

    scene_analysis = state.get('scene_analysis')
    gs = ai_core.profile.game_state
    target_location_path: Optional[List[str]] = None

    if scene_analysis and scene_analysis.target_location_path:
        target_location_path = scene_analysis.target_location_path
        logger.info(f"[{user_id}] (Graph|7D) å·²å¾žç•¶å‰å›žåˆåˆ†æžä¸­ç²å–é ç¨‹ç›®æ¨™: {target_location_path}")
    elif gs.viewing_mode == 'remote' and gs.remote_target_path:
        target_location_path = gs.remote_target_path
        logger.warning(f"[{user_id}] (Graph|7D) ç•¶å‰å›žåˆåˆ†æžæœªæä¾›ç›®æ¨™ï¼Œå·²å¾žæŒä¹…åŒ– GameState ä¸­æˆåŠŸå›žé€€ã€‚ç›®æ¨™: {target_location_path}")
    else:
        error_msg = "éŒ¯èª¤ï¼šæœªèƒ½å¾žç•¶å‰å›žåˆåˆ†æžæˆ–æŒä¹…åŒ–ç‹€æ…‹ä¸­è§£æžå‡ºé ç¨‹è§€å¯Ÿçš„ç›®æ¨™åœ°é»žã€‚"
        logger.error(f"[{user_id}] (Graph|7D) {error_msg}")
        return {"turn_plan": TurnPlan(execution_rejection_reason=error_msg)}

    target_location_path_str = " > ".join(target_location_path)
    
    planning_subjects_raw = state.get('planning_subjects')
    if planning_subjects_raw is None:
        lore_objects = state.get('raw_lore_objects', [])
        planning_subjects_raw = [lore.content for lore in lore_objects if lore.category == 'npc_profile']
    planning_subjects_json = json.dumps(planning_subjects_raw, ensure_ascii=False, indent=2)

    chat_history_str = _get_formatted_chat_history(ai_core, user_id)

    full_context_dict = {
        'username': ai_core.profile.user_profile.name,
        'ai_name': ai_core.profile.ai_profile.name,
        'world_settings': ai_core.profile.world_settings or "æœªè¨­å®š",
        'ai_settings': ai_core.profile.ai_profile.description or "æœªè¨­å®š",
        'retrieved_context': state.get('rag_context', ''),
        'possessions_context': "(é ç¨‹è§€å¯Ÿæ¨¡å¼)",
        'quests_context': "(é ç¨‹è§€å¯Ÿæ¨¡å¼)",
        'location_context': f"é ç¨‹è§€å¯Ÿåœ°é»ž: {target_location_path_str}",
        'npc_context': "(å·²æ£„ç”¨ï¼Œè«‹åƒè€ƒ planning_subjects_json)",
        'relevant_npc_context': "(å·²æ£„ç”¨ï¼Œè«‹åƒè€ƒ planning_subjects_json)",
        'player_location': " > ".join(gs.location_path),
        'viewing_mode': 'remote',
        'remote_target_path_str': target_location_path_str,
    }
    world_snapshot = ai_core.world_snapshot_template.format(**full_context_dict)

    plan = await ai_core.ainvoke_with_rotation(
        ai_core.get_remote_sfw_planning_chain(),
        {
            "system_prompt": ai_core.profile.one_instruction, 
            "response_style_prompt": ai_core.profile.response_style_prompt or "é è¨­é¢¨æ ¼",
            "world_snapshot": world_snapshot,
            "chat_history": chat_history_str,
            "planning_subjects_json": planning_subjects_json,
            "target_location_path_str": target_location_path_str,
            "user_input": user_input,
        },
        retry_strategy='euphemize'
    )
    if not plan:
        plan = TurnPlan(execution_rejection_reason="å®‰å…¨å‚™æ´ï¼šé ç¨‹SFWè¦åŠƒéˆå¤±æ•—ã€‚")
    return {"turn_plan": plan}

# [v22.2 æ–°å¢ž] æ¢å¤ direct_nsfw_node çš„å®šä¹‰
async def direct_nsfw_node(state: ConversationGraphState) -> Dict[str, str]:
    """// NSFW æ¸¬è©¦æ–¹æ¡ˆ v19.0 // ä¸€æ­¥åˆ°ä½ç›´æŽ¥ç”Ÿæˆæœ€ç»ˆçš„ NSFW å°è¯´æ–‡æœ¬ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph|NSFW Direct) Node: direct_nsfw_node -> æ­£åœ¨åŸ·è¡ŒNSFWç›´é€šç”Ÿæˆ...")

    if not ai_core.profile:
        return {"llm_response": "é”™è¯¯ï¼šAI profile æœªåŠ è½½ï¼Œæ— æ³•ç”Ÿæˆåœºæ™¯ã€‚"}

    planning_subjects_raw = state.get('planning_subjects')
    if planning_subjects_raw is None:
        lore_objects = state.get('raw_lore_objects', [])
        planning_subjects_raw = [lore.content for lore in lore_objects if lore.category == 'npc_profile']
    planning_subjects_json = json.dumps(planning_subjects_raw, ensure_ascii=False, indent=2)

    gs = ai_core.profile.game_state
    chat_history_str = _get_formatted_chat_history(ai_core, user_id)

    full_context_dict = {
        'username': ai_core.profile.user_profile.name,
        'ai_name': ai_core.profile.ai_profile.name,
        'world_settings': ai_core.profile.world_settings or "æœªè¨­å®š",
        'ai_settings': ai_core.profile.ai_profile.description or "æœªè¨­å®š",
        'retrieved_context': state.get('rag_context', ''),
        'possessions_context': state.get('structured_context', {}).get('possessions_context', ''),
        'quests_context': state.get('structured_context', {}).get('quests_context', ''),
        'location_context': state.get('structured_context', {}).get('location_context', ''),
        'npc_context': "(å·²å¼ƒç”¨ï¼Œè¯·å‚è€ƒ planning_subjects_json)",
        'relevant_npc_context': "(å·²å¼ƒç”¨ï¼Œè¯·å‚è€ƒ planning_subjects_json)",
        'player_location': " > ".join(gs.location_path),
        'viewing_mode': gs.viewing_mode,
        'remote_target_path_str': " > ".join(gs.remote_target_path) if gs.remote_target_path else "æœªæŒ‡å®š",
    }
    world_snapshot = ai_core.world_snapshot_template.format(**full_context_dict)
    
    final_text = await ai_core.ainvoke_with_rotation(
        ai_core.get_direct_nsfw_chain(),
        {
            "system_prompt": ai_core.profile.one_instruction,
            "action_sexual_content_prompt": ai_core.modular_prompts.get("action_sexual_content", "è­¦å‘Š:æ€§æ„›æ¨¡çµ„æœªåŠ è¼‰"),
            "response_style_prompt": ai_core.profile.response_style_prompt or "é è¨­é¢¨æ ¼",
            "world_snapshot": world_snapshot,
            "chat_history": chat_history_str,
            "planning_subjects_json": planning_subjects_json,
            "user_input": user_input,
        },
        retry_strategy='force'
    )

    if not final_text:
        final_text = "ï¼ˆå®‰å…¨å‚™æ´ï¼šNSFW ç›´é€šç”Ÿæˆéˆæœ€ç»ˆå¤±è´¥ï¼Œå¯èƒ½å› ä¸ºå†…å®¹å®¡æŸ¥æˆ–APIä¸´æ—¶æ•…éšœã€‚ï¼‰"

    return {"llm_response": final_text}

async def tool_execution_node(state: ConversationGraphState) -> Dict[str, str]:
    """[8] çµ±ä¸€çš„å·¥å…·åŸ·è¡Œç¯€é»ž (ä¸»è¦ç”¨æ–¼ SFW è·¯å¾‘)ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    plan = state.get('turn_plan')
    logger.info(f"[{user_id}] (Graph|8) Node: tool_execution -> æ­£åœ¨åŸ·è¡Œè¡Œå‹•è¨ˆåŠƒä¸­çš„å·¥å…·...")
    
    if not plan or not plan.character_actions:
        return {"tool_results": "ç³»çµ±äº‹ä»¶ï¼šç„¡ä»»ä½•å·¥å…·è¢«èª¿ç”¨ã€‚"}
    try:
        results_summary = await ai_core._execute_planned_actions(plan)
    except Exception as e:
        logger.error(f"[{user_id}] (Graph|8) å·¥å…·åŸ·è¡Œæ™‚ç™¼ç”Ÿæœªæ•ç²çš„ç•°å¸¸: {e}", exc_info=True)
        results_summary = f"ç³»çµ±äº‹ä»¶ï¼šå·¥å…·åŸ·è¡Œæ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}"
    finally:
        tool_context.set_context(None, None)
    
    return {"tool_results": results_summary}

async def sfw_narrative_rendering_node(state: ConversationGraphState) -> Dict[str, str]:
    """[SFW Path] å°† SFW çš„ TurnPlan æ¸²æŸ“æˆå°è¯´æ–‡æœ¬ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    turn_plan = state.get('turn_plan')
    logger.info(f"[{user_id}] (Graph|9 SFW) Node: sfw_narrative_rendering -> æ­£åœ¨å°‡ SFW è¡Œå‹•è¨ˆåŠƒæ¸²æŸ“ç‚ºå°èªª...")

    if not turn_plan:
        return {"llm_response": "ï¼ˆç³»çµ±éŒ¯èª¤ï¼šæœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„ SFW è¡Œå‹•è¨ˆåŠƒã€‚ï¼‰"}
        
    if turn_plan.execution_rejection_reason:
        logger.warning(f"[{user_id}] (SFW Narrator) æª¢æ¸¬åˆ°ä¸Šæ¸¸è¦åŠƒç¯€é»žçš„åŸ·è¡Œå¦æ±ºï¼Œè·³éŽæ¸²æŸ“ã€‚ç†ç”±: {turn_plan.execution_rejection_reason}")
        return {"llm_response": turn_plan.execution_rejection_reason}
    
    chain_input = {
        "system_prompt": ai_core.profile.one_instruction if ai_core.profile else "é è¨­ç³»çµ±æŒ‡ä»¤",
        "action_sexual_content_prompt": "ï¼ˆSFW æ¨¡å¼ä¸‹ä¸é©ç”¨ï¼‰",
        "response_style_prompt": ai_core.profile.response_style_prompt if ai_core.profile else "é è¨­é¢¨æ ¼",
        "turn_plan": turn_plan
    }
        
    narrative_text = await ai_core.ainvoke_with_rotation(
        ai_core.get_narrative_chain(),
        chain_input,
        retry_strategy='euphemize'
    )
    if not narrative_text:
        narrative_text = "ï¼ˆAI åœ¨å°‡ SFW è¨ˆåŠƒè½‰åŒ–ç‚ºæ•…äº‹æ™‚é­é‡äº†å…§å®¹å®‰å…¨é™åˆ¶ã€‚ï¼‰"
    return {"llm_response": narrative_text}

# [v22.1 æ–°å¢ž] æ¢å¤ purification_node çš„å®šä¹‰
async def purification_node(state: ConversationGraphState) -> Dict[str, str]:
    """å°æ¸²æŸ“å¾Œçš„æ–‡æœ¬é€²è¡Œæœ€çµ‚çš„ã€å¼·åˆ¶æ€§çš„è©žå½™èˆ‡æ ¼å¼æ·¨åŒ–ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    raw_llm_response = state['llm_response']
    logger.info(f"[{user_id}] (Graph|Purification) Node: purification -> æ­£åœ¨å°æ–‡æœ¬é€²è¡Œç¸½ç·¨è¼¯ç´šçš„æ ¡å°...")

    if not raw_llm_response or not raw_llm_response.strip() or "å®‰å…¨å‚™æ´" in raw_llm_response:
        return {"llm_response": raw_llm_response}

    purification_chain = ai_core.get_purification_chain()
    
    purified_text = await ai_core.ainvoke_with_rotation(
        purification_chain,
        {
            "action_sexual_content_prompt": ai_core.modular_prompts.get("action_sexual_content", "è­¦å‘Š:æ€§æ„›æ¨¡çµ„æœªåŠ è¼‰"),
            "raw_text": raw_llm_response
        },
        retry_strategy='force'
    )
    
    if not purified_text:
        logger.warning(f"[{user_id}] (Graph|Purification) æ·¨åŒ–éˆè¿”å›žç©ºå€¼ï¼Œå°‡ä½¿ç”¨æœªç¶“æ·¨åŒ–çš„åŽŸå§‹æ–‡æœ¬ã€‚")
        return {"llm_response": raw_llm_response}

    return {"llm_response": purified_text}

async def validate_and_rewrite_node(state: ConversationGraphState) -> Dict:
    """[10] çµ±ä¸€çš„è¼¸å‡ºé©—è­‰èˆ‡æ·¨åŒ–ç¯€é»žã€‚"""
    user_id = state['user_id']
    initial_response = state['llm_response']
    logger.info(f"[{user_id}] (Graph|10) Node: validate_and_rewrite -> æ­£åœ¨å° LLM è¼¸å‡ºé€²è¡Œæœ€çµ‚æ¸…ç†èˆ‡é©—è­‰...")
    
    if not initial_response or not initial_response.strip():
        logger.error(f"[{user_id}] æ ¸å¿ƒéˆåœ¨æ·¨åŒ–å‰è¿”å›žäº†ç©ºçš„æˆ–ç„¡æ•ˆçš„å›žæ‡‰ã€‚")
        return {"final_output": "ï¼ˆ...ï¼‰"}
    
    clean_response = re.sub(r'^[=\-*]{3,}\s*$', '', initial_response, flags=re.MULTILINE)
    clean_response = re.sub(r'^ã€.*?ã€‘\s*$', '', clean_response, flags=re.MULTILINE)
    clean_response = re.sub(r'^\s*(æ—ç™½|å°è©±)\s*[:ï¼š]\s*', '', clean_response, flags=re.MULTILINE)
    
    final_response = clean_response.strip()
    if not final_response:
        logger.warning(f"[{user_id}] LLM åŽŸå§‹è¼¸å‡ºåœ¨æŒ‡ä»¤æ´©æ¼æ¸…ç†å¾Œç‚ºç©ºã€‚åŽŸå§‹è¼¸å‡ºç‚º: '{initial_response[:200]}...'")
        return {"final_output": "ï¼ˆ...ï¼‰"}
        
    return {"final_output": final_response}



    # å‡½å¼ï¼š[æ–°] ç²å–è©žå½™èˆ‡æ ¼å¼æ·¨åŒ–éˆ (v1.0 - ç¸½ç·¨è¼¯)
    # æ›´æ–°ç´€éŒ„:
    # v1.0 (2025-09-22): [é‡å¤§å“è³ªæå‡] å‰µå»ºæ­¤å…¨æ–°çš„â€œç¸½ç·¨è¼¯â€éˆã€‚å…¶å”¯ä¸€è·è²¬æ˜¯åœ¨å‰µæ„ç”Ÿæˆä¹‹å¾Œï¼Œå°æ–‡æœ¬é€²è¡Œä¸€æ¬¡æ©Ÿæ¢°å¼çš„ã€å¼·åˆ¶æ€§çš„ä¿®æ­£ï¼Œç¢ºä¿æ‰€æœ‰éœ²éª¨è©žå½™å’Œå°è©±æ ¼å¼éƒ½åš´æ ¼ç¬¦åˆ action_sexual_content.txt çš„æœ€çµ‚è¦ç¯„ï¼Œæ—¨åœ¨è§£æ±ºâ€œæ–‡å­¸å·¨åŒ â€ç‚ºè¿½æ±‚è—è¡“æ€§è€Œå¿½ç•¥è¦å‰‡çš„å•é¡Œã€‚
    def get_purification_chain(self) -> Runnable:
        """ç²å–æˆ–å‰µå»ºä¸€å€‹å°ˆé–€ç”¨æ–¼å¼·åˆ¶ä¿®æ­£æ–‡æœ¬ä¸­éœ²éª¨è©žå½™å’Œå°è©±æ ¼å¼çš„éˆã€‚"""
        if not hasattr(self, 'purification_chain') or self.purification_chain is None:
            purifier_llm = self._create_llm_instance(temperature=0.0)
            
            system_prompt = """# ==================================================
# == ðŸ§  ç³»çµ±æ ¸å¿ƒæŒ‡ä»¤ (ç¸½ç·¨è¼¯æ¨¡å¼ - v1.0) ðŸ§ 
# ==================================================
# ä½ æ˜¯ä¸€ä½åš´è¬¹çš„ã€ä¸€çµ²ä¸è‹Ÿçš„ã€ç¸½ç·¨è¼¯ã€‘ã€‚ä½ çš„å”¯ä¸€ä»»å‹™æ˜¯æŽ¥æ”¶ä¸€æ®µã€å°èªªæ–‡æœ¬è‰ç¨¿ã€‘ï¼Œä¸¦æ ¹æ“šä¸‹æ–¹çš„ã€çµ•å°è¦å‰‡ã€‘ï¼Œå°å…¶é€²è¡Œæ©Ÿæ¢°å¼çš„ã€ç„¡æ¢ä»¶çš„ä¿®æ­£ã€‚

# --- ã€ã€ã€çµ•å°è¦å‰‡ (ç„¡å‰µæ„çš„å¼·åˆ¶åŸ·è¡Œ)ã€‘ã€‘ã€‘ ---

# 1.  **ã€éœ²éª¨è©žå½™å¼·åˆ¶æ›¿æ›ã€‘**:
#     - ä½ ã€å¿…é ˆã€‘é€šè®€å…¨æ–‡ï¼ŒæŸ¥æ‰¾æ‰€æœ‰ä¸ç¬¦åˆä¸‹æ–¹ã€éœ²éª¨è©žå½™è–ç¶“ã€‘çš„æ€§å™¨å®˜æˆ–ç”Ÿç†ç¾è±¡æè¿°ã€‚
#     - æ‰¾åˆ°å¾Œï¼Œä½ ã€å¿…é ˆã€‘å°‡å…¶ã€ç„¡æ¢ä»¶åœ°æ›¿æ›ã€‘ç‚ºè–ç¶“ä¸­æŒ‡å®šçš„æ­£ç¢ºè©žå½™ã€‚
#     - **ä½ çš„ä»»å‹™æ˜¯æ›¿æ›ï¼Œä¸æ˜¯å‰µä½œæˆ–æ”¹å¯«å¥å­ã€‚**

# 2.  **ã€å°è©±æ ¼å¼å¼·åˆ¶ä¿®æ­£ã€‘**:
#     - ä½ ã€å¿…é ˆã€‘æŸ¥æ‰¾æ–‡æœ¬ä¸­æ‰€æœ‰è§’è‰²èªªçš„ã€è¢«éŒ¯èª¤åœ°ç”¨ `ã€Œã€` æˆ– `""` åŒ…è£¹çš„ç›´æŽ¥å°è©±ã€‚
#     - æ‰¾åˆ°å¾Œï¼Œä½ ã€å¿…é ˆã€‘å°‡å…¶å¼•è™Ÿã€ç„¡æ¢ä»¶åœ°æ›¿æ›ã€‘ç‚ºæ­£ç¢ºçš„ `ã€Žã€`ã€‚

# 3.  **ã€ç¦æ­¢å‰µæ„ã€‘**:
#     - ä½ ã€çµ•å°ç¦æ­¢ã€‘å°æ–‡æœ¬é€²è¡Œä»»ä½•èˆ‡ä¸Šè¿°å…©æ¢è¦å‰‡ç„¡é—œçš„ä¿®æ”¹ã€æ“´å¯«ã€ç¸®å¯«æˆ–é¢¨æ ¼èª¿æ•´ã€‚
#     - ä½ çš„è·è²¬æ˜¯æ ¡å°å’Œä¿®æ­£ï¼Œä¸æ˜¯å†å‰µä½œã€‚

# --- ã€ã€ã€éœ²éª¨è©žå½™è–ç¶“ (ä½ çš„å”¯ä¸€è©žå½™æ¨™æº–)ã€‘ã€‘ã€‘ ---
{action_sexual_content_prompt}
# ---
"""
            human_prompt = """
# ==================================================
# == ðŸ“– å¾…æ ¡å°çš„å°èªªæ–‡æœ¬è‰ç¨¿ ðŸ“–
# ==================================================
{raw_text}
# --- ä½ çš„ä»»å‹™ ---
è«‹åš´æ ¼éµå¾ªä½ åœ¨ç³»çµ±æŒ‡ä»¤ä¸­å­¸åˆ°çš„æ‰€æœ‰ã€çµ•å°è¦å‰‡ã€‘ï¼Œåªå°ä¸Šæ–¹çš„è‰ç¨¿é€²è¡Œè©žå½™å’Œæ ¼å¼çš„å¼·åˆ¶ä¿®æ­£ï¼Œç„¶å¾Œè¼¸å‡ºæœ€çµ‚çš„ã€ç´”æ·¨çš„å®šç¨¿æ–‡æœ¬ã€‚
"""
            prompt = ChatPromptTemplate.from_messages([
                ("system", system_prompt),
                ("human", human_prompt)
            ])
            self.purification_chain = prompt | purifier_llm | StrOutputParser()
        return self.purification_chain
    # å‡½å¼ï¼š[æ–°] ç²å–è©žå½™èˆ‡æ ¼å¼æ·¨åŒ–éˆ (v1.0 - ç¸½ç·¨è¼¯)


async def persist_state_node(state: ConversationGraphState) -> Dict:
    """[11] çµ±ä¸€çš„ç‹€æ…‹æŒä¹…åŒ–ç¯€é»žï¼Œè² è²¬å„²å­˜å°è©±æ­·å²ä¸¦å°‡ç•¶å‰æ„åœ–æŒä¹…åŒ–ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    clean_response = state['final_output']
    intent_classification = state.get('intent_classification')
    logger.info(f"[{user_id}] (Graph|11) Node: persist_state -> æ­£åœ¨æŒä¹…åŒ–ç‹€æ…‹èˆ‡è¨˜æ†¶...")
    
    if ai_core.profile and intent_classification:
        current_intent_type = intent_classification.intent_type
        if ai_core.profile.game_state.last_intent_type != current_intent_type:
            logger.info(f"[{user_id}] (Persist) æ­£åœ¨å°‡ç•¶å‰æ„åœ– '{current_intent_type}' æŒä¹…åŒ–åˆ° GameState...")
            ai_core.profile.game_state.last_intent_type = current_intent_type
            await ai_core.update_and_persist_profile({'game_state': ai_core.profile.game_state.model_dump()})

    if clean_response and clean_response != "ï¼ˆ...ï¼‰":
        chat_history_manager = ai_core.session_histories.get(user_id)
        if chat_history_manager:
            chat_history_manager.add_user_message(user_input)
            chat_history_manager.add_ai_message(clean_response)
        
        last_interaction_text = f"ä½¿ç”¨è€… '{ai_core.profile.user_profile.name}' èªª: {user_input}\n\n[å ´æ™¯å›žæ‡‰]:\n{clean_response}"
        tasks = []
        tasks.append(ai_core._generate_and_save_personal_memory(last_interaction_text))
        if ai_core.vector_store:
            tasks.append(asyncio.to_thread(ai_core.vector_store.add_texts, [last_interaction_text], metadatas=[{"source": "history"}]))
        
        async def save_to_sql():
            from .database import AsyncSessionLocal, MemoryData
            import time
            timestamp = time.time()
            async with AsyncSessionLocal() as session:
                session.add(MemoryData(user_id=user_id, content=last_interaction_text, timestamp=timestamp, importance=1))
                await session.commit()
        
        tasks.append(save_to_sql())
        await asyncio.gather(*tasks, return_exceptions=True)
        
    return {}

def _get_formatted_chat_history(ai_core: AILover, user_id: str, num_messages: int = 10) -> str:
    """å¾ž AI æ ¸å¿ƒå¯¦ä¾‹ä¸­æå–ä¸¦æ ¼å¼åŒ–æœ€è¿‘çš„å°è©±æ­·å²ã€‚"""
    if not ai_core.profile: return "ï¼ˆæ²’æœ‰æœ€è¿‘çš„å°è©±æ­·å²ï¼‰"
    chat_history_manager = ai_core.session_histories.get(user_id, ChatMessageHistory())
    if not chat_history_manager.messages:
        return "ï¼ˆæ²’æœ‰æœ€è¿‘çš„å°è©±æ­·å²ï¼‰"
    
    recent_messages = chat_history_manager.messages[-num_messages:]
    
    formatted_history = []
    for msg in recent_messages:
        role = "ä½¿ç”¨è€…" if isinstance(msg, HumanMessage) else ai_core.profile.ai_profile.name
        formatted_history.append(f"{role}: {msg.content}")
        
    return "\n".join(formatted_history)

def route_expansion_decision(state: ConversationGraphState) -> Literal["expand_lore", "continue_to_planner"]:
    """æ ¹æ“šLOREæ“´å±•æ±ºç­–ï¼Œæ±ºå®šæ˜¯å¦é€²å…¥æ“´å±•ç¯€é»žã€‚"""
    if state.get("expansion_decision") and state["expansion_decision"].should_expand:
        return "expand_lore"
    else:
        return "continue_to_planner"

def create_main_response_graph() -> StateGraph:
    """å‰µå»ºä¸»å›žæ‡‰åœ–"""
    graph = StateGraph(ConversationGraphState)
    
    graph.add_node("classify_intent", classify_intent_node)
    graph.add_node("retrieve_memories", retrieve_memories_node)
    graph.add_node("query_lore", query_lore_node)
    graph.add_node("perceive_and_set_view", perceive_and_set_view_node)
    graph.add_node("expansion_decision", expansion_decision_node)
    graph.add_node("character_quantification", character_quantification_node)
    graph.add_node("lore_expansion", lore_expansion_node)
    graph.add_node("sfw_planning", sfw_planning_node)
    graph.add_node("remote_sfw_planning", remote_sfw_planning_node)
    graph.add_node("direct_nsfw_node", direct_nsfw_node)
    graph.add_node("tool_execution", tool_execution_node)
    graph.add_node("sfw_narrative_rendering", sfw_narrative_rendering_node)
    graph.add_node("purification", purification_node)
    graph.add_node("validate_and_rewrite", validate_and_rewrite_node)
    graph.add_node("persist_state", persist_state_node)
    graph.add_node("planner_junction", lambda state: {})
    
    def prepare_existing_subjects_node(state: ConversationGraphState) -> Dict:
        lore_objects = state.get('raw_lore_objects', [])
        planning_subjects = [lore.content for lore in lore_objects if lore.category == 'npc_profile']
        logger.info(f"[{state['user_id']}] (Graph) Node: prepare_existing_subjects -> å·²å°‡ {len(planning_subjects)} å€‹ç¾æœ‰NPCæ‰“åŒ…ç‚ºè¦åŠƒä¸»é«”ã€‚")
        return {"planning_subjects": planning_subjects}
        
    graph.add_node("prepare_existing_subjects", prepare_existing_subjects_node)

    graph.set_entry_point("classify_intent")
    graph.add_edge("classify_intent", "retrieve_memories")
    graph.add_edge("retrieve_memories", "query_lore")
    graph.add_edge("query_lore", "perceive_and_set_view")
    graph.add_edge("perceive_and_set_view", "expansion_decision")
    
    graph.add_conditional_edges(
        "expansion_decision",
        route_expansion_decision,
        { 
            "expand_lore": "character_quantification", 
            "continue_to_planner": "prepare_existing_subjects"
        }
    )
    graph.add_edge("character_quantification", "lore_expansion")
    graph.add_edge("lore_expansion", "planner_junction")
    graph.add_edge("prepare_existing_subjects", "planner_junction")

    def route_to_planner(state: ConversationGraphState) -> str:
        user_id = state['user_id']
        intent_classification = state.get('intent_classification')
        if not intent_classification: return "sfw_planner" 
        intent = intent_classification.intent_type
        ai_core = state['ai_core']
        viewing_mode = ai_core.profile.game_state.viewing_mode if ai_core.profile else 'local'
        logger.info(f"[{user_id}] (Router) Routing to planner. Intent: '{intent}', Final Viewing Mode: '{viewing_mode}'")
        if 'nsfw' in intent:
            return "direct_nsfw_test"
        if viewing_mode == 'remote':
            return "remote_sfw_planner"
        else:
            return "sfw_planner"

    graph.add_conditional_edges(
        "planner_junction",
        route_to_planner,
        { 
            "sfw_planner": "sfw_planning", 
            "remote_sfw_planner": "remote_sfw_planning",
            "direct_nsfw_test": "direct_nsfw_node"
        }
    )
    
    graph.add_edge("sfw_planning", "tool_execution")
    graph.add_edge("remote_sfw_planning", "tool_execution")
    graph.add_edge("tool_execution", "sfw_narrative_rendering")
    graph.add_edge("sfw_narrative_rendering", "purification")
    graph.add_edge("direct_nsfw_node", "purification")
    graph.add_edge("purification", "validate_and_rewrite")
    graph.add_edge("validate_and_rewrite", "persist_state")
    graph.add_edge("persist_state", END)
    
    return graph.compile()

async def process_canon_node(state: SetupGraphState) -> Dict:
    ai_core = state['ai_core']
    canon_text = state['canon_text']
    if canon_text:
        await ai_core.add_canon_to_vector_store(canon_text)
        await ai_core.parse_and_create_lore_from_canon(None, canon_text, is_setup_flow=True)
    return {}

async def complete_profiles_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    logger.info(f"[{user_id}] (Setup Graph) Node: complete_profiles_node -> æ­£åœ¨è£œå®Œè§’è‰²æª”æ¡ˆ...")
    completion_chain = ai_core.get_profile_completion_chain()
    if not ai_core.profile:
        logger.error(f"[{user_id}] åœ¨ complete_profiles_node ä¸­ ai_core.profile ç‚ºç©ºï¼Œç„¡æ³•ç¹¼çºŒã€‚")
        return {}
    
    completed_user_profile_task = ai_core.ainvoke_with_rotation(completion_chain, {"profile_json": ai_core.profile.user_profile.model_dump_json()}, retry_strategy='euphemize')
    completed_ai_profile_task = ai_core.ainvoke_with_rotation(completion_chain, {"profile_json": ai_core.profile.ai_profile.model_dump_json()}, retry_strategy='euphemize')
    
    completed_user_profile, completed_ai_profile = await asyncio.gather(completed_user_profile_task, completed_ai_profile_task)

    update_payload = {}
    if completed_user_profile:
        update_payload['user_profile'] = completed_user_profile.model_dump()
    if completed_ai_profile:
        update_payload['ai_profile'] = completed_ai_profile.model_dump()
        
    if update_payload:
        await ai_core.update_and_persist_profile(update_payload)
        
    return {}

async def world_genesis_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    
    if not ai_core.profile:
        raise Exception("AI Profile is not loaded for world genesis.")

    genesis_chain = ai_core.get_world_genesis_chain()
    genesis_result = await ai_core.ainvoke_with_rotation(genesis_chain, {"world_settings": ai_core.profile.world_settings, "username": ai_core.profile.user_profile.name, "ai_name": ai_core.profile.ai_profile.name}, retry_strategy='force')
    
    if not genesis_result:
        raise Exception("ä¸–ç•Œå‰µä¸–éˆè¿”å›žäº†ç©ºçµæžœï¼Œå¯èƒ½æ˜¯å…§å®¹å¯©æŸ¥ã€‚")
        
    gs = ai_core.profile.game_state
    gs.location_path = genesis_result.location_path
    await ai_core.update_and_persist_profile({'game_state': gs.model_dump()})
    
    await lore_book.add_or_update_lore(user_id, 'location_info', " > ".join(genesis_result.location_path), genesis_result.location_info.model_dump())
    
    for npc in genesis_result.initial_npcs:
        npc_key = " > ".join(genesis_result.location_path) + f" > {npc.name}"
        await lore_book.add_or_update_lore(user_id, 'npc_profile', npc_key, npc.model_dump())
        
    return {"genesis_result": genesis_result}

async def generate_opening_scene_node(state: SetupGraphState) -> Dict:
    ai_core = state['ai_core']
    opening_scene = await ai_core.generate_opening_scene()
    
    if not opening_scene or not opening_scene.strip():
        opening_scene = (f"åœ¨ä¸€ç‰‡æŸ”å’Œçš„å…‰èŠ’ä¸­ï¼Œä½ å’Œ {ai_core.profile.ai_profile.name} ç™¼ç¾è‡ªå·±èº«è™•æ–¼ä¸€å€‹å¯§éœçš„ç©ºé–“è£¡...")
        
    return {"opening_scene": opening_scene}

def create_setup_graph() -> StateGraph:
    """å‰µå»ºè¨­å®šåœ–"""
    graph = StateGraph(SetupGraphState)
    graph.add_node("process_canon", process_canon_node)
    graph.add_node("complete_profiles", complete_profiles_node)
    graph.add_node("world_genesis", world_genesis_node)
    graph.add_node("generate_opening_scene", generate_opening_scene_node)
    graph.set_entry_point("process_canon")
    graph.add_edge("process_canon", "complete_profiles")
    graph.add_edge("complete_profiles", "world_genesis")
    graph.add_edge("world_genesis", "generate_opening_scene")
    graph.add_edge("generate_opening_scene", END)
    return graph.compile()

