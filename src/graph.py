# src/graph.py çš„ä¸­æ–‡è¨»é‡‹(v22.0 - æ¸²æŸ“å™¨åˆ†ç¦»ä¿®å¤)
# æ›´æ–°ç´€éŒ„:
# v22.0 (2025-09-22): [ç½é›£æ€§BUGä¿®å¾©] è§£å†³äº†å› é‡å‘½åæ¸²æŸ“èŠ‚ç‚¹å¯¼è‡´çš„ NameErrorã€‚æ¢å¤å¹¶é‡å‘½åäº†ä¸“ç”¨äº SFW è·¯å¾„çš„ `sfw_narrative_rendering_node`ï¼Œå¹¶ç¡®ä¿ `create_main_response_graph` æ­£ç¡®æ³¨å†Œäº†ä¸¤ä¸ªç‹¬ç«‹çš„æ¸²æŸ“å™¨ï¼ˆ`sfw_narrative_rendering_node` å’Œ `final_rendering_node`ï¼‰ï¼Œä»è€Œä¿®å¤äº†å›¾çš„æ‹“æ‰‘ç»“æ„ã€‚
# v21.1 (2025-09-10): [ç½é›£æ€§BUGä¿®å¾©] æ¢å¤äº†æ‰€æœ‰è¢«å…ˆå‰ç‰ˆæœ¬é”™è¯¯çœç•¥çš„ `SetupGraph` ç›¸å…³èŠ‚ç‚¹ã€‚
# v21.0 (2025-09-09): [é‡å¤§æ¶æ§‹é‡æ§‹] å¯¹å›¾çš„æ‹“æ‰‘ç»“æ„è¿›è¡Œäº†ç²¾ç»†åŒ–é‡æ„ã€‚
import sys
import asyncio
import json
import re
from typing import Dict, List, Literal, Optional, Any

from langchain_core.messages import HumanMessage
from langchain_community.chat_message_histories import ChatMessageHistory
from langgraph.graph import StateGraph, END

from .ai_core import AILover
from .logger import logger
from .graph_state import ConversationGraphState, SetupGraphState
from . import lore_book, tools
from .schemas import (CharacterProfile, TurnPlan, ExpansionDecision, 
                      UserInputAnalysis, SceneAnalysisResult, SceneCastingResult, 
                      WorldGenesisResult, IntentClassificationResult, StyleAnalysisResult,
                      CharacterQuantificationResult)
from .tool_context import tool_context
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# --- ä¸»å°è©±åœ– (Main Conversation Graph) çš„ç¯€é» ---

# å‡½å¼ï¼šåˆ†é¡æ„åœ–ç¯€é» (v2.0 - å»¶çºŒæ€§æŒ‡ä»¤å®‰å…¨æŸ¥è©¢ç”Ÿæˆ)
# æ›´æ–°ç´€éŒ„:
# v2.0 (2025-09-08): [ç½é›£æ€§BUGä¿®å¾©] å¾¹åº•é‡æ§‹äº†æ­¤ç¯€é»å°å»¶çºŒæ€§æŒ‡ä»¤çš„è™•ç†é‚è¼¯ã€‚ç¾åœ¨ï¼Œç•¶æª¢æ¸¬åˆ° "ç¹¼çºŒ" æ™‚ï¼Œå®ƒä¸åƒ…æœƒç¹¼æ‰¿ä¸Šä¸€è¼ªçš„æ„åœ–ï¼Œé‚„æœƒä¸»å‹•ä½¿ç”¨ã€ä¸Šä¸€è¼ª AI çš„å›è¦†ã€‘ä½œç‚ºè¼¸å…¥ï¼Œèª¿ç”¨â€œæ–‡å­¸è©•è«–å®¶â€éˆä¾†é å…ˆç”Ÿæˆä¸€å€‹å®‰å…¨çš„ `sanitized_query_for_tools`ã€‚æ­¤ä¿®æ”¹å¾æ ¹æœ¬ä¸Šè§£æ±ºäº†å› å¿«é€Ÿé€šé“ç¹é `retrieve_memories_node` è€Œå°è‡´çš„ KeyErrorã€‚
# v1.0 (2025-09-08): åŸå§‹å‰µå»ºã€‚
async def classify_intent_node(state: ConversationGraphState) -> Dict:
    """[1] åœ–çš„å…¥å£é»ï¼Œå°è¼¸å…¥è¿›è¡Œæ„å›¾åˆ†ç±»ï¼Œå¹¶èƒ½å¤„ç†å»¶ç»­æ€§æŒ‡ä»¤ä»¥ç»§æ‰¿æŒä¹…åŒ–çš„çŠ¶æ€ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    
    logger.info(f"[{user_id}] (Graph|1) Node: classify_intent -> æ­£åœ¨é€²è¡Œåˆæ­¥è¼¸å…¥é¡å‹åˆ†æ...")
    input_analysis_chain = ai_core.get_input_analysis_chain()
    input_analysis_result = await ai_core.ainvoke_with_rotation(
        input_analysis_chain,
        {"user_input": user_input},
        retry_strategy='euphemize'
    )
    
    if input_analysis_result and input_analysis_result.input_type == 'continuation':
        if ai_core.profile and ai_core.profile.game_state.last_intent_type:
            last_intent_type = ai_core.profile.game_state.last_intent_type
            logger.info(f"[{user_id}] (Graph|1) æª¢æ¸¬åˆ°å»¶ç»­æ€§æŒ‡ä»¤ï¼Œå·²å¾ã€æŒä¹…åŒ– GameStateã€‘ç¹¼æ‰¿æ„å›¾: '{last_intent_type}'")
            
            inherited_intent = IntentClassificationResult(
                intent_type=last_intent_type,
                reasoning=f"å¾æŒä¹…åŒ–ç‹€æ…‹ç¹¼æ‰¿äº†ä¸Šä¸€è¼ªçš„ '{last_intent_type}' æ„åœ–ã€‚"
            )

            # [v2.0 æ ¸å¿ƒä¿®æ­£] é ç”Ÿæˆ sanitized_query_for_tools ä»¥ä¿®å¾© KeyError
            sanitized_query_for_continuation = "æ¥çºŒä¸Šä¸€å¹•çš„æƒ…ç¯€ã€‚" # é è¨­å®‰å…¨æŸ¥è©¢
            chat_history = ai_core.session_histories.get(user_id)
            if chat_history and chat_history.messages:
                last_ai_message = next((m.content for m in reversed(chat_history.messages) if m.type == 'ai'), None)
                if last_ai_message:
                    try:
                        logger.info(f"[{user_id}] (Graph|1) æ­£åœ¨åŸºæ–¼ä¸Šä¸€è¼ª AI å›è¦†ç‚ºå»¶çºŒæ€§æŒ‡ä»¤ç”Ÿæˆå®‰å…¨æŸ¥è©¢...")
                        literary_chain = ai_core.get_literary_euphemization_chain()
                        safe_overview = await ai_core.ainvoke_with_rotation(
                            literary_chain,
                            {"dialogue_history": last_ai_message},
                            retry_strategy='euphemize'
                        )
                        if safe_overview:
                            sanitized_query_for_continuation = safe_overview
                    except Exception as e:
                         logger.warning(f"[{user_id}] (Graph|1) ç‚ºå»¶çºŒæ€§æŒ‡ä»¤ç”Ÿæˆå®‰å…¨æŸ¥è©¢æ™‚å¤±æ•—: {e}ï¼Œå°‡ä½¿ç”¨é è¨­å€¼ã€‚")

            return {
                "intent_classification": inherited_intent,
                "input_analysis": input_analysis_result,
                "sanitized_query_for_tools": sanitized_query_for_continuation
            }
        else:
            logger.warning(f"[{user_id}] (Graph|1) æª¢æ¸¬åˆ°å»¶ç»­æ€§æŒ‡ä»¤ï¼Œä½† GameState ä¸­æ²’æœ‰æ„å›¾å¯ä¾›ç»§æ‰¿ï¼Œå°†æŒ‰å¸¸è§„æµç¨‹å¤„ç†ã€‚")

    logger.info(f"[{user_id}] (Graph|1) æ­£åœ¨å¯¹å…·ä½“æŒ‡ä»¤ '{user_input[:30]}...' é€²è¡Œæ„åœ–åˆ†é¡...")
    classification_chain = ai_core.get_intent_classification_chain()
    classification_result = await ai_core.ainvoke_with_rotation(
        classification_chain,
        {"user_input": user_input},
        retry_strategy='euphemize'
    )
    
    if not classification_result:
        logger.warning(f"[{user_id}] (Graph|1) æ„åœ–åˆ†é¡éˆå¤±æ•—ï¼Œå•Ÿå‹•å®‰å…¨å‚™æ´ï¼Œé è¨­ç‚º SFWã€‚")
        classification_result = IntentClassificationResult(intent_type='sfw', reasoning="å®‰å…¨å‚™æ´ï¼šåˆ†é¡éˆå¤±æ•—ã€‚")
        
    return {
        "intent_classification": classification_result,
        "input_analysis": input_analysis_result
    }
# å‡½å¼ï¼šåˆ†é¡æ„åœ–ç¯€é» (v2.0 - å»¶çºŒæ€§æŒ‡ä»¤å®‰å…¨æŸ¥è©¢ç”Ÿæˆ)

# å‡½å¼ï¼šæª¢ç´¢è¨˜æ†¶ç¯€é» (v29.0 - æºé ­æ¸…æ´—)
# æ›´æ–°ç´€éŒ„:
# v29.0 (2025-09-08): [é‡å¤§æ¶æ§‹é‡æ§‹] æ­¤ç¯€é»çš„è·è²¬å·²å‡ç´šç‚ºã€å”¯ä¸€çš„ NSFW è¼¸å…¥æ¸…æ´—æºé ­ã€‘ã€‚å®ƒä¸å†ä½¿ç”¨è„†å¼±çš„å¯¦é«”æå–éˆï¼Œè€Œæ˜¯å¼·åˆ¶æ€§åœ°ä½¿ç”¨æ›´å¼·å¤§çš„â€œæ–‡å­¸è©•è«–å®¶â€éˆå°‡åŸå§‹è¼¸å…¥è½‰æ›ç‚ºä¸€æ®µå®‰å…¨çš„æ–‡å­¸æ¦‚è¿°ã€‚é€™æ®µå®‰å…¨çš„æ¦‚è¿°å°‡è¢«ç”¨æ–¼ RAG æª¢ç´¢ï¼Œä¸¦åŒæ™‚å„²å­˜åˆ°æ–°çš„ `sanitized_query_for_tools` ç‹€æ…‹ä¸­ï¼Œä¾›æ‰€æœ‰ä¸‹æ¸¸å…§éƒ¨å·¥å…·éˆå®‰å…¨ä½¿ç”¨ï¼Œå¾æ ¹æœ¬ä¸Šè§£æ±ºå› å¤šå€‹ç¯€é»é‡è¤‡è™•ç†åŸå§‹ NSFW è¼¸å…¥è€Œå°è‡´çš„è¶…æ™‚å’Œæ›èµ·å•é¡Œã€‚
# v28.0 (2025-09-12): [ç½é›£æ€§BUGä¿®å¾©] å°ˆç”¨è¨˜æ†¶æª¢ç´¢ç¯€é»ï¼ŒåŸ·è¡ŒRAGæ“ä½œã€‚
async def retrieve_memories_node(state: ConversationGraphState) -> Dict:
    """
    [v29.0 æºé ­æ¸…æ´—] å°ˆç”¨è¨˜æ†¶æª¢ç´¢èˆ‡è¼¸å…¥æ¸…æ´—ç¯€é»ã€‚
    å®ƒæœƒå°‡åŸå§‹è¼¸å…¥è½‰æ›ç‚ºå®‰å…¨çš„æ–‡å­¸æ¦‚è¿°ï¼Œç”¨æ–¼RAGï¼Œä¸¦å°‡å…¶å‚³éçµ¦ä¸‹æ¸¸ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input_for_retrieval = state['messages'][-1].content
    
    logger.info(f"[{user_id}] (Graph|2) Node: retrieve_memories -> æ­£åœ¨å°è¼¸å…¥ '{user_input_for_retrieval[:30]}...' åŸ·è¡Œã€æºé ­æ¸…æ´—ã€‘èˆ‡è¨˜æ†¶æª¢ç´¢...")
    
    sanitized_query = ""
    try:
        # --- æ­¥é©Ÿ 1: å¼·åˆ¶æ€§çš„å®‰å…¨é æ¸…æ´— ---
        # ä½¿ç”¨å¼·å¤§çš„â€œæ–‡å­¸è©•è«–å®¶â€éˆï¼Œå°‡æ½›åœ¨çš„ NSFW è¼¸å…¥è½‰æ›ç‚ºå®‰å…¨çš„æ–‡å­¸æ¦‚è¿°ã€‚
        logger.info(f"[{user_id}] (RAG Pre-cleaner) æ­£åœ¨ä½¿ç”¨'æ–‡å­¸è©•è«–å®¶'éˆå°è¼¸å…¥é€²è¡Œå¼·åˆ¶æ€§å®‰å…¨é æ¸…æ´—...")
        literary_chain = ai_core.get_literary_euphemization_chain()

        # ä½¿ç”¨ ainvoke_with_rotation ä¸¦æŒ‡å®š euphemize ç­–ç•¥ï¼Œä»¥ç¢ºä¿å³ä½¿æ¸…æ´—éˆæœ¬èº«è¢«å¯©æŸ¥ä¹Ÿèƒ½æœ‰å‚™æ´
        sanitized_query = await ai_core.ainvoke_with_rotation(
            literary_chain, 
            {"dialogue_history": user_input_for_retrieval},
            retry_strategy='euphemize' 
        )
        
        # å¦‚æœå§”å©‰åŒ–é‡è©¦å¾Œä»ç„¶å¤±æ•—ï¼Œå‰‡è§¸ç™¼çµ‚æ¥µå‚™æ´
        if not sanitized_query or not sanitized_query.strip():
            logger.error(f"[{user_id}] (RAG Pre-cleaner) 'æ–‡å­¸è©•è«–å®¶'æ¸…æ´—éˆæœ€çµ‚å¤±æ•—ï¼Œå°‡è§¸ç™¼çµ‚æ¥µå‚™æ´ã€‚")
            raise ValueError("Literary chain failed to produce output.")

        logger.info(f"[{user_id}] (RAG Pre-cleaner) è¼¸å…¥å·²æˆåŠŸé æ¸…æ´—ç‚ºå®‰å…¨çš„æ–‡å­¸æ¦‚è¿°: '{sanitized_query[:50]}...'")

    except Exception as e:
        # --- æ­¥é©Ÿ 2: çµ‚æ¥µå‚™æ´ ---
        logger.error(f"[{user_id}] (RAG Pre-cleaner) å®‰å…¨é æ¸…æ´—å¤±æ•—: {e}ã€‚å•Ÿå‹•ã€çµ‚æ¥µå‚™æ´ã€‘ï¼šç›´æ¥ä½¿ç”¨åŸå§‹è¼¸å…¥é€²è¡Œæœ¬åœ°æª¢ç´¢ã€‚")
        sanitized_query = user_input_for_retrieval

    # --- æ­¥é©Ÿ 3: åŸ·è¡Œæª¢ç´¢ ---
    # ä½¿ç”¨æ¸…æ´—å¾Œçš„å®‰å…¨æŸ¥è©¢æ–‡æœ¬ä¾†åŸ·è¡Œ RAG
    rag_context_str = await ai_core.retrieve_and_summarize_memories(sanitized_query)
    
    # --- æ­¥é©Ÿ 4: è¿”å›çµæœï¼Œä¸¦å°‡å®‰å…¨æŸ¥è©¢æ–‡æœ¬å­˜å…¥ç‹€æ…‹ä¾›ä¸‹æ¸¸ä½¿ç”¨ ---
    return {
        "rag_context": rag_context_str,
        "sanitized_query_for_tools": sanitized_query
    }
# å‡½å¼ï¼šæª¢ç´¢è¨˜æ†¶ç¯€é» (v29.0 - æºé ­æ¸…æ´—)

# å‡½å¼ï¼šæŸ¥è©¢ LORE ç¯€é» (v29.0 - é©é…å®‰å…¨æŸ¥è©¢)
# æ›´æ–°ç´€éŒ„:
# v29.0 (2025-09-08): [é‡å¤§æ¶æ§‹é‡æ§‹] æ­¤ç¯€é»çš„é‚è¼¯è¢«æ¥µå¤§ç°¡åŒ–ã€‚å®ƒä¸å†ç›´æ¥è™•ç†åŸå§‹çš„ã€æœ‰é¢¨éšªçš„ `user_input`ï¼Œè€Œæ˜¯ç›´æ¥å¾ `ConversationGraphState` ä¸­è®€å–ç”±ä¸Šæ¸¸ `retrieve_memories_node` ç”Ÿæˆçš„ã€çµ•å°å®‰å…¨çš„ `sanitized_query_for_tools` ä¾†æå–å¯¦é«”ã€‚æ­¤ä¿®æ”¹ä½¿å…¶å®Œå…¨å…ç–«æ–¼å› è¼¸å…¥å…§å®¹å¯©æŸ¥è€Œå°è‡´çš„æ›èµ·æˆ–éŒ¯èª¤ã€‚
# v28.0 (2025-09-12): [ç½é›£æ€§BUGä¿®å¾©] å°ˆç”¨LOREæŸ¥è©¢ç¯€é»ï¼Œå¾è³‡æ–™åº«ç²å–èˆ‡ç•¶å‰è¼¸å…¥å’Œã€æ•´å€‹å ´æ™¯ã€‘ç›¸é—œçš„æ‰€æœ‰ã€éä¸»è§’ã€‘LOREå°è±¡ã€‚
async def query_lore_node(state: ConversationGraphState) -> Dict:
    """[v29.0 é©é…å®‰å…¨æŸ¥è©¢] å°ˆç”¨LOREæŸ¥è©¢ç¯€é»ï¼Œä½¿ç”¨é æ¸…æ´—éçš„æŸ¥è©¢æ–‡æœ¬ä¾†æå–å¯¦é«”ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    # [v29.0 æ ¸å¿ƒä¿®æ­£] ä½¿ç”¨ä¸Šæ¸¸ç¯€é»ç”Ÿæˆçš„å®‰å…¨æŸ¥è©¢æ–‡æœ¬
    safe_query_text = state['sanitized_query_for_tools']
    logger.info(f"[{user_id}] (Graph|3) Node: query_lore -> æ­£åœ¨åŸºæ–¼ã€å®‰å…¨æŸ¥è©¢æ–‡æœ¬ã€‘ '{safe_query_text[:30]}...' åŸ·è¡ŒLOREæŸ¥è©¢...")

    if not ai_core.profile:
        logger.error(f"[{user_id}] (LORE Querier) ai_core.profile æœªåŠ è¼‰ï¼Œç„¡æ³•æŸ¥è©¢LOREã€‚")
        return {"raw_lore_objects": []}

    gs = ai_core.profile.game_state
    
    effective_location_path: List[str]
    if gs.viewing_mode == 'remote' and gs.remote_target_path:
        effective_location_path = gs.remote_target_path
    else:
        effective_location_path = gs.location_path
    
    logger.info(f"[{user_id}] (LORE Querier) å·²é–å®šæœ‰æ•ˆå ´æ™¯: {' > '.join(effective_location_path)}")

    lores_in_scene = await lore_book.get_lores_by_category_and_filter(
        user_id,
        'npc_profile',
        lambda c: c.get('location_path') == effective_location_path
    )
    logger.info(f"[{user_id}] (LORE Querier) åœ¨æœ‰æ•ˆå ´æ™¯ä¸­æ‰¾åˆ° {len(lores_in_scene)} ä½å¸¸é§NPCã€‚")

    # [v29.0 æ ¸å¿ƒä¿®æ­£] ä½¿ç”¨å®‰å…¨æŸ¥è©¢æ–‡æœ¬é€²è¡Œå¯¦é«”æå–
    is_remote = gs.viewing_mode == 'remote'
    lores_from_input = await ai_core._query_lore_from_entities(safe_query_text, is_remote_scene=is_remote)
    logger.info(f"[{user_id}] (LORE Querier) å¾å®‰å…¨æŸ¥è©¢æ–‡æœ¬ä¸­æå–ä¸¦æŸ¥è©¢åˆ° {len(lores_from_input)} æ¢ç›¸é—œLOREã€‚")

    final_lores_map = {lore.key: lore for lore in lores_in_scene}
    for lore in lores_from_input:
        if lore.key not in final_lores_map:
            final_lores_map[lore.key] = lore
            
    protected_names = {
        ai_core.profile.user_profile.name.lower(),
        ai_core.profile.ai_profile.name.lower()
    }
    
    filtered_lores_list = []
    for lore in final_lores_map.values():
        lore_name = lore.content.get('name', '').lower()
        if lore_name not in protected_names:
            filtered_lores_list.append(lore)
        else:
            logger.warning(f"[{user_id}] (LORE Querier) å·²éæ¿¾æ‰èˆ‡æ ¸å¿ƒä¸»è§’åŒåçš„LOREè¨˜éŒ„: '{lore.content.get('name')}'")

    logger.info(f"[{user_id}] (LORE Querier) ç¶“éä¸Šä¸‹æ–‡å„ªå…ˆåˆä½µèˆ‡éæ¿¾å¾Œï¼Œå…±é–å®š {len(filtered_lores_list)} æ¢LOREä½œç‚ºæœ¬å›åˆä¸Šä¸‹æ–‡ã€‚")
    
    return {"raw_lore_objects": filtered_lores_list}
# å‡½å¼ï¼šæŸ¥è©¢ LORE ç¯€é» (v29.0 - é©é…å®‰å…¨æŸ¥è©¢)

# å‡½å¼ï¼šæ„ŸçŸ¥å¹¶è®¾å®šè§†è§’
async def perceive_and_set_view_node(state: ConversationGraphState) -> Dict:
    """
    [v30.0 ä¿®æ­£] ä¸€ä¸ªç»Ÿä¸€çš„èŠ‚ ç‚¹ï¼Œè´Ÿè´£åˆ†æåœºæ™¯ã€æ ¹æ®æ„å›¾è®¾å®šè§†è§’ã€å¹¶æŒä¹…åŒ–çŠ¶æ€ã€‚
    å…¶èŒè´£å·²è¢«ç²¾ç®€ï¼Œä¸å†è´Ÿè´£ç»„è£…ä¸Šä¸‹æ–‡ï¼Œåªä¸“æ³¨äºè§†è§’çš„åˆ†æä¸æ›´æ–°ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    intent = state['intent_classification'].intent_type
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: perceive_and_set_view -> æ­£åœ¨åŸºæ–¼æ„åœ– '{intent}' ç»Ÿä¸€å¤„ç†æ„ŸçŸ¥ä¸è§†è§’...")

    if not ai_core.profile:
        return {"scene_analysis": SceneAnalysisResult(viewing_mode='local', reasoning='é”™è¯¯ï¼šAI profile æœªåŠ è½½ã€‚', action_summary=user_input)}

    gs = ai_core.profile.game_state
    new_viewing_mode = gs.viewing_mode
    new_target_path = gs.remote_target_path

    if 'descriptive' in intent:
        logger.info(f"[{user_id}] (View Mode) æ£€æµ‹åˆ°æè¿°æ€§æ„å›¾ï¼Œå‡†å¤‡è¿›å…¥/æ›´æ–°è¿œç¨‹è§†è§’ã€‚")
        
        # ä¸ºäº†è¿›è¡Œåœ°ç‚¹æ¨æ–­ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªä¸´æ—¶çš„ã€è½»é‡çº§çš„ä¸Šä¸‹æ–‡
        scene_context_lores = [lore.content for lore in state.get('raw_lore_objects_for_view_decision', []) if lore.category == 'npc_profile']
        scene_context_json_str = json.dumps(scene_context_lores, ensure_ascii=False, indent=2)
        
        location_chain = ai_core.get_contextual_location_chain()
        location_result = await ai_core.ainvoke_with_rotation(
            location_chain, 
            {
                "user_input": user_input,
                "world_settings": ai_core.profile.world_settings or "æœªè®¾å®š",
                "scene_context_json": scene_context_json_str
            }
        )
        
        extracted_path = location_result.location_path if location_result else None
        
        if extracted_path:
            new_viewing_mode = 'remote'
            new_target_path = extracted_path
        else:
            logger.warning(f"[{user_id}] (Perception Hub) æè¿°æ€§æ„å›¾æœªèƒ½æ¨æ–­å‡ºæœ‰æ•ˆåœ°ç‚¹ï¼Œå°†å›é€€åˆ°æœ¬åœ°æ¨¡å¼ã€‚")
            new_viewing_mode = 'local'
            new_target_path = None
            
    else:
        new_viewing_mode = 'local'
        new_target_path = None

    if gs.viewing_mode != new_viewing_mode or gs.remote_target_path != new_target_path:
        gs.viewing_mode = new_viewing_mode
        gs.remote_target_path = new_target_path
        await ai_core.update_and_persist_profile({'game_state': gs.model_dump()})
        logger.info(f"[{user_id}] (Perception Hub) GameState å·²æ›´æ–°: mode={gs.viewing_mode}, path={gs.remote_target_path}")
    else:
        logger.info(f"[{user_id}] (Perception Hub) GameState æ— éœ€æ›´æ–°ã€‚")

    scene_analysis = SceneAnalysisResult(
        viewing_mode=gs.viewing_mode,
        reasoning=f"åŸºæ–¼æ„åœ– '{intent}' çš„ç»Ÿä¸€æ„ŸçŸ¥ç»“æœã€‚",
        target_location_path=gs.remote_target_path,
        focus_entity=None,
        action_summary=user_input
    )
    
    # [v30.0 æ ¸å¿ƒä¿®æ­£] ä¸å†è¿”å› structured_contextï¼Œå› ä¸º LORE æ•°æ®å°šæœªå®Œå…¨æŸ¥è¯¢
    return {"scene_analysis": scene_analysis}
# å‡½å¼ï¼šæ„ŸçŸ¥å¹¶è®¾å®šè§†è§’



# å‡½å¼ï¼šç»„è£…ä¸Šä¸‹æ–‡ (v30.2 - Pydantic ç‰©ä»¶è¨ªå•ä¿®æ­£)
# æ›´æ–°ç´€éŒ„:
# v30.2 (2025-09-09): [ç½é›£æ€§BUGä¿®å¾©] æ ¹æ“š AttributeError Tracebackï¼Œå¾¹åº•ä¿®æ­£äº†ä¸Šä¸€ç‰ˆå¼•å…¥çš„èªæ³•éŒ¯èª¤ã€‚èˆŠç‰ˆæœ¬éŒ¯èª¤åœ°å° Pydantic ç‰©ä»¶ä½¿ç”¨äº†å­—å…¸çš„ .get() æ–¹æ³•ã€‚æ–°ç‰ˆæœ¬æ”¹ç‚ºä½¿ç”¨æ­£ç¢ºçš„ã€å¸¶æœ‰ None æª¢æŸ¥çš„ç‰©ä»¶å±¬æ€§é»è™Ÿè¡¨ç¤ºæ³•ï¼ˆ`scene_analysis.viewing_mode if scene_analysis else False`ï¼‰ï¼Œå¾æ ¹æœ¬ä¸Šè§£æ±ºäº†å› æ­¤å¼•ç™¼çš„å´©æ½°å•é¡Œã€‚
# v30.1 (2025-09-09): [ç½é›£æ€§BUGä¿®å¾©] å¼·åŒ–äº†æ­¤ç¯€é»çš„é˜²ç¦¦æ€§ç¨‹å¼è¨­è¨ˆã€‚
async def assemble_context_node(state: ConversationGraphState) -> Dict:
    """
    [v30.2 ä¿®æ­£] ä¸€å€‹å…¨æ–°çš„ã€è·è²¬å–®ä¸€çš„ç¯€é»ã€‚
    å®ƒçš„å”¯ä¸€ä»»å‹™æ˜¯åœ¨ LORE æŸ¥è©¢å®Œæˆåï¼Œå°‡æ‰€æœ‰ LORE æ•¸æ“šå’ŒéŠæˆ²ç‹€æ…‹çµ„è£æˆæœ€çµ‚çš„ structured_contextã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    raw_lore_objects = state.get('raw_lore_objects', [])
    
    # [v30.2 æ ¸å¿ƒä¿®æ­£] ä½¿ç”¨æ­£ç¢ºçš„ç‰©ä»¶å±¬æ€§è¨ªå•èªæ³•ï¼Œä¸¦å®‰å…¨åœ°è™•ç† None çš„æƒ…æ³
    scene_analysis = state.get('scene_analysis') 
    is_remote_scene = scene_analysis.viewing_mode == 'remote' if scene_analysis else False
    
    logger.info(f"[{user_id}] (Graph) Node: assemble_context -> æ­£åœ¨å°† {len(raw_lore_objects)} æ¡ LORE è®°å½•ç»„è£…ä¸ºæœ€ç»ˆä¸Šä¸‹æ–‡...")
    
    structured_context = ai_core._assemble_context_from_lore(raw_lore_objects, is_remote_scene=is_remote_scene)
    
    return {"structured_context": structured_context}
# å‡½å¼ï¼šç»„è£…ä¸Šä¸‹æ–‡ (v30.2 - Pydantic ç‰©ä»¶è¨ªå•ä¿®æ­£)




# å‡½å¼ï¼šLOREæ“´å±•æ±ºç­– (v32.0 - å¥å£¯æ€§èˆ‡å®‰å…¨æŸ¥è©¢é©é…)
# æ›´æ–°ç´€éŒ„:
# v32.0 (2025-09-09): [ç½é›£æ€§BUGä¿®å¾©] ç‚ºäº†å¾æ ¹æœ¬ä¸Šè§£æ±º LangChain Prompt è§£æå™¨å› ç¯„ä¾‹ä¸­çš„ JSON èªæ³•è€Œå¼•ç™¼çš„ KeyErrorï¼Œæ­¤ç¯€é»ç¾åœ¨è² è²¬å‹•æ…‹æ§‹å»ºä¸€å€‹åŒ…å«æ­£ç¢ºè½‰ç¾©ï¼ˆä½¿ç”¨é›™å¤§æ‹¬è™Ÿ `{{}}`ï¼‰çš„ç¯„ä¾‹å­—ç¬¦ä¸²ï¼Œä¸¦å°‡å…¶å®‰å…¨åœ°æ³¨å…¥åˆ°æ±ºç­–éˆä¸­ã€‚
# v31.0 (2025-09-12): [ç½é›£æ€§BUGä¿®å¾©] LOREæ“´å±•æ±ºç­–ç¯€é»ã€‚
async def expansion_decision_node(state: ConversationGraphState) -> Dict:
    """
    [v32.0 ä¿®æ­£] LOREæ“´å±•æ±ºç­–ç¯€é»ï¼Œä½¿ç”¨é æ¸…æ´—éçš„æŸ¥è©¢æ–‡æœ¬é€²è¡Œæ±ºç­–ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    safe_query_text = state['sanitized_query_for_tools']
    raw_lore_objects = state.get('raw_lore_objects', [])
    logger.info(f"[{user_id}] (Graph|5) Node: expansion_decision -> æ­£åœ¨åŸºæ–¼ã€å®‰å…¨æŸ¥è©¢æ–‡æœ¬ã€‘ '{safe_query_text[:30]}...' åˆ¤æ–·æ˜¯å¦æ“´å±•...")

    lightweight_lore_for_decision = []
    for lore in raw_lore_objects:
        if lore.category == 'npc_profile':
            content = lore.content
            lightweight_lore_for_decision.append({
                "name": content.get("name"),
                "gender": content.get("gender"),
                "description": content.get("description")
            })

    lore_json_str = json.dumps(lightweight_lore_for_decision, ensure_ascii=False, indent=2)
    
    # [v32.0 æ ¸å¿ƒä¿®æ­£] å‹•æ…‹æ§‹å»ºåŒ…å«æ­£ç¢ºè½‰ç¾©çš„ç¯„ä¾‹å­—ç¬¦ä¸²
    examples_str = """
- **æƒ…å¢ƒ 1**: 
    - ç¾æœ‰è§’è‰²JSON: `[{{"name": "æµ·å¦–åŸ", "description": "ä¸€ä½è²©è³£æ´»é­šçš„å¥³æ€§æ€§ç¥æ•™å¾’..."}}]`
    - ä½¿ç”¨è€…è¼¸å…¥: `ç»§ç»­æè¿°é‚£ä¸ªå–é±¼çš„å¥³äºº`
    - **ä½ çš„æ±ºç­–**: `should_expand: false` (ç†ç”±æ‡‰é¡ä¼¼æ–¼: å ´æ™¯ä¸­å·²å­˜åœ¨ç¬¦åˆ 'è³£é­šçš„å¥³äºº' æè¿°çš„è§’è‰² (ä¾‹å¦‚ 'æµ·å¦–åŸ')ï¼Œæ‡‰å„ªå…ˆèˆ‡å…¶äº’å‹•ã€‚)
- **æƒ…å¢ƒ 2**:
    - ç¾æœ‰è§’è‰²JSON: `[{{"name": "æµ·å¦–åŸ", "description": "ä¸€ä½å¥³æ€§æ€§ç¥æ•™å¾’..."}}]`
    - ä½¿ç”¨è€…è¼¸å…¥: `é€™æ™‚ä¸€å€‹è¡›å…µèµ°äº†éä¾†`
    - **ä½ çš„æ±ºç­–**: `should_expand: true` (ç†ç”±æ‡‰é¡ä¼¼æ–¼: å ´æ™¯ä¸­ç¼ºä¹èƒ½å¤ æ‰®æ¼” 'è¡›å…µ' çš„è§’è‰²ï¼Œéœ€è¦å‰µå»ºæ–°è§’è‰²ä»¥éŸ¿æ‡‰æŒ‡ä»¤ã€‚)
"""

    decision_chain = ai_core.get_expansion_decision_chain()
    decision = await ai_core.ainvoke_with_rotation(
        decision_chain, 
        {
            "user_input": safe_query_text,
            "existing_characters_json": lore_json_str,
            "examples": examples_str
        },
        retry_strategy='euphemize'
    )

    if not decision:
        logger.warning(f"[{user_id}] (Graph|5) LOREæ“´å±•æ±ºç­–éˆå¤±æ•—ï¼Œå®‰å…¨å‚™æ´ç‚ºä¸æ“´å±•ã€‚")
        decision = ExpansionDecision(should_expand=False, reasoning="å®‰å…¨å‚™æ´ï¼šæ±ºç­–éˆå¤±æ•—ã€‚")
    
    logger.info(f"[{user_id}] (Graph|5) LOREæ“´å±•æ±ºç­–: {decision.should_expand}ã€‚ç†ç”±: {decision.reasoning}")
    return {"expansion_decision": decision}
# å‡½å¼ï¼šLOREæ“´å±•æ±ºç­– (v32.0 - å¥å£¯æ€§èˆ‡å®‰å…¨æŸ¥è©¢é©é…)




async def character_quantification_node(state: ConversationGraphState) -> Dict:
    """[6A.1] å°‡æ¨¡ç³Šçš„ç¾¤é«”æè¿°è½‰åŒ–ç‚ºå…·é«”çš„è§’è‰²åˆ—è¡¨ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph|6A.1) Node: character_quantification -> æ­£åœ¨é‡åŒ–è¼¸å…¥ä¸­çš„è§’è‰²...")

    quantification_chain = ai_core.get_character_quantification_chain()
    quantification_result = await ai_core.ainvoke_with_rotation(
        quantification_chain,
        {"user_input": user_input},
        retry_strategy='euphemize'
    )

    if not quantification_result or not quantification_result.character_descriptions:
        logger.warning(f"[{user_id}] (Graph|6A.1) è§’è‰²é‡åŒ–éˆå¤±æ•—æˆ–è¿”å›ç©ºåˆ—è¡¨ï¼ŒLOREæ“´å±•å°‡è¢«è·³éã€‚")
        return {"quantified_character_list": []}
    
    logger.info(f"[{user_id}] (Graph|6A.1) è§’è‰²é‡åŒ–æˆåŠŸï¼Œè­˜åˆ¥å‡º {len(quantification_result.character_descriptions)} å€‹å¾…å‰µå»ºè§’è‰²ã€‚")
    return {"quantified_character_list": quantification_result.character_descriptions}

async def lore_expansion_node(state: ConversationGraphState) -> Dict:
    """[6A.2] å°ˆç”¨çš„LOREæ“´å±•åŸ·è¡Œç¯€é»ï¼Œç‚ºé‡åŒ–å¾Œçš„è§’è‰²åˆ—è¡¨å‰µå»ºæª”æ¡ˆã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    existing_lores = state.get('raw_lore_objects', [])
    quantified_character_list = state.get('quantified_character_list', [])
    
    logger.info(f"[{user_id}] (Graph|6A.2) Node: lore_expansion -> æ­£åœ¨ç‚º {len(quantified_character_list)} å€‹é‡åŒ–è§’è‰²åŸ·è¡Œé¸è§’...")
    
    if not quantified_character_list:
        logger.info(f"[{user_id}] (Graph|6A.2) é‡åŒ–è§’è‰²åˆ—è¡¨ç‚ºç©ºï¼Œè·³éLOREæ“´å±•ã€‚")
        planning_subjects = [lore.content for lore in existing_lores if lore.category == 'npc_profile']
        return {"planning_subjects": planning_subjects}

    if not ai_core.profile:
        logger.error(f"[{user_id}] (Graph|6A.2) ai_core.profile æœªåŠ è¼‰ï¼Œè·³é LORE æ“´å±•ã€‚")
        return {}

    gs = ai_core.profile.game_state
    effective_location_path = gs.remote_target_path if gs.viewing_mode == 'remote' and gs.remote_target_path else gs.location_path

    cast_result = await ai_core.ainvoke_with_rotation(
        ai_core.get_scene_casting_chain(),
        {
            "world_settings": ai_core.profile.world_settings or "", 
            "current_location_path": effective_location_path,
            "character_descriptions_list": quantified_character_list
        },
        retry_strategy='euphemize'
    )
    
    if cast_result and cast_result.implied_location:
        location_info = cast_result.implied_location
        base_path = [gs.location_path[0]] if gs.location_path else ["æœªçŸ¥å€åŸŸ"]
        new_location_path = base_path + [location_info.name]
        lore_key = " > ".join(new_location_path)
        
        await lore_book.add_or_update_lore(user_id, 'location_info', lore_key, location_info.model_dump())
        logger.info(f"[{user_id}] (Scene Anchor) å·²æˆåŠŸç‚ºå ´æ™¯éŒ¨å®šä¸¦å‰µå»ºæ–°åœ°é»LORE: '{lore_key}'")
        
        gs.viewing_mode = 'remote'
        gs.remote_target_path = new_location_path
        await ai_core.update_and_persist_profile({'game_state': gs.model_dump()})
        logger.info(f"[{user_id}] (Scene Anchor) GameState å·²å¼·åˆ¶æ›´æ–°ç‚ºé ç¨‹è¦–è§’ï¼Œç›®æ¨™: {new_location_path}")

    planning_subjects = [lore.content for lore in existing_lores if lore.category == 'npc_profile']
    
    if cast_result and (cast_result.newly_created_npcs or cast_result.supporting_cast):
        created_names = await ai_core._add_cast_to_scene(cast_result)
        logger.info(f"[{user_id}] (Graph|6A.2) é¸è§’å®Œæˆï¼Œå‰µå»ºäº† {len(created_names)} ä½æ–°è§’è‰²: {', '.join(created_names)}.")
        
        if created_names:
            newly_created_lores = await lore_book.get_lores_by_category_and_filter(user_id, 'npc_profile', lambda c: c.get('name') in created_names)
            if newly_created_lores:
                planning_subjects.extend([lore.content for lore in newly_created_lores])
    
    logger.info(f"[{user_id}] (Graph|6A.2) å·²å°‡ {len(planning_subjects)} ä½è§’è‰² (æ–°èˆŠåˆä½µ) æˆåŠŸç¶å®šç‚ºæœ¬å›åˆçš„è¦åŠƒä¸»é«”ã€‚")
    return {"planning_subjects": planning_subjects}

async def sfw_planning_node(state: ConversationGraphState) -> Dict[str, TurnPlan]:
    """[7A] SFWè·¯å¾‘å°ˆç”¨è¦åŠƒå™¨ï¼Œç”Ÿæˆçµæ§‹åŒ–è¡Œå‹•è¨ˆåŠƒã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph|7A) Node: sfw_planning -> æ­£åœ¨åŸºæ–¼æŒ‡ä»¤ '{user_input[:50]}...' ç”ŸæˆSFWè¡Œå‹•è¨ˆåŠƒ...")

    if not ai_core.profile:
        return {"turn_plan": TurnPlan(execution_rejection_reason="éŒ¯èª¤ï¼šAI profile æœªåŠ è¼‰ï¼Œç„¡æ³•è¦åŠƒã€‚")}

    planning_subjects_raw = state.get('planning_subjects')
    if planning_subjects_raw is None:
        lore_objects = state.get('raw_lore_objects', [])
        planning_subjects_raw = [lore.content for lore in lore_objects if lore.category == 'npc_profile']
    planning_subjects_json = json.dumps(planning_subjects_raw, ensure_ascii=False, indent=2)

    gs = ai_core.profile.game_state
    chat_history_str = await _get_summarized_chat_history(ai_core, user_id)

    full_context_dict = {
        'username': ai_core.profile.user_profile.name,
        'ai_name': ai_core.profile.ai_profile.name,
        'world_settings': ai_core.profile.world_settings or "æœªè¨­å®š",
        'ai_settings': ai_core.profile.ai_profile.description or "æœªè¨­å®š",
        'retrieved_context': state.get('rag_context', ''),
        'possessions_context': state.get('structured_context', {}).get('possessions_context', ''),
        'quests_context': state.get('structured_context', {}).get('quests_context', ''),
        'location_context': state.get('structured_context', {}).get('location_context', ''),
        'npc_context': "(å·²æ£„ç”¨ï¼Œè«‹åƒè€ƒ planning_subjects_json)",
        'relevant_npc_context': "(å·²æ£„ç”¨ï¼Œè«‹åƒè€ƒ planning_subjects_json)",
        'player_location': " > ".join(gs.location_path),
        'viewing_mode': gs.viewing_mode,
        'remote_target_path_str': " > ".join(gs.remote_target_path) if gs.remote_target_path else "æœªæŒ‡å®š",
    }
    world_snapshot = ai_core.world_snapshot_template.format(**full_context_dict)
    
    plan = await ai_core.ainvoke_with_rotation(
        ai_core.get_sfw_planning_chain(), 
        {
            "one_instruction": ai_core.profile.one_instruction, 
            "response_style_prompt": ai_core.profile.response_style_prompt or "é è¨­é¢¨æ ¼",
            "world_snapshot": world_snapshot, 
            "chat_history": chat_history_str,
            "planning_subjects_json": planning_subjects_json,
            "user_input": user_input,
        },
        retry_strategy='euphemize'
    )
    if not plan:
        plan = TurnPlan(execution_rejection_reason="å®‰å…¨å‚™æ´ï¼šSFWè¦åŠƒéˆå¤±æ•—ã€‚")
    return {"turn_plan": plan}


# å‡½å¼ï¼šç²å–åŸå§‹å°è©±æ­·å² (v1.0 - å…¨æ–°å‰µå»º)
# æ›´æ–°ç´€éŒ„:
# v1.0 (2025-09-08): [é‡å¤§æ¶æ§‹å‡ç´š] å‰µå»ºæ­¤å…¨æ–°çš„è¼”åŠ©å‡½å¼ï¼Œå°ˆé–€ç”¨æ–¼åœ¨è™•ç†â€œç»§ç»­â€ç­‰å»¶ç»­æ€§æŒ‡ä»¤æ™‚ï¼Œç‚ºç”Ÿæˆç¯€é»æä¾›æœªç¶“æ‘˜è¦çš„ã€æœ€åŸå§‹ã€æœ€å®Œæ•´çš„æœ€è¿‘å°è©±æ­·å²ã€‚é€™èƒ½ç¢ºä¿ AI åœ¨çºŒå¯«æ™‚æ“æœ‰æœ€ç²¾ç¢ºçš„ä¸Šä¸‹æ–‡ï¼Œé¿å…å› æ‘˜è¦é€ æˆçš„ä¿¡æ¯æå¤±è€Œå°è‡´åŠ‡æƒ…åé›¢ã€‚
def _get_raw_chat_history(ai_core: AILover, user_id: str, num_messages: int = 4) -> str:
    """ä¸€å€‹å°ˆé–€çš„è¼”åŠ©å‡½å¼ï¼Œç”¨æ–¼ç‚ºâ€œç»§ç»­â€ç­‰å»¶ç»­æ€§æŒ‡ä»¤æä¾›æœªç¶“æ‘˜è¦çš„åŸå§‹å°è©±æ­·å²ã€‚"""
    if not ai_core.profile: return "ï¼ˆæ²’æœ‰æœ€è¿‘çš„å°è©±æ­·å²ï¼‰"
    chat_history_manager = ai_core.session_histories.get(user_id, ChatMessageHistory())
    if not chat_history_manager.messages:
        return "ï¼ˆæ²’æœ‰æœ€è¿‘çš„å°è©±æ­·å²ï¼‰"
    
    # ç²å–æœ€è¿‘çš„å¹¾æ¢æ¶ˆæ¯ï¼ˆä½¿ç”¨è€… + AI ç‚ºä¸€çµ„ï¼‰
    recent_messages = chat_history_manager.messages[-num_messages:]
    
    formatted_history = []
    for msg in recent_messages:
        role = "ä½¿ç”¨è€…" if isinstance(msg, HumanMessage) else "AI"
        formatted_history.append(f"{role}: {msg.content}")
        
    return "\n".join(formatted_history)
# å‡½å¼ï¼šç²å–åŸå§‹å°è©±æ­·å² (v1.0 - å…¨æ–°å‰µå»º)


# å‡½å¼ï¼šç²å–æ‘˜è¦å¾Œçš„å°è©±æ­·å² (v28.0 - çµ‚æ¥µå‚™æ´ä¿®æ­£)
# æ›´æ–°ç´€éŒ„:
# v28.0 (2025-09-08): [ç½é›£æ€§BUGä¿®å¾©] å¾¹åº•é‡æ§‹äº†æ­¤å‡½å¼çš„çµ‚æ¥µå‚™æ´é‚è¼¯ã€‚èˆŠç‰ˆæœ¬åœ¨æ‰€æœ‰æ‘˜è¦å˜—è©¦å¤±æ•—å¾Œï¼Œæœƒä¸å®‰å…¨åœ°è¿”å›åŸå§‹çš„ã€æœªç¶“è™•ç†çš„å°è©±æ­·å²ï¼Œé€™æ˜¯å°è‡´ AIâ€œå·æ‡¶â€ä¸¦é‡è¤‡æ­·å²æ–‡æœ¬çš„æ ¹æœ¬åŸå› ã€‚æ–°ç‰ˆæœ¬åœ¨æ‰€æœ‰å˜—è©¦å¤±æ•—å¾Œï¼Œå°‡è¿”å›ä¸€å€‹å®‰å…¨çš„ä¸­æ€§æç¤ºå­—ç¬¦ä¸²ï¼Œå¾è€Œåˆ‡æ–·äº†å°‡é‡è¤‡æˆ–éœ²éª¨å…§å®¹æ±¡æŸ“åˆ°ä¸‹æ¸¸éˆçš„æ•¸æ“šæºã€‚
# v27.0 (2025-09-08): [ç½é›£æ€§BUGä¿®å¾©] è£œå……äº†ç¼ºå¤±çš„å°å…¥èªå¥ã€‚
async def _get_summarized_chat_history(ai_core: AILover, user_id: str, num_messages: int = 8) -> str:
    """
    [v28.0 ä¿®æ­£] æå–ä¸¦æ‘˜è¦æœ€è¿‘çš„å°è©±æ­·å²ï¼Œä¸¦å…§å»ºä¸€å€‹å¼·å¤§çš„ã€åŸºæ–¼ã€Œæ–‡å­¸è©•è«–å®¶ã€é‡å¯«çš„ NSFW å…§å®¹å®‰å…¨å‚™æ´æ©Ÿåˆ¶ã€‚
    """
    if not ai_core.profile: return "ï¼ˆæ²’æœ‰æœ€è¿‘çš„å°è©±æ­·å²ï¼‰"
    chat_history_manager = ai_core.session_histories.get(user_id, ChatMessageHistory())
    if not chat_history_manager.messages:
        return "ï¼ˆæ²’æœ‰æœ€è¿‘çš„å°è©±æ­·å²ï¼‰"
        
    recent_messages = chat_history_manager.messages[-num_messages:]
    if not recent_messages:
        return "ï¼ˆæ²’æœ‰æœ€è¿‘çš„å°è©±æ­·å²ï¼‰"

    raw_history_text = "\n".join([f"{'ä½¿ç”¨è€…' if isinstance(m, HumanMessage) else 'AI'}: {m.content}" for m in recent_messages])

    # å‰µå»ºå³æ™‚çš„ã€è¼•é‡ç´šçš„æ‘˜è¦éˆ
    summarizer_prompt_template = """ä½ çš„å”¯ä¸€ä»»å‹™æ˜¯æ‰®æ¼”ä¸€åå°èªªç·¨è¼¯ã€‚è«‹é–±è®€ä¸‹æ–¹çš„ã€å°è©±ç´€éŒ„ã€‘ï¼Œä¸¦å°‡å…¶æç…‰æˆä¸€æ®µç°¡æ½”çš„ã€å®¢è§€çš„ã€ç¬¬ä¸‰äººç¨±çš„ã€å‰æƒ…æè¦ã€‘ã€‚

ã€æ ¸å¿ƒè¦å‰‡ã€‘
1.  **åªæå–æ ¸å¿ƒåŠ‡æƒ…**: ä½ çš„æ‘˜è¦ã€å¿…é ˆä¸”åªèƒ½ã€‘åŒ…å«é—œéµçš„åŠ‡æƒ…ç™¼å±•ã€è§’è‰²çš„æ ¸å¿ƒè¡Œå‹•å’Œé‡è¦çš„ç‹€æ…‹è®ŠåŒ–ã€‚
2.  **ç¦æ­¢å°è©±**: ã€çµ•å°ç¦æ­¢ã€‘åœ¨æ‘˜è¦ä¸­åŒ…å«ä»»ä½•ç›´æ¥çš„å°è©±å¼•è™Ÿã€‚
3.  **ä¿æŒä¸­ç«‹**: ä¸è¦æ·»åŠ ä»»ä½•åŸå§‹æ–‡æœ¬ä¸­æ²’æœ‰çš„æ¨è«–æˆ–è©•è«–ã€‚
4.  **ç°¡æ½”è‡³ä¸Š**: ä½ çš„ç›®æ¨™æ˜¯ç”¨æœ€å°‘çš„æ–‡å­—è¬›æ¸…æ¥šæ•…äº‹çš„ä¾†é¾å»è„ˆã€‚

---
ã€å°è©±ç´€éŒ„ã€‘:
{dialogue_history}
---
ã€å‰æƒ…æè¦ã€‘:
"""
    summarizer_prompt = ChatPromptTemplate.from_template(summarizer_prompt_template)
    summarizer_llm = ai_core._create_llm_instance(temperature=0.0)
    summarizer_chain = summarizer_prompt | summarizer_llm | StrOutputParser()

    try:
        # --- æ­¥é©Ÿ 1: æ¨‚è§€å˜—è©¦ ---
        logger.info(f"[{user_id}] (History Summarizer) æ­£åœ¨æ¨‚è§€å˜—è©¦ç›´æ¥æ‘˜è¦åŸå§‹æ­·å²æ–‡æœ¬...")
        summary = await summarizer_chain.ainvoke({"dialogue_history": raw_history_text})

        if not summary or not summary.strip():
            raise Exception("SafetyError: Direct summarization returned empty content.")
            
        logger.info(f"[{user_id}] (History Summarizer) ç›´æ¥æ‘˜è¦æˆåŠŸã€‚")
        return f"ã€å‰æƒ…æè¦ã€‘:\n{summary}"

    except Exception as e:
        error_str = str(e).lower()
        if "safety" in error_str or "blocked" in error_str:
            logger.warning(f"[{user_id}] (History Summarizer) ç›´æ¥æ‘˜è¦å¤±æ•—ï¼Œè§¸ç™¼ã€æ–‡å­¸è©•è«–å®¶ã€‘NSFWå®‰å…¨å‚™æ´...")
            try:
                literary_chain = ai_core.get_literary_euphemization_chain()
                safe_literary_overview = await literary_chain.ainvoke({"dialogue_history": raw_history_text})
                
                if not safe_literary_overview or not safe_literary_overview.strip():
                    raise Exception("Literary euphemization also returned empty content.")

                logger.info(f"[{user_id}] (History Summarizer) æ–‡å­¸å¼å§”å©‰åŒ–æˆåŠŸï¼Œæ­£åœ¨åŸºæ–¼å®‰å…¨çš„æ¦‚è¿°é‡æ–°ç”Ÿæˆæ‘˜è¦...")
                
                final_summary = await summarizer_chain.ainvoke({"dialogue_history": safe_literary_overview})

                if not final_summary or not final_summary.strip():
                     raise Exception("Final summarization after euphemization returned empty content.")

                logger.info(f"[{user_id}] (History Summarizer) NSFW å®‰å…¨å‚™æ´æˆåŠŸå®Œæˆã€‚")
                return f"ã€å‰æƒ…æè¦ã€‘:\n{final_summary}"

            except Exception as fallback_e:
                # [v28.0 æ ¸å¿ƒä¿®æ­£] çµ‚æ¥µå‚™æ´ä¸å†è¿”å›åŸå§‹æ­·å²
                logger.error(f"[{user_id}] (History Summarizer) ã€æ–‡å­¸è©•è«–å®¶ã€‘å‚™æ´æ©Ÿåˆ¶æœ€çµ‚å¤±æ•—: {fallback_e}ã€‚å•Ÿå‹•çµ‚æ¥µå‚™æ´ã€‚", exc_info=False) # æ¸›å°‘æ—¥èªŒå™ªéŸ³
                return "ï¼ˆæ­·å²å°è©±æ‘˜è¦å› å…§å®¹å¯©æŸ¥è€Œç”Ÿæˆå¤±æ•—ï¼Œéƒ¨åˆ†ä¸Šä¸‹æ–‡å¯èƒ½ç¼ºå¤±ã€‚ï¼‰"
        else:
            logger.error(f"[{user_id}] (History Summarizer) ç”Ÿæˆæ‘˜è¦æ™‚ç™¼ç”Ÿéå®‰å…¨ç›¸é—œçš„æœªçŸ¥éŒ¯èª¤: {e}ã€‚å•Ÿå‹•çµ‚æ¥µå‚™æ´ã€‚", exc_info=True)
            return "ï¼ˆæ­·å²å°è©±æ‘˜è¦å› æŠ€è¡“éŒ¯èª¤è€Œç”Ÿæˆå¤±æ•—ï¼Œéƒ¨åˆ†ä¸Šä¸‹æ–‡å¯èƒ½ç¼ºå¤±ã€‚ï¼‰"
# å‡½å¼ï¼šç²å–æ‘˜è¦å¾Œçš„å°è©±æ­·å² (v28.0 - çµ‚æ¥µå‚™æ´ä¿®æ­£)



async def remote_sfw_planning_node(state: ConversationGraphState) -> Dict[str, TurnPlan]:
    """[7D] SFW æè¿°è·¯å¾‘å°ˆç”¨è¦åŠƒå™¨ï¼Œç”Ÿæˆé æ™¯å ´æ™¯çš„çµæ§‹åŒ–è¡Œå‹•è¨ˆåŠƒã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph|7D) Node: remote_sfw_planning -> æ­£åœ¨åŸºæ–¼æŒ‡ä»¤ '{user_input[:50]}...' ç”Ÿæˆé ç¨‹SFWå ´æ™¯è¨ˆåŠƒ...")

    if not ai_core.profile:
        return {"turn_plan": TurnPlan(execution_rejection_reason="éŒ¯èª¤ï¼šAI profile æœªåŠ è¼‰ï¼Œç„¡æ³•è¦åŠƒã€‚")}

    scene_analysis = state.get('scene_analysis')
    gs = ai_core.profile.game_state
    target_location_path: Optional[List[str]] = None

    if scene_analysis and scene_analysis.target_location_path:
        target_location_path = scene_analysis.target_location_path
        logger.info(f"[{user_id}] (Graph|7D) å·²å¾ç•¶å‰å›åˆåˆ†æä¸­ç²å–é ç¨‹ç›®æ¨™: {target_location_path}")
    elif gs.viewing_mode == 'remote' and gs.remote_target_path:
        target_location_path = gs.remote_target_path
        logger.warning(f"[{user_id}] (Graph|7D) ç•¶å‰å›åˆåˆ†ææœªæä¾›ç›®æ¨™ï¼Œå·²å¾æŒä¹…åŒ– GameState ä¸­æˆåŠŸå›é€€ã€‚ç›®æ¨™: {target_location_path}")
    else:
        error_msg = "éŒ¯èª¤ï¼šæœªèƒ½å¾ç•¶å‰å›åˆåˆ†ææˆ–æŒä¹…åŒ–ç‹€æ…‹ä¸­è§£æå‡ºé ç¨‹è§€å¯Ÿçš„ç›®æ¨™åœ°é»ã€‚"
        logger.error(f"[{user_id}] (Graph|7D) {error_msg}")
        return {"turn_plan": TurnPlan(execution_rejection_reason=error_msg)}

    target_location_path_str = " > ".join(target_location_path)
    
    planning_subjects_raw = state.get('planning_subjects')
    if planning_subjects_raw is None:
        lore_objects = state.get('raw_lore_objects', [])
        planning_subjects_raw = [lore.content for lore in lore_objects if lore.category == 'npc_profile']
    planning_subjects_json = json.dumps(planning_subjects_raw, ensure_ascii=False, indent=2)

    chat_history_str = await _get_summarized_chat_history(ai_core, user_id)

    full_context_dict = {
        'username': ai_core.profile.user_profile.name,
        'ai_name': ai_core.profile.ai_profile.name,
        'world_settings': ai_core.profile.world_settings or "æœªè¨­å®š",
        'ai_settings': ai_core.profile.ai_profile.description or "æœªè¨­å®š",
        'retrieved_context': state.get('rag_context', ''),
        'possessions_context': "(é ç¨‹è§€å¯Ÿæ¨¡å¼)",
        'quests_context': "(é ç¨‹è§€å¯Ÿæ¨¡å¼)",
        'location_context': f"é ç¨‹è§€å¯Ÿåœ°é»: {target_location_path_str}",
        'npc_context': "(å·²æ£„ç”¨ï¼Œè«‹åƒè€ƒ planning_subjects_json)",
        'relevant_npc_context': "(å·²æ£„ç”¨ï¼Œè«‹åƒè€ƒ planning_subjects_json)",
        'player_location': " > ".join(gs.location_path),
        'viewing_mode': 'remote',
        'remote_target_path_str': target_location_path_str,
    }
    world_snapshot = ai_core.world_snapshot_template.format(**full_context_dict)

    plan = await ai_core.ainvoke_with_rotation(
        ai_core.get_remote_sfw_planning_chain(),
        {
            "one_instruction": ai_core.profile.one_instruction, 
            "response_style_prompt": ai_core.profile.response_style_prompt or "é è¨­é¢¨æ ¼",
            "world_snapshot": world_snapshot,
            "chat_history": chat_history_str,
            "planning_subjects_json": planning_subjects_json,
            "target_location_path_str": target_location_path_str,
            "user_input": user_input,
        },
        retry_strategy='euphemize'
    )
    if not plan:
        plan = TurnPlan(execution_rejection_reason="å®‰å…¨å‚™æ´ï¼šé ç¨‹SFWè¦åŠƒéˆå¤±æ•—ã€‚")
    return {"turn_plan": plan}





# å‡½å¼ï¼šNSFW çªç ´ç¯€é» (v38.1 - æ•¸æ“šæµä¿®å¾©)
# æ›´æ–°ç´€éŒ„:
# v38.1 (2025-09-10): [ç½é›£æ€§BUGä¿®å¾©] ä¿®æ­£äº†å› ç¯€é»é‚è¼¯åˆä½µå°è‡´çš„æ•¸æ“šæµæ–·è£‚å•é¡Œã€‚æ­¤ç¯€é»çš„è¼¸å‡ºéµè¢«å¾éŒ¯èª¤çš„ `llm_response` æ¢å¾©ç‚ºæ­£ç¢ºçš„ `narrative_outline`ï¼Œä»¥ç¢ºä¿ä¸‹æ¸¸çš„ `nsfw_refinement_node` èƒ½å¤ æ¥æ”¶åˆ°å®ƒæ‰€æœŸæœ›çš„æ•…äº‹å¤§ç¶±è¼¸å…¥ï¼Œå¾è€Œè§£æ±ºäº† `KeyError: 'narrative_outline'` çš„å•é¡Œã€‚
# v38.0 (2025-09-10): [ç½é›£æ€§BUGä¿®å¾©] æ³¨å…¥äº†â€œæ•¸æ“šéš”é›¢â€é‚è¼¯ä»¥è§£æ±ºé æ™¯æ¨¡å¼ä¸‹çš„ä¸Šä¸‹æ–‡æ±¡æŸ“å•é¡Œã€‚
# v37.0 (2025-09-09): [ç½é›£æ€§BUGä¿®å¾©] å¯¦ç¾äº†â€œé›™è»Œæ­·å²ç®¡ç†â€ç­–ç•¥ä»¥æ­£ç¢ºè™•ç†â€œç¹¼çºŒâ€æŒ‡ä»¤ã€‚
async def nsfw_breakthrough_node(state: ConversationGraphState) -> Dict[str, Any]:
    """
    [NSFW Path] åŸ·è¡ŒæŒ‡ä»¤è½Ÿç‚¸çš„ç¬¬ä¸€æ­¥ï¼ˆæƒ…ç¯€æ¶æ§‹å¸«ï¼‰ï¼Œä¸¦æ¡ç”¨é›™è»Œæ­·å²ç®¡ç†èˆ‡é æ™¯æ•¸æ“šéš”é›¢ç­–ç•¥ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    input_analysis = state.get('input_analysis')
    logger.info(f"[{user_id}] (Graph|NSFW Chain Pt.1) Node: nsfw_breakthrough_node -> æ­£åœ¨ç”ŸæˆNSFWæ•…äº‹å¤§çº²è‰ç¨¿...")

    if not ai_core.profile:
        return {"narrative_outline": "ï¼ˆç³»çµ±éŒ¯èª¤ï¼šAI profile æœªåŠ è¼‰ï¼Œç„¡æ³•ç”Ÿæˆå…§å®¹ã€‚ï¼‰", "world_snapshot": ""}

    planning_subjects_raw = state.get('planning_subjects')
    if planning_subjects_raw is None:
        lore_objects = state.get('raw_lore_objects', [])
        planning_subjects_raw = [lore.content for lore in lore_objects if lore.category == 'npc_profile']
    planning_subjects_json = json.dumps(planning_subjects_raw, ensure_ascii=False, indent=2)

    gs = ai_core.profile.game_state
    
    user_input_for_chain: str
    chat_history_for_chain: str

    if input_analysis and input_analysis.input_type == 'continuation':
        logger.info(f"[{user_id}] (NSFW Node) æª¢æ¸¬åˆ°å»¶ç»­æ€§æŒ‡ä»¤ï¼Œæ­£åœ¨æº–å‚™é«˜ä¿çœŸä¸Šä¸‹æ–‡å’Œå¼·åŒ–å¼•å°å¥...")
        user_input_for_chain = "ä½¿ç”¨è€…è¦æ±‚ä½ æ·±å…¥ç´°ç¯€ã€æ¯«ä¸ä¿ç•™åœ°æ¥çºŒä¸Šä¸€å¹•çš„æƒ…ç¯€ï¼Œæ¨é€²è§’è‰²çš„äº’å‹•ï¼Œä¸¦åŠ åŠ‡å ´æ™¯çš„æ„Ÿå®˜åˆºæ¿€ã€‚"
        chat_history_for_chain = _get_raw_chat_history(ai_core, user_id, num_messages=8)
    else:
        logger.info(f"[{user_id}] (NSFW Node) æª¢æ¸¬åˆ°æ–°æŒ‡ä»¤ï¼Œæ­£åœ¨æº–å‚™æ‘˜è¦æ­·å²ä»¥é¼“å‹µå‰µæ–°...")
        user_input_for_chain = state['messages'][-1].content
        chat_history_for_chain = await _get_summarized_chat_history(ai_core, user_id)
    
    full_context_dict = {
        'username': ai_core.profile.user_profile.name,
        'ai_name': ai_core.profile.ai_profile.name,
        'world_settings': ai_core.profile.world_settings or "æœªè¨­å®š",
        'ai_settings': ai_core.profile.ai_profile.description or "æœªè¨­å®š",
        'retrieved_context': state.get('rag_context', ''),
        'quests_context': state.get('structured_context', {}).get('quests_context', ''),
        'location_context': state.get('structured_context', {}).get('location_context', ''),
        'relevant_npc_context': "(å·²æ•´åˆè‡³ä¸‹æ–¹æª”æ¡ˆ)",
        'viewing_mode': gs.viewing_mode,
        'remote_target_path_str': " > ".join(gs.remote_target_path) if gs.remote_target_path else "æœªæŒ‡å®š",
    }
    
    if gs.viewing_mode == 'remote':
        logger.warning(f"[{user_id}] (NSFW Node) æª¢æ¸¬åˆ°é æ™¯æ¨¡å¼ï¼Œæ­£åœ¨éš”é›¢æœ¬åœ°ä¸Šä¸‹æ–‡æ•¸æ“š...")
        full_context_dict['player_location'] = "ï¼ˆé ç¨‹è§€å¯Ÿæ¨¡å¼ï¼Œç©å®¶ä¸åœ¨å ´ï¼‰"
        full_context_dict['possessions_context'] = "ï¼ˆé ç¨‹è§€å¯Ÿæ¨¡å¼ï¼‰"
        remote_dossiers = []
        for char_data in planning_subjects_raw:
            name = char_data.get('name', 'æœªçŸ¥åç¨±')
            remote_dossiers.append(f"--- æª”æ¡ˆ: {name} ---\n- æè¿°: {char_data.get('description', 'ç„¡')}")
        full_context_dict['npc_context'] = "\n".join(remote_dossiers) if remote_dossiers else "é ç¨‹å ´æ™¯ä¸­ç„¡å·²çŸ¥çš„ç‰¹å®šæƒ…å ±ã€‚"
    else:
        full_context_dict['player_location'] = " > ".join(gs.location_path)
        full_context_dict['possessions_context'] = state.get('structured_context', {}).get('possessions_context', '')
        local_dossiers = []
        local_dossiers.append(f"--- æª”æ¡ˆ: {ai_core.profile.user_profile.name} (ä½¿ç”¨è€…è§’è‰²) ---\n- æè¿°: {ai_core.profile.user_profile.description}")
        local_dossiers.append(f"--- æª”æ¡ˆ: {ai_core.profile.ai_profile.name} (AI è§’è‰²) ---\n- æè¿°: {ai_core.profile.ai_profile.description}")
        for char_data in planning_subjects_raw:
            name = char_data.get('name', 'æœªçŸ¥åç¨±')
            local_dossiers.append(f"--- æª”æ¡ˆ: {name} ---\n- æè¿°: {char_data.get('description', 'ç„¡')}")
        full_context_dict['npc_context'] = "\n".join(local_dossiers)

    world_snapshot = ai_core.world_snapshot_template.format(**full_context_dict)

    outline_draft = await ai_core.ainvoke_with_rotation(
        ai_core.get_nsfw_breakthrough_planning_chain(),
        {
            "system_prompt": ai_core.profile.one_instruction,
            "action_sexual_content_prompt": ai_core.modular_prompts.get("action_sexual_content", "è­¦å‘Š:æ€§æ„›æ¨¡çµ„æœªåŠ è¼‰"),
            "response_style_prompt": ai_core.profile.response_style_prompt or "é è¨­é¢¨æ ¼",
            "world_snapshot": world_snapshot,
            "chat_history": chat_history_for_chain,
            "planning_subjects_json": planning_subjects_json,
            "user_input": user_input_for_chain,
        },
        retry_strategy='euphemize'
    )
    if not outline_draft:
        outline_draft = "å®‰å…¨å‚™æ´ï¼šNSFWå¤§çº²ç”Ÿæˆéˆæœ€ç»ˆå¤±è´¥ã€‚"
        
    # [v38.1 æ ¸å¿ƒä¿®æ­£] ç¢ºä¿å°‡çµæœæ”¾å…¥æ­£ç¢ºçš„éµä¸­
    return {"narrative_outline": outline_draft, "world_snapshot": world_snapshot}
# å‡½å¼ï¼šNSFW çªç ´ç¯€é» (v38.1 - æ•¸æ“šæµä¿®å¾©)




# å‡½å¼ï¼šNSFW æ½¤è‰²ç¯€é» (v2.0 - æ•¸æ“šæµä¿®å¾©)
# æ›´æ–°ç´€éŒ„:
# v2.0 (2025-09-10): [ç½é›£æ€§BUGä¿®å¾©] ä¿®æ­£äº†æ­¤ç¯€é»çš„è¼¸å‡ºé‚è¼¯ã€‚ç¾åœ¨å®ƒæœƒå°‡æ½¤è‰²å¾Œçš„çµæœæ­£ç¢ºåœ°æ”¾å› `narrative_outline` éµä¸­ï¼Œä»¥ç¢ºä¿æ•¸æ“šæµèƒ½å¤ é †åˆ©å‚³éåˆ°æœ€çµ‚çš„æ¸²æŸ“ç¯€é»ã€‚åŒæ™‚å¢åŠ äº†å°æ½¤è‰²å¤±æ•—çš„è™•ç†ï¼Œç¢ºä¿æµç¨‹çš„å¥å£¯æ€§ã€‚
async def nsfw_refinement_node(state: ConversationGraphState) -> Dict[str, str]:
    """[æ•¸æ“šå½è£-æ­¥é©Ÿ2] æ¥æ”¶å¤§ç¶±è‰ç¨¿ï¼Œä¸¦å°‡å…¶è±å¯Œç‚ºæœ€çµ‚çš„ã€è©³ç´°çš„æ•…äº‹å¤§ç¶±ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    narrative_outline_draft = state['narrative_outline']
    logger.info(f"[{user_id}] (Graph|NSFW Chain Pt.2) Node: nsfw_refinement -> æ­£åœ¨æ¶¦è‰²NSFWæ•…äº‹å¤§çº²...")

    if not ai_core.profile or "å®‰å…¨å‚™æ´" in narrative_outline_draft:
        # å¦‚æœä¸Šä¸€æ­¥å¤±æ•—ï¼Œç›´æ¥å°‡ç¾æœ‰å¤§ç¶±å‚³éä¸‹å»ï¼Œä¸é€²è¡Œä»»ä½•æ“ä½œ
        return {} 

    chat_history_str = _get_raw_chat_history(ai_core, user_id)
    world_snapshot = state.get('world_snapshot', '') 

    final_outline = await ai_core.ainvoke_with_rotation(
        ai_core.get_nsfw_refinement_chain(),
        {
            "system_prompt": ai_core.profile.one_instruction,
            "response_style_prompt": ai_core.profile.response_style_prompt or "é è¨­é¢¨æ ¼",
            "world_snapshot": world_snapshot,
            "chat_history": chat_history_str,
            "narrative_outline_draft": narrative_outline_draft
        },
        retry_strategy='euphemize'
    )
    if not final_outline or not final_outline.strip():
        logger.warning(f"[{user_id}] (Graph|NSFW Chain Pt.2) NSFWå¤§çº²æ¶¦è‰²é“¾è¿”å›ç©ºå€¼ï¼Œå°‡ä½¿ç”¨æœªç¶“æ½¤è‰²çš„åŸå§‹å¤§ç¶±ç¹¼çºŒæµç¨‹ã€‚")
        # è¿”å›ç©ºå­—å…¸ï¼Œlanggraphæœƒè‡ªå‹•æ²¿ç”¨ä¸Šä¸€æ­¥çš„narrative_outline
        return {}

    # [æ ¸å¿ƒä¿®æ­£] å°‡æ½¤è‰²å¾Œçš„çµæœæ”¾å›æ­£ç¢ºçš„éµä¸­
    return {"narrative_outline": final_outline}
# å‡½å¼ï¼šNSFW æ½¤è‰²ç¯€é» (v2.0 - æ•¸æ“šæµä¿®å¾©)

async def tool_execution_node(state: ConversationGraphState) -> Dict[str, str]:
    """[8] çµ±ä¸€çš„å·¥å…·åŸ·è¡Œç¯€é» (ä¸»è¦ç”¨æ–¼ SFW è·¯å¾‘)ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    plan = state.get('turn_plan') # turn_plan åªåœ¨ SFW è·¯å¾„ä¸­å­˜åœ¨
    logger.info(f"[{user_id}] (Graph|8) Node: tool_execution -> æ­£åœ¨åŸ·è¡Œè¡Œå‹•è¨ˆåŠƒä¸­çš„å·¥å…·...")
    
    if not plan or not plan.character_actions:
        return {"tool_results": "ç³»çµ±äº‹ä»¶ï¼šç„¡ä»»ä½•å·¥å…·è¢«èª¿ç”¨ã€‚"}
    try:
        results_summary = await ai_core._execute_planned_actions(plan)
    except Exception as e:
        logger.error(f"[{user_id}] (Graph|8) å·¥å…·åŸ·è¡Œæ™‚ç™¼ç”Ÿæœªæ•ç²çš„ç•°å¸¸: {e}", exc_info=True)
        results_summary = f"ç³»çµ±äº‹ä»¶ï¼šå·¥å…·åŸ·è¡Œæ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}"
    finally:
        tool_context.set_context(None, None)
    
    return {"tool_results": results_summary}

# [v22.0 æ–°å¢] æ¢å¤å¹¶é‡å‘½åçš„ SFW ä¸“ç”¨æ¸²æŸ“èŠ‚ç‚¹
async def sfw_narrative_rendering_node(state: ConversationGraphState) -> Dict[str, str]:
    """[SFW Path] å°† SFW çš„ TurnPlan æ¸²æŸ“æˆå°è¯´æ–‡æœ¬ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    turn_plan = state.get('turn_plan')
    logger.info(f"[{user_id}] (Graph|9 SFW) Node: sfw_narrative_rendering -> æ­£åœ¨å°‡ SFW è¡Œå‹•è¨ˆåŠƒæ¸²æŸ“ç‚ºå°èªª...")

    if not turn_plan:
        return {"llm_response": "ï¼ˆç³»çµ±éŒ¯èª¤ï¼šæœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„ SFW è¡Œå‹•è¨ˆåŠƒã€‚ï¼‰"}
        
    if turn_plan.execution_rejection_reason:
        logger.warning(f"[{user_id}] (SFW Narrator) æª¢æ¸¬åˆ°ä¸Šæ¸¸è¦åŠƒç¯€é»çš„åŸ·è¡Œå¦æ±ºï¼Œè·³éæ¸²æŸ“ã€‚ç†ç”±: {turn_plan.execution_rejection_reason}")
        return {"llm_response": turn_plan.execution_rejection_reason}
    
    chain_input = {
        "system_prompt": ai_core.profile.one_instruction if ai_core.profile else "é è¨­ç³»çµ±æŒ‡ä»¤",
        "response_style_prompt": ai_core.profile.response_style_prompt if ai_core.profile else "é è¨­é¢¨æ ¼",
        "turn_plan": turn_plan
    }
        
    narrative_text = await ai_core.ainvoke_with_rotation(
        ai_core.get_sfw_narrative_chain(),
        chain_input,
        retry_strategy='euphemize'
    )
    if not narrative_text:
        narrative_text = "ï¼ˆAI åœ¨å°‡ SFW è¨ˆåŠƒè½‰åŒ–ç‚ºæ•…äº‹æ™‚é­é‡äº†å…§å®¹å®‰å…¨é™åˆ¶ã€‚ï¼‰"
    return {"llm_response": narrative_text}







# å‡½å¼ï¼šæœ€çµ‚æ¸²æŸ“ç¯€é» (v2.0 - é©é…æºé ­éš”é›¢)
# æ›´æ–°ç´€éŒ„:
# v2.0 (2025-09-10): [ç½é›£æ€§BUGä¿®å¾©] ç‚ºäº†é…åˆæ¸²æŸ“éˆçš„â€œæºé ­éš”é›¢â€é‡æ§‹ï¼Œæ­¤ç¯€é»çš„é‚è¼¯è¢«å®Œå…¨é‡å¯«ã€‚å®ƒç¾åœ¨è² è²¬å°‡å®Œæ•´çš„ world_snapshot åˆ†è§£ç‚ºåŒ…å«æ•æ„ŸæŒ‡ä»¤çš„ `director_view_prompt` å’ŒåªåŒ…å«ç´”æ•¸æ“šçš„ `core_data_snapshot`ï¼Œç„¶å¾Œå°‡å®ƒå€‘åˆ†åˆ¥å‚³éçµ¦æ¸²æŸ“éˆä¸­å°æ‡‰çš„ system å’Œ human prompt å€åŸŸã€‚
async def final_rendering_node(state: ConversationGraphState) -> Dict[str, str]:
    """[æ•°æ®ä¼ªè£…-æœ€ç»ˆæ­¥éª¤] å°†æœ€ç»ˆçš„è‡ªç„¶è¯­è¨€å¤§çº²æ¸²æŸ“ä¸ºç”µå½±æ„Ÿå°è¯´ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    narrative_outline = state['narrative_outline']
    world_snapshot = state.get('world_snapshot', '')
    logger.info(f"[{user_id}] (Graph|Final Rendering) Node: final_rendering -> æ­£åœ¨å°†æ•…äº‹å¤§çº²æ¸²æŸ“ä¸ºæœ€ç»ˆå°è¯´...")

    if not narrative_outline or "å®‰å…¨å‚™æ´" in narrative_outline:
        return {"llm_response": narrative_outline or "ï¼ˆç³»ç»Ÿé”™è¯¯ï¼šæœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„å™äº‹å¤§çº²ã€‚ï¼‰"}
        
    # [v2.0 æ ¸å¿ƒä¿®æ­£] åˆ†é›¢å°æ¼”è¦–è§’æŒ‡ä»¤å’Œæ ¸å¿ƒæ•¸æ“š
    director_view_prompt = ""
    core_data_snapshot = world_snapshot
    
    director_view_pattern = r"(# ==============================================================================\n# == ğŸ‘ï¸ å°æ¼”è¦–è§’èˆ‡æƒ…å¢ƒæœ€é«˜æŒ‡ä»¤[\s\S]*?# == æœ€é«˜æŒ‡ä»¤çµæŸ ==\n# ==============================================================================\n)"
    match = re.search(director_view_pattern, world_snapshot)
    if match:
        director_view_prompt = match.group(1)
        core_data_snapshot = world_snapshot.replace(director_view_prompt, "").strip()
        logger.info(f"[{user_id}] (Rendering Prep) å·²æˆåŠŸå°‡å°æ¼”è¦–è§’æŒ‡ä»¤å¾ä¸–ç•Œå¿«ç…§ä¸­åˆ†é›¢ã€‚")

    chain_input = {
        "director_view_prompt": director_view_prompt,
        "core_data_snapshot": core_data_snapshot,
        "system_prompt": ai_core.profile.one_instruction if ai_core.profile else "é è¨­ç³»çµ±æŒ‡ä»¤",
        "action_sexual_content_prompt": ai_core.modular_prompts.get("action_sexual_content", "è­¦å‘Šï¼šæ€§æ„›å…§å®¹æ¨¡çµ„æœªåŠ è¼‰ã€‚"),
        "response_style_prompt": ai_core.profile.response_style_prompt if ai_core.profile else "é è¨­é¢¨æ ¼",
        "narrative_outline": narrative_outline
    }
        
    narrative_text = await ai_core.ainvoke_with_rotation(
        ai_core.get_final_novelist_chain(),
        chain_input,
        retry_strategy='force'
    )
    if not narrative_text:
        narrative_text = "ï¼ˆAI åœ¨å°†æ•…äº‹å¤§çº²æ‰©å±•ä¸ºæœ€ç»ˆå°è¯´æ—¶é­é‡äº†å†…å®¹å®‰å…¨é™åˆ¶ã€‚ï¼‰"
    return {"llm_response": narrative_text}
# å‡½å¼ï¼šæœ€çµ‚æ¸²æŸ“ç¯€é» (v2.0 - é©é…æºé ­éš”é›¢)







# å‡½å¼ï¼šé©—è­‰ä¸¦é‡å¯«ç¯€é» (v1.3 - å¼·åŠ›HTMLè¨»è§£æ·¨åŒ–)
# æ›´æ–°ç´€éŒ„:
# v1.3 (2025-09-10): [ç½é›£æ€§BUGä¿®å¾©] æ ¹æ“šä½¿ç”¨è€…å›å ±çš„æŒ‡ä»¤æ´©æ¼å•é¡Œï¼Œæ–°å¢äº†ç¬¬å››å±¤æ·¨åŒ–é˜²ç¦¦ã€‚ä½¿ç”¨æ­£å‰‡è¡¨é”å¼å¼·åŠ›ç§»é™¤æ‰€æœ‰HTMLè¨»è§£æ ¼å¼çš„å…§å®¹ (`<!-- ... -->`)ï¼Œå¾æ ¹æœ¬ä¸Šæœçµ•æ­¤é¡ç³»çµ±æŒ‡ä»¤çš„æ´©æ¼ã€‚
# v1.2 (2025-09-08): [ç½é›£æ€§BUGä¿®å¾©] æ ¹æ“šä½¿ç”¨è€…å»ºè­°ï¼Œå¾¹åº•é‡æ§‹äº†æ·¨åŒ–é‚è¼¯ï¼Œå¼•å…¥äº†æ›´å¯é çš„â€œèµ·å§‹ç¬¦è™Ÿâ€ç­–ç•¥ã€‚
# v1.1 (2025-09-08): [ç½é›£æ€§BUGä¿®å¾©] æ³¨å…¥äº†é‡å°æŒ‡ä»¤è½Ÿç‚¸æ¨¡å¼ä¸‹â€œç³»çµ±æŒ‡ä»¤æ´©æ¼â€çš„å°ˆé–€æ·¨åŒ–é‚è¼¯ã€‚
async def validate_and_rewrite_node(state: ConversationGraphState) -> Dict:
    """[10] çµ±ä¸€çš„è¼¸å‡ºé©—è­‰èˆ‡æ·¨åŒ–ç¯€é»ã€‚"""
    user_id = state['user_id']
    initial_response = state['llm_response']
    logger.info(f"[{user_id}] (Graph|10) Node: validate_and_rewrite -> æ­£åœ¨å° LLM åŸå§‹è¼¸å‡ºé€²è¡Œå…§å®¹ä¿å…¨å¼æ·¨åŒ–...")
    
    if not initial_response or not initial_response.strip():
        logger.error(f"[{user_id}] æ ¸å¿ƒéˆåœ¨æ·¨åŒ–å‰è¿”å›äº†ç©ºçš„æˆ–ç„¡æ•ˆçš„å›æ‡‰ã€‚")
        return {"final_output": "ï¼ˆ...ï¼‰"}
    
    clean_response = initial_response
    
    # --- [v1.3 æ–°å¢] ç¬¬é›¶å±¤ (æœ€é«˜å„ªå…ˆç´š)ï¼šå¼·åŠ›ç§»é™¤HTMLè¨»è§£ ---
    html_comment_pattern = r'<!--[\s\S]*?-->'
    if '<!--' in clean_response:
        logger.warning(f"[{user_id}] æª¢æ¸¬åˆ°HTMLè¨»è§£æ´©æ¼ï¼Œæ­£åœ¨å•Ÿå‹•å¼·åŠ›æ·¨åŒ–...")
        clean_response = re.sub(html_comment_pattern, '', clean_response)
        logger.info(f"[{user_id}] HTMLè¨»è§£æ·¨åŒ–æˆåŠŸã€‚")

    # --- [v1.2 æ ¸å¿ƒä¿®æ­£] å¤šå±¤æ·¨åŒ–ç³»çµ± ---
    
    # ç¬¬ä¸€å±¤ï¼šå°‹æ‰¾ Â§ èµ·å§‹ç¬¦è™Ÿ
    start_marker = "Â§"
    if start_marker in clean_response:
        logger.warning(f"[{user_id}] æª¢æ¸¬åˆ°ã€ŒÂ§ã€èµ·å§‹ç¬¦è™Ÿï¼Œæ­£åœ¨å•Ÿå‹•æœ€é«˜å„ªå…ˆç´šæ·¨åŒ–...")
        parts = clean_response.split(start_marker, 1)
        if len(parts) > 1:
            clean_response = parts[1]
            logger.info(f"[{user_id}] ã€ŒÂ§ã€èµ·å§‹ç¬¦è™Ÿæ·¨åŒ–æˆåŠŸã€‚")
        else:
            logger.error(f"[{user_id}] æ·¨åŒ–å¤±æ•—ï¼šæ‰¾åˆ°äº†ã€ŒÂ§ã€ä½†ç„¡æ³•åˆ†å‰²ã€‚")
            clean_response = ""
    else:
        # ç¬¬äºŒå±¤ (å‚™æ´)ï¼šå°‹æ‰¾èˆŠçš„æ´©æ¼æ¨™è¨˜
        leak_marker = "ã€ä½ ç»­å†™çš„å®Œæ•´å°è¯´ç« èŠ‚ã€‘:"
        if leak_marker in clean_response:
            logger.warning(f"[{user_id}] æœªæ‰¾åˆ°ã€ŒÂ§ã€ï¼Œä½†æª¢æ¸¬åˆ°èˆŠçš„æ´©æ¼æ¨™è¨˜ï¼Œå•Ÿå‹•å‚™æ´æ·¨åŒ–...")
            parts = clean_response.split(leak_marker, 1)
            if len(parts) > 1:
                clean_response = parts[1]
                logger.info(f"[{user_id}] å‚™æ´æ·¨åŒ–æˆåŠŸã€‚")

    # ç¬¬ä¸‰å±¤ (é€šç”¨)ï¼šåœ¨ä¸»è¦æ·¨åŒ–å¾Œï¼Œæ¸…ç†å‰©é¤˜çš„å°æ¨™ç±¤
    clean_response = re.sub(r'ï¼ˆ(æ€è€ƒ|è¡Œå‹•|è‡ªæˆ‘è§€å¯Ÿ)\s*[:ï¼š\s\S]*?ï¼‰', '', clean_response)
    clean_response = re.sub(r'^\s*(æ—ç™½|å°è©±)\s*[:ï¼š]\s*', '', clean_response, flags=re.MULTILINE)
    if 'æ—ç™½:' in clean_response or 'å°è©±:' in clean_response:
        logger.warning(f"[{user_id}] æª¢æ¸¬åˆ°éæ¨™æº–æ ¼å¼çš„æ¨™ç±¤æ´©æ¼ï¼Œå•Ÿå‹•é€šç”¨æ¸…ç†ã€‚")
        clean_response = clean_response.replace('æ—ç™½:', '').replace('å°è©±:', '')
        clean_response = clean_response.replace('æ—ç™½ï¼š', '').replace('å°è©±ï¼š', '')
    
    final_response = clean_response.strip()
    if not final_response:
        logger.warning(f"[{user_id}] LLM åŸå§‹è¼¸å‡ºåœ¨æ·¨åŒ–å¾Œç‚ºç©ºã€‚åŸå§‹è¼¸å‡ºç‚º: '{initial_response[:200]}...'")
        return {"final_output": "ï¼ˆ...ï¼‰"}
        
    return {"final_output": final_response}
# å‡½å¼ï¼šé©—è­‰ä¸¦é‡å¯«ç¯€é» (v1.3 - å¼·åŠ›HTMLè¨»è§£æ·¨åŒ–)




# å‡½å¼ï¼šæŒä¹…åŒ–ç‹€æ…‹ç¯€é» (v13.0 - è§¸ç™¼èƒŒæ™¯LOREæ“´å±•)
# æ›´æ–°ç´€éŒ„:
# v13.0 (2025-09-09): [é‡å¤§åŠŸèƒ½æ“´å±•] åœ¨æ­¤ç¯€é»çš„æœ«å°¾ï¼Œæ–°å¢äº†å° `_background_lore_extraction` èƒŒæ™¯ä»»å‹™çš„éé˜»å¡èª¿ç”¨ã€‚æ­¤ä¿®æ”¹å°‡â€œäº‹å¾ŒLOREæ“´å±•â€åŠŸèƒ½ç„¡ç¸«æ•´åˆé€²ä¸»å°è©±æµç¨‹ï¼Œä½¿å¾—ä¸–ç•Œè§€èƒ½å¤ åœ¨æ¯æ¬¡äº’å‹•å¾Œå‹•æ…‹æˆé•·ï¼ŒåŒæ™‚ä¸å½±éŸ¿å°ä½¿ç”¨è€…çš„å›æ‡‰é€Ÿåº¦ã€‚
# v12.0 (2025-09-08): [ç½é›£æ€§BUGä¿®å¾©] æ–°å¢äº†æ ¸å¿ƒé‚è¼¯ï¼Œåœ¨å„²å­˜å°è©±æ­·å²å¾Œï¼Œæœƒå°‡ç•¶å‰å›åˆçš„æœ€çµ‚æ„åœ–åˆ†é¡ï¼ˆSFW/NSFWï¼‰å¯«å…¥ GameState ä¸¦æŒä¹…åŒ–åˆ°è³‡æ–™åº«ã€‚
# v11.0 (2025-09-08): åŸå§‹å‰µå»ºã€‚
async def persist_state_node(state: ConversationGraphState) -> Dict:
    """[11] çµ±ä¸€çš„ç‹€æ…‹æŒä¹…åŒ–ç¯€é»ï¼Œè² è²¬å„²å­˜å°è©±æ­·å²ã€æŒä¹…åŒ–æ„åœ–ï¼Œä¸¦è§¸ç™¼èƒŒæ™¯LOREæ“´å±•ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    clean_response = state['final_output']
    intent_classification = state.get('intent_classification')
    logger.info(f"[{user_id}] (Graph|11) Node: persist_state -> æ­£åœ¨æŒä¹…åŒ–ç‹€æ…‹èˆ‡è¨˜æ†¶...")
    
    if not ai_core.profile:
        logger.error(f"[{user_id}] åœ¨ persist_state_node ä¸­ ai_core.profile ç‚ºç©ºï¼Œç„¡æ³•æŒä¹…åŒ–ã€‚")
        return {}
    
    # æŒä¹…åŒ–ç•¶å‰å›åˆçš„æ„åœ–
    if intent_classification:
        current_intent_type = intent_classification.intent_type
        if ai_core.profile.game_state.last_intent_type != current_intent_type:
            logger.info(f"[{user_id}] (Persist) æ­£åœ¨å°‡ç•¶å‰æ„åœ– '{current_intent_type}' æŒä¹…åŒ–åˆ° GameState...")
            ai_core.profile.game_state.last_intent_type = current_intent_type
            await ai_core.update_and_persist_profile({'game_state': ai_core.profile.game_state.model_dump()})

    if clean_response and clean_response != "ï¼ˆ...ï¼‰":
        chat_history_manager = ai_core.session_histories.get(user_id)
        if chat_history_manager:
            chat_history_manager.add_user_message(user_input)
            chat_history_manager.add_ai_message(clean_response)
        
        last_interaction_text = f"ä½¿ç”¨è€… '{ai_core.profile.user_profile.name}' èªª: {user_input}\n\n[å ´æ™¯å›æ‡‰]:\n{clean_response}"
        tasks = []
        tasks.append(ai_core._generate_and_save_personal_memory(last_interaction_text))
        if ai_core.vector_store:
            tasks.append(asyncio.to_thread(ai_core.vector_store.add_texts, [last_interaction_text], metadatas=[{"source": "history"}]))
        
        async def save_to_sql():
            from .database import AsyncSessionLocal, MemoryData
            import time
            timestamp = time.time()
            async with AsyncSessionLocal() as session:
                session.add(MemoryData(user_id=user_id, content=last_interaction_text, timestamp=timestamp, importance=1))
                await session.commit()
        
        tasks.append(save_to_sql())
        await asyncio.gather(*tasks, return_exceptions=True)
        
        # [v13.0 æ ¸å¿ƒä¿®æ­£] åœ¨æ‰€æœ‰ä¸»è¦æŒä¹…åŒ–å®Œæˆå¾Œï¼Œéé˜»å¡åœ°è§¸ç™¼èƒŒæ™¯LOREæ“´å±•
        logger.info(f"[{user_id}] (Persist) æ­£åœ¨å°‡ LORE æå–ä»»å‹™åˆ†æ´¾åˆ°èƒŒæ™¯åŸ·è¡Œ...")
        asyncio.create_task(ai_core._background_lore_extraction(user_input, clean_response))

    return {}
# å‡½å¼ï¼šæŒä¹…åŒ–ç‹€æ…‹ç¯€é» (v13.0 - è§¸ç™¼èƒŒæ™¯LOREæ“´å±•)

def _get_formatted_chat_history(ai_core: AILover, user_id: str, num_messages: int = 10) -> str:
    """å¾ AI æ ¸å¿ƒå¯¦ä¾‹ä¸­æå–ä¸¦æ ¼å¼åŒ–æœ€è¿‘çš„å°è©±æ­·å²ã€‚"""
    if not ai_core.profile: return "ï¼ˆæ²’æœ‰æœ€è¿‘çš„å°è©±æ­·å²ï¼‰"
    chat_history_manager = ai_core.session_histories.get(user_id, ChatMessageHistory())
    if not chat_history_manager.messages:
        return "ï¼ˆæ²’æœ‰æœ€è¿‘çš„å°è©±æ­·å²ï¼‰"
    
    recent_messages = chat_history_manager.messages[-num_messages:]
    
    formatted_history = []
    for msg in recent_messages:
        role = "ä½¿ç”¨è€…" if isinstance(msg, HumanMessage) else ai_core.profile.ai_profile.name
        formatted_history.append(f"{role}: {msg.content}")
        
    return "\n".join(formatted_history)

def route_expansion_decision(state: ConversationGraphState) -> Literal["expand_lore", "continue_to_planner"]:
    """æ ¹æ“šLOREæ“´å±•æ±ºç­–ï¼Œæ±ºå®šæ˜¯å¦é€²å…¥æ“´å±•ç¯€é»ã€‚"""
    if state.get("expansion_decision") and state["expansion_decision"].should_expand:
        return "expand_lore"
    else:
        return "continue_to_planner"





# å‡½å¼ï¼šå‰µå»ºä¸»å›æ‡‰åœ– (v22.0 - å¼•å…¥ NSFW æ€ç¶­éˆ)
# æ›´æ–°ç´€éŒ„:
# v22.0 (2025-09-09): [é‡å¤§æ¶æ§‹é‡æ§‹] æ ¹æ“šâ€œæ•¸æ“šå½è£ä¸‹çš„æ€ç¶­éˆâ€ç­–ç•¥ï¼Œå¾¹åº•é‡æ§‹äº† NSFW è™•ç†è·¯å¾‘ã€‚èˆŠçš„å–®ä¸€ `direct_nsfw_generation_node` è¢«ä¸€å€‹åŒ…å«ä¸‰å€‹æ–°ç¯€é»ï¼ˆ`nsfw_breakthrough_node`, `nsfw_refinement_node`, `final_rendering_node`ï¼‰çš„ã€é‚è¼¯æ›´æ¸…æ™°çš„å­éˆæ‰€å–ä»£ã€‚æ­¤ä¿®æ”¹æ—¨åœ¨é€šéå°‡â€œè¦åŠƒâ€å’Œâ€œæ¸²æŸ“â€åˆ†é›¢ï¼Œå¾æ ¹æœ¬ä¸Šè§£æ±º LORE æ‡‰ç”¨ã€åŠ‡æƒ…é€£çºŒæ€§å’Œè¤‡é›œæŒ‡ä»¤éµå¾ªçš„ä¸‰å¤§æ ¸å¿ƒå•é¡Œã€‚
# v33.0 (2025-09-09): [ç½é›£æ€§BUGä¿®å¾©] ä¿®æ­£äº†å¿«é€Ÿé€šé“çš„æ‹“æ’²çµæ§‹ã€‚
def create_main_response_graph() -> StateGraph:
    """
    [v22.0 ä¿®æ­£] å‰µå»ºä¸»å›æ‡‰åœ–ï¼Œå…§å»ºå…¨æ–°çš„ NSFW æ€ç¶­éˆã€‚
    """
    graph = StateGraph(ConversationGraphState)
    
    # --- ç¯€é»è¨»å†Š ---
    graph.add_node("classify_intent", classify_intent_node)
    graph.add_node("retrieve_memories", retrieve_memories_node)
    graph.add_node("perceive_and_set_view", perceive_and_set_view_node)
    graph.add_node("query_lore", query_lore_node)
    graph.add_node("assemble_context", assemble_context_node)
    graph.add_node("expansion_decision", expansion_decision_node)
    graph.add_node("character_quantification", character_quantification_node)
    graph.add_node("lore_expansion", lore_expansion_node)
    graph.add_node("sfw_planning", sfw_planning_node)
    graph.add_node("remote_sfw_planning", remote_sfw_planning_node)
    # [v22.0 æ–°å¢] è¨»å†Šæ–°çš„ NSFW æ€ç¶­éˆç¯€é»
    graph.add_node("nsfw_breakthrough", nsfw_breakthrough_node)
    graph.add_node("nsfw_refinement", nsfw_refinement_node)
    graph.add_node("final_rendering", final_rendering_node)
    
    graph.add_node("tool_execution", tool_execution_node)
    graph.add_node("sfw_narrative_rendering", sfw_narrative_rendering_node)
    graph.add_node("validate_and_rewrite", validate_and_rewrite_node)
    graph.add_node("persist_state", persist_state_node)
    graph.add_node("planner_junction", lambda state: {})
    graph.add_node("rendering_junction", lambda state: {})
    
    def prepare_existing_subjects_node(state: ConversationGraphState) -> Dict:
        lore_objects = state.get('raw_lore_objects', [])
        planning_subjects = [lore.content for lore in lore_objects if lore.category == 'npc_profile']
        logger.info(f"[{state['user_id']}] (Graph) Node: prepare_existing_subjects -> å·²å°† {len(planning_subjects)} ä¸ªç°æœ‰NPCæ‰“åŒ…ä¸ºè§„åˆ’ä¸»ä½“ã€‚")
        return {"planning_subjects": planning_subjects}
        
    graph.add_node("prepare_existing_subjects", prepare_existing_subjects_node)

    # --- åœ–çš„é‚Šç·£é€£æ¥ ---
    graph.set_entry_point("classify_intent")
    
    def route_after_intent_classification(state: ConversationGraphState) -> Literal["standard_flow", "continuation_flow"]:
        if state.get("input_analysis") and state["input_analysis"].input_type == 'continuation':
            logger.info(f"[{state['user_id']}] (Router) æª¢æ¸¬åˆ°å»¶ç»­æ€§æŒ‡ä»¤ï¼Œæ­£åœ¨å•Ÿç”¨ã€å¿«é€Ÿé€šé“ã€‘ã€‚")
            return "continuation_flow"
        else:
            return "standard_flow"

    graph.add_conditional_edges(
        "classify_intent",
        route_after_intent_classification,
        { "standard_flow": "retrieve_memories", "continuation_flow": "perceive_and_set_view" }
    )

    graph.add_edge("retrieve_memories", "perceive_and_set_view")
    graph.add_edge("perceive_and_set_view", "query_lore")
    graph.add_edge("query_lore", "assemble_context")
    graph.add_edge("assemble_context", "expansion_decision")
    
    graph.add_conditional_edges(
        "expansion_decision",
        route_expansion_decision,
        { "expand_lore": "character_quantification", "continue_to_planner": "prepare_existing_subjects" }
    )
    graph.add_edge("character_quantification", "lore_expansion")
    graph.add_edge("lore_expansion", "planner_junction")
    graph.add_edge("prepare_existing_subjects", "planner_junction")

    def route_to_planner(state: ConversationGraphState) -> str:
        user_id = state['user_id']
        intent_classification = state.get('intent_classification')
        if not intent_classification: return "sfw_planner" 
        intent = intent_classification.intent_type
        ai_core = state['ai_core']
        viewing_mode = ai_core.profile.game_state.viewing_mode if ai_core.profile else 'local'
        logger.info(f"[{user_id}] (Router) Routing to planner. Intent: '{intent}', Final Viewing Mode: '{viewing_mode}'")
        
        if 'nsfw' in intent:
            return "nsfw_chain_of_thought" # [v22.0 ä¿®æ­£] è·¯ç”±åˆ°æ–°çš„ NSFW æ€ç¶­éˆ
        if viewing_mode == 'remote':
            return "remote_sfw_planner"
        else:
            return "sfw_planner"

    graph.add_conditional_edges(
        "planner_junction",
        route_to_planner,
        { 
            "sfw_planner": "sfw_planning", 
            "remote_sfw_planner": "remote_sfw_planning",
            "nsfw_chain_of_thought": "nsfw_breakthrough" # [v22.0 ä¿®æ­£] è·¯ç”±åˆ°æ–°éˆçš„ç¬¬ä¸€æ­¥
        }
    )
    
    # SFW è·¯å¾‘
    graph.add_edge("sfw_planning", "tool_execution")
    graph.add_edge("remote_sfw_planning", "tool_execution")
    graph.add_edge("tool_execution", "sfw_narrative_rendering")
    graph.add_edge("sfw_narrative_rendering", "rendering_junction")
    
    # [v22.0 æ–°å¢] NSFW æ€ç¶­éˆè·¯å¾‘
    graph.add_edge("nsfw_breakthrough", "nsfw_refinement")
    graph.add_edge("nsfw_refinement", "final_rendering")
    graph.add_edge("final_rendering", "rendering_junction")

    # çµ±ä¸€çš„å¾Œè™•ç†è·¯å¾‘
    graph.add_edge("rendering_junction", "validate_and_rewrite")
    graph.add_edge("validate_and_rewrite", "persist_state")
    graph.add_edge("persist_state", END)
    
    return graph.compile()
# å‡½å¼ï¼šå‰µå»ºä¸»å›æ‡‰åœ– (v22.0 - å¼•å…¥ NSFW æ€ç¶­éˆ)

        






async def process_canon_node(state: SetupGraphState) -> Dict:
    ai_core = state['ai_core']
    canon_text = state['canon_text']
    if canon_text:
        await ai_core.add_canon_to_vector_store(canon_text)
        await ai_core.parse_and_create_lore_from_canon(None, canon_text, is_setup_flow=True)
    return {}

# å‡½å¼ï¼šè£œå®Œè§’è‰²æª”æ¡ˆç¯€é» (v2.0 - æ•¸æ“šå®‰å…¨é è™•ç†)
# æ›´æ–°ç´€éŒ„:
# v2.0 (2025-09-08): [ç½é›£æ€§BUGä¿®å¾©] æ ¹æ“š /start æµç¨‹ä¸­çš„ API è¶…æ™‚éŒ¯èª¤ï¼Œå¾¹åº•é‡æ§‹äº†æ­¤ç¯€é»çš„åŸ·è¡Œé‚è¼¯ã€‚èˆŠç‰ˆæœ¬æœƒç›´æ¥å°‡å¯èƒ½åŒ…å«æ•æ„Ÿè©çš„åŸå§‹è§’è‰²æª”æ¡ˆç™¼é€çµ¦è£œå®Œéˆï¼Œå°è‡´ API å…§å®¹å¯©æŸ¥ç³»çµ±æ›èµ·ã€‚æ–°ç‰ˆæœ¬æ³¨å…¥äº†ã€æ•¸æ“šå®‰å…¨é è™•ç†ã€‘æµç¨‹ï¼šåœ¨èª¿ç”¨ AI å‰ï¼Œå…ˆå‰µå»ºä¸€å€‹æª”æ¡ˆçš„â€œå®‰å…¨å‰¯æœ¬â€ï¼Œä¸¦ä½¿ç”¨â€œæ–‡å­¸è©•è«–å®¶â€éˆå°‡å…¶ä¸­é¢¨éšªæœ€é«˜çš„ description å’Œ appearance æ¬„ä½æ¸…æ´—æˆå®‰å…¨çš„æ–‡å­¸æ¦‚è¿°ï¼Œç„¶å¾Œå†å°‡é€™å€‹å®‰å…¨å‰¯æœ¬ç™¼é€çµ¦ AI é€²è¡Œè£œå®Œï¼Œæœ€å¾Œå°‡è£œå®Œçš„çµæœå®‰å…¨åœ°åˆä½µå›åŸå§‹æª”æ¡ˆã€‚æ­¤ä¿®æ”¹å¾æ ¹æœ¬ä¸Šè§£æ±ºäº†å‰µä¸–æµç¨‹ä¸­çš„ API æ›èµ·å•é¡Œã€‚
# v1.0 (2025-09-12): åŸå§‹å‰µå»º
async def complete_profiles_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    logger.info(f"[{user_id}] (Setup Graph) Node: complete_profiles_node -> æ­£åœ¨è£œå®Œè§’è‰²æª”æ¡ˆ...")
    
    if not ai_core.profile:
        logger.error(f"[{user_id}] åœ¨ complete_profiles_node ä¸­ ai_core.profile ç‚ºç©ºï¼Œç„¡æ³•ç¹¼çºŒã€‚")
        return {}

    completion_chain = ai_core.get_profile_completion_chain()
    literary_chain = ai_core.get_literary_euphemization_chain()

    async def _safe_complete_profile(original_profile: CharacterProfile) -> CharacterProfile:
        """ä¸€å€‹è¼”åŠ©å‡½å¼ï¼ŒåŸ·è¡Œâ€œæ¸…æ´— -> è£œå®Œ -> åˆä½µâ€çš„å®‰å…¨æµç¨‹ã€‚"""
        try:
            # æ­¥é©Ÿ 1: å‰µå»ºä¸€å€‹ç”¨æ–¼è£œå®Œçš„å®‰å…¨å‰¯æœ¬
            safe_profile_data = original_profile.model_dump()
            
            # æ­¥é©Ÿ 2: æ¸…æ´—é¢¨éšªæœ€é«˜çš„æ¬„ä½
            description_to_clean = safe_profile_data.get('description', '')
            appearance_to_clean = safe_profile_data.get('appearance', '')

            tasks_to_clean = {}
            if description_to_clean.strip():
                tasks_to_clean['description'] = literary_chain.ainvoke({"dialogue_history": description_to_clean})
            if appearance_to_clean.strip():
                tasks_to_clean['appearance'] = literary_chain.ainvoke({"dialogue_history": appearance_to_clean})

            if tasks_to_clean:
                cleaned_results = await asyncio.gather(*tasks_to_clean.values(), return_exceptions=True)
                results_dict = dict(zip(tasks_to_clean.keys(), cleaned_results))
                
                if 'description' in results_dict and isinstance(results_dict['description'], str):
                    safe_profile_data['description'] = results_dict['description']
                if 'appearance' in results_dict and isinstance(results_dict['appearance'], str):
                    safe_profile_data['appearance'] = results_dict['appearance']

            # æ­¥é©Ÿ 3: ä½¿ç”¨å®‰å…¨å‰¯æœ¬èª¿ç”¨è£œå®Œéˆ
            logger.info(f"[{user_id}] æ­£åœ¨ç‚ºè§’è‰² '{original_profile.name}' åŸ·è¡Œå®‰å…¨çš„æª”æ¡ˆè£œå®Œ...")
            completed_safe_profile = await ai_core.ainvoke_with_rotation(
                completion_chain, 
                {"profile_json": json.dumps(safe_profile_data, ensure_ascii=False)}, 
                retry_strategy='euphemize'
            )

            if not completed_safe_profile:
                logger.warning(f"[{user_id}] è§’è‰² '{original_profile.name}' çš„è£œå®Œéˆè¿”å›ç©ºçµæœï¼Œå°‡è·³éè£œå®Œã€‚")
                return original_profile

            # æ­¥é©Ÿ 4: å®‰å…¨åœ°å°‡è£œå®Œçš„çµæœåˆä½µå›åŸå§‹æª”æ¡ˆ
            # æˆ‘å€‘åªåˆä½µé‚£äº›åœ¨åŸå§‹æª”æ¡ˆä¸­ç‚ºç©ºæˆ–ç‚ºé è¨­å€¼çš„æ¬„ä½
            original_data = original_profile.model_dump()
            completed_data = completed_safe_profile.model_dump()
            
            for key, value in completed_data.items():
                is_empty_or_default = not original_data.get(key) or original_data.get(key) in [[], {}, "æœªè¨­å®š", "æœªçŸ¥", ""]
                if is_empty_or_default and value:
                    original_data[key] = value
            
            # ç¢ºä¿æ ¸å¿ƒæè¿°ä¸è¢«è¦†è“‹
            original_data['description'] = original_profile.description
            original_data['appearance'] = original_profile.appearance
            original_data['name'] = original_profile.name

            return CharacterProfile.model_validate(original_data)

        except Exception as e:
            logger.error(f"[{user_id}] åœ¨ç‚ºè§’è‰² '{original_profile.name}' é€²è¡Œå®‰å…¨è£œå®Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}ï¼Œå°‡è¿”å›åŸå§‹æª”æ¡ˆã€‚", exc_info=True)
            return original_profile

    # ä¸¦è¡Œè™•ç†ä½¿ç”¨è€…å’ŒAIçš„æª”æ¡ˆ
    completed_user_profile_task = _safe_complete_profile(ai_core.profile.user_profile)
    completed_ai_profile_task = _safe_complete_profile(ai_core.profile.ai_profile)
    
    final_user_profile, final_ai_profile = await asyncio.gather(completed_user_profile_task, completed_ai_profile_task)

    # æ›´æ–°ä¸¦æŒä¹…åŒ–
    update_payload = {
        'user_profile': final_user_profile.model_dump(),
        'ai_profile': final_ai_profile.model_dump()
    }
    await ai_core.update_and_persist_profile(update_payload)
        
    return {}
# å‡½å¼ï¼šè£œå®Œè§’è‰²æª”æ¡ˆç¯€é» (v2.0 - æ•¸æ“šå®‰å…¨é è™•ç†)

async def world_genesis_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    
    if not ai_core.profile:
        raise Exception("AI Profile is not loaded for world genesis.")

    genesis_chain = ai_core.get_world_genesis_chain()
    genesis_result = await ai_core.ainvoke_with_rotation(genesis_chain, {"world_settings": ai_core.profile.world_settings, "username": ai_core.profile.user_profile.name, "ai_name": ai_core.profile.ai_profile.name}, retry_strategy='force')
    
    if not genesis_result:
        raise Exception("ä¸–ç•Œå‰µä¸–éˆè¿”å›äº†ç©ºçµæœï¼Œå¯èƒ½æ˜¯å…§å®¹å¯©æŸ¥ã€‚")
        
    gs = ai_core.profile.game_state
    gs.location_path = genesis_result.location_path
    await ai_core.update_and_persist_profile({'game_state': gs.model_dump()})
    
    await lore_book.add_or_update_lore(user_id, 'location_info', " > ".join(genesis_result.location_path), genesis_result.location_info.model_dump())
    
    for npc in genesis_result.initial_npcs:
        npc_key = " > ".join(genesis_result.location_path) + f" > {npc.name}"
        await lore_book.add_or_update_lore(user_id, 'npc_profile', npc_key, npc.model_dump())
        
    return {"genesis_result": genesis_result}

async def generate_opening_scene_node(state: SetupGraphState) -> Dict:
    ai_core = state['ai_core']
    opening_scene = await ai_core.generate_opening_scene()
    
    if not opening_scene or not opening_scene.strip():
        opening_scene = (f"åœ¨ä¸€ç‰‡æŸ”å’Œçš„å…‰èŠ’ä¸­ï¼Œä½ å’Œ {ai_core.profile.ai_profile.name} ç™¼ç¾è‡ªå·±èº«è™•æ–¼ä¸€å€‹å¯§éœçš„ç©ºé–“è£¡...")
        
    return {"opening_scene": opening_scene}

def create_setup_graph() -> StateGraph:
    """å‰µå»ºè¨­å®šåœ–"""
    graph = StateGraph(SetupGraphState)
    graph.add_node("process_canon", process_canon_node)
    graph.add_node("complete_profiles", complete_profiles_node)
    graph.add_node("world_genesis", world_genesis_node)
    graph.add_node("generate_opening_scene", generate_opening_scene_node)
    graph.set_entry_point("process_canon")
    graph.add_edge("process_canon", "complete_profiles")
    graph.add_edge("complete_profiles", "world_genesis")
    graph.add_edge("world_genesis", "generate_opening_scene")
    graph.add_edge("generate_opening_scene", END)
    return graph.compile()




