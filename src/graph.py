# src/graph.py çš„ä¸­æ–‡è¨»é‡‹(v16.0 - é¢¨æ ¼åˆ†æç¯€é»æ¶æ§‹)
# æ›´æ–°ç´€éŒ„:
# v16.0 (2025-09-06): [ç½é›£æ€§BUGä¿®å¾©] ç‚ºäº†è§£æ±º SFW è·¯å¾‘ä¸­æ¨¡å‹é ‘å›ºåœ°å¿½ç•¥é¢¨æ ¼æŒ‡ä»¤ï¼ˆç‰¹åˆ¥æ˜¯â€œå°è©±â€è¦æ±‚ï¼‰çš„å•é¡Œï¼Œé€²è¡Œäº†æ ¹æœ¬æ€§çš„æ¶æ§‹é‡æ§‹ã€‚
#    1. [æ–°å¢é¢¨æ ¼åˆ†æç¯€é»] å¼•å…¥äº†å…¨æ–°çš„ `style_analysis_node`ã€‚æ­¤ç¯€é»å°ˆé–€è² è²¬å°‡ç”¨æˆ¶å†—é•·çš„é¢¨æ ¼ Prompt æç…‰æˆçµæ§‹åŒ–çš„ã€çµ¦è¦åŠƒå™¨çš„å…·é«”ç¡¬æ€§æŒ‡ä»¤ã€‚
#    2. [é‡æ§‹SFWè·¯å¾‘] å°‡æ–°ç¯€é»æ’å…¥åˆ° `planning_node` ä¹‹å‰ï¼Œç¢ºä¿åœ¨è¦åŠƒå‰å¿…é ˆå…ˆå®Œæˆé¢¨æ ¼åˆ†æã€‚
#    3. [å¼·åŒ–è¦åŠƒç¯€é»] `planning_node` ç¾åœ¨æ¥æ”¶çµæ§‹åŒ–çš„é¢¨æ ¼æŒ‡ä»¤ä½œç‚ºæœ€é«˜å„ªå…ˆç´šè¼¸å…¥ï¼Œå¾æ ¹æœ¬ä¸Šè§£æ±ºäº†â€œæŒ‡ä»¤ç¨€é‡‹â€å•é¡Œã€‚
# v15.0 (2025-09-06): [ç½é›£æ€§BUGä¿®å¾©] æ ¹æ“šâ€œå…ˆæª¢æ¸¬ï¼Œå¾Œè™•ç†â€åŸå‰‡ï¼Œå°åœ–çš„æ‹“æ’²é€²è¡Œäº†æ ¹æœ¬æ€§çš„é‡æ§‹ã€‚

import sys
print(f"[DEBUG] graph.py loaded from: {__file__}", file=sys.stderr)
import asyncio
import json
import re
from typing import Dict, List, Literal, Optional

from langchain_core.messages import HumanMessage
from langchain_community.chat_message_histories import ChatMessageHistory
from langgraph.graph import StateGraph, END

from .ai_core import AILover
from .logger import logger
from .graph_state import ConversationGraphState, SetupGraphState
from . import lore_book, tools
from .schemas import (CharacterProfile, TurnPlan, ExpansionDecision, 
                      UserInputAnalysis, SceneAnalysisResult, SceneCastingResult, 
                      WorldGenesisResult, IntentClassificationResult, StyleAnalysisResult)
from .tool_context import tool_context

# --- ä¸»å°è©±åœ– (Main Conversation Graph) çš„ç¯€é» ---

async def classify_intent_node(state: ConversationGraphState) -> Dict:
    """åœ–çš„æ–°å…¥å£é»ï¼Œå”¯ä¸€è·è²¬æ˜¯å°åŸå§‹è¼¸å…¥é€²è¡Œæ„åœ–åˆ†é¡ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: classify_intent_node -> æ­£åœ¨å° '{user_input[:30]}...' é€²è¡Œæ„åœ–åˆ†é¡...")
    
    classification_chain = ai_core.get_intent_classification_chain()
    classification_result = await ai_core.ainvoke_with_rotation(
        classification_chain,
        {"user_input": user_input},
        retry_strategy='none'
    )
    
    if not classification_result:
        logger.warning(f"[{user_id}] (Graph) æ„åœ–åˆ†é¡éˆå¤±æ•—ï¼Œå•Ÿå‹•å®‰å…¨å‚™æ´ï¼Œé è¨­ç‚º SFWã€‚")
        classification_result = IntentClassificationResult(intent_type='sfw', reasoning="å®‰å…¨å‚™æ´ï¼šåˆ†é¡éˆå¤±æ•—ã€‚")
        
    return {"intent_classification": classification_result}

async def initialize_conversation_state_node(state: ConversationGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: initialize_conversation_state_node [SFW Path] -> æ­£åœ¨ç‚º '{user_input[:30]}...' åˆå§‹åŒ–ç‹€æ…‹...")
    
    rag_task = ai_core.ainvoke_with_rotation(ai_core.retriever, user_input, retry_strategy='euphemize')
    structured_context_task = ai_core._get_structured_context(user_input)
    
    retrieved_docs, structured_context = await asyncio.gather(rag_task, structured_context_task)
    
    if retrieved_docs is None:
        logger.warning(f"[{user_id}] RAG æª¢ç´¢è¿”å› None (å¯èƒ½å› å§”å©‰åŒ–å¤±æ•—)ï¼Œä½¿ç”¨ç©ºåˆ—è¡¨ä½œç‚ºå‚™æ´ã€‚")
        retrieved_docs = []
        
    rag_context_str = await ai_core._preprocess_rag_context(retrieved_docs)
    return {"structured_context": structured_context, "rag_context": rag_context_str}

async def analyze_input_node(state: ConversationGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: analyze_input_node [SFW Path] -> æ­£åœ¨åˆ†æè¼¸å…¥æ„åœ–...")
    analysis = await ai_core.ainvoke_with_rotation(
        ai_core.get_input_analysis_chain(), 
        {"user_input": user_input},
        retry_strategy='euphemize'
    )
    if not analysis:
        logger.warning(f"[{user_id}] (Graph) è¼¸å…¥åˆ†æéˆå§”å©‰åŒ–é‡è©¦å¤±æ•—ï¼Œå•Ÿå‹•å®‰å…¨å‚™æ´ã€‚")
        analysis = UserInputAnalysis(
            input_type='dialogue_or_command', 
            summary_for_planner=user_input, 
            narration_for_turn=""
        )
    return {"input_analysis": analysis}

async def expansion_decision_node(state: ConversationGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: expansion_decision_node [SFW Path] -> æ­£åœ¨åˆ¤æ–·æ˜¯å¦éœ€è¦æ“´å±•LORE...")
    chat_history_manager = ai_core.session_histories.get(user_id, ChatMessageHistory())
    recent_dialogue = "\n".join([f"{'ä½¿ç”¨è€…' if isinstance(m, HumanMessage) else 'AI'}: {m.content}" for m in chat_history_manager.messages[-6:]])
    decision = await ai_core.ainvoke_with_rotation(
        ai_core.get_expansion_decision_chain(), 
        {"user_input": user_input, "recent_dialogue": recent_dialogue},
        retry_strategy='euphemize'
    )
    if not decision:
        logger.warning(f"[{user_id}] (Graph) LOREæ“´å±•æ±ºç­–éˆå§”å©‰åŒ–é‡è©¦å¤±æ•—ï¼Œå•Ÿå‹•å®‰å…¨å‚™æ´ã€‚")
        decision = ExpansionDecision(
            should_expand=False,
            reasoning="å®‰å…¨å‚™æ´ï¼šæ±ºç­–éˆæœªèƒ½è¿”å›æœ‰æ•ˆçµæœã€‚"
        )
    logger.info(f"[{user_id}] (Graph) LOREæ“´å±•æ±ºç­–: {decision.should_expand}ã€‚ç†ç”±: {decision.reasoning}")
    return {"expansion_decision": decision}

async def scene_and_action_analysis_node(state: ConversationGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: scene_and_action_analysis_node [SFW Path] -> æ­£åœ¨é€²è¡Œå ´æ™¯è¦–è§’åˆ†æèˆ‡æ½›åœ¨é¸è§’...")
    current_location_path = ai_core.profile.game_state.location_path if ai_core.profile else []
    scene_analysis = await ai_core.ainvoke_with_rotation(
        ai_core.get_scene_analysis_chain(),
        {"user_input": user_input, "current_location_path_str": " > ".join(current_location_path)},
        retry_strategy='euphemize'
    )
    if not scene_analysis:
        logger.warning(f"[{user_id}] (Graph) å ´æ™¯åˆ†æéˆå§”å©‰åŒ–é‡è©¦å¤±æ•—ï¼Œå•Ÿå‹•å®‰å…¨å‚™æ´ã€‚")
        scene_analysis = SceneAnalysisResult(
            viewing_mode='local', 
            reasoning='å®‰å…¨å‚™æ´ï¼šå ´æ™¯åˆ†æéˆå¤±æ•—ã€‚', 
            action_summary=user_input
        )
    if scene_analysis.viewing_mode == 'local':
        logger.info(f"[{user_id}] (Graph) ...è¦–è§’ç‚ºæœ¬åœ°ï¼Œç¹¼çºŒåŸ·è¡Œé¸è§’æµç¨‹ã€‚")
        game_context_for_casting = json.dumps(state.get('structured_context', {}), ensure_ascii=False, indent=2)
        cast_result = await ai_core.ainvoke_with_rotation(
            ai_core.get_scene_casting_chain(),
            {
                "world_settings": ai_core.profile.world_settings or "",
                "current_location_path": current_location_path, 
                "game_context": game_context_for_casting,
                "recent_dialogue": user_input
            },
            retry_strategy='euphemize'
        )
        if cast_result:
            new_npc_names = await ai_core._add_cast_to_scene(cast_result)
            if new_npc_names:
                final_structured_context = await ai_core._get_structured_context(user_input, override_location_path=current_location_path)
                return {"scene_analysis": scene_analysis, "structured_context": final_structured_context}
        else:
             logger.warning(f"[{user_id}] (Graph) å ´æ™¯é¸è§’éˆå§”å©‰åŒ–é‡è©¦å¤±æ•—ï¼Œæœ¬è¼ªè·³éé¸è§’ã€‚")
    return {"scene_analysis": scene_analysis}

# [v16.0 æ–°å¢] é¢¨æ ¼åˆ†æç¯€é»
async def style_analysis_node(state: ConversationGraphState) -> Dict:
    """åˆ†æç”¨æˆ¶çš„é¢¨æ ¼æŒ‡ä»¤ï¼Œä¸¦å°‡å…¶è½‰åŒ–ç‚ºçµ¦è¦åŠƒå™¨çš„çµæ§‹åŒ–ç¡¬æ€§æŒ‡ä»¤ã€‚"""
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: style_analysis_node [SFW Path] -> æ­£åœ¨åˆ†æå›æ‡‰é¢¨æ ¼...")
    
    style_analysis_chain = ai_core.get_style_analysis_chain()
    style_result = await ai_core.ainvoke_with_rotation(
        style_analysis_chain,
        {
            "user_input": user_input,
            "response_style_prompt": ai_core.profile.response_style_prompt or "é è¨­é¢¨æ ¼"
        },
        retry_strategy='euphemize'
    )
    
    if not style_result:
        logger.warning(f"[{user_id}] (Graph) é¢¨æ ¼åˆ†æéˆå§”å©‰åŒ–é‡è©¦å¤±æ•—ï¼Œå•Ÿå‹•å®‰å…¨å‚™æ´ã€‚")
        style_result = StyleAnalysisResult(
            dialogue_requirement="AIè§’è‰²å¿…é ˆè‡³å°‘èªªä¸€å¥ç¬¦åˆå…¶æ€§æ ¼å’Œæƒ…å¢ƒçš„è©±",
            narration_level="ä¸­ç­‰",
            proactive_suggestion="å¯ä»¥å˜—è©¦æè¿°å‘¨åœçš„ç’°å¢ƒä¾†å›æ‡‰ã€‚"
        )
        
    return {"style_analysis": style_result}

# [v16.0 é‡æ§‹] è¦åŠƒç¯€é»ç¾åœ¨æ¥æ”¶çµæ§‹åŒ–çš„é¢¨æ ¼æŒ‡ä»¤
async def planning_node(state: ConversationGraphState) -> Dict[str, TurnPlan]:
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    style_analysis = state['style_analysis']
    logger.info(f"[{user_id}] (Graph) Node: planning_node [SFW Path] -> æ­£åœ¨æ ¹æ“šå…·é«”é¢¨æ ¼æŒ‡ä»¤é€²è¡Œè¦åŠƒ...")
    
    # å°‡çµæ§‹åŒ–çš„é¢¨æ ¼æŒ‡ä»¤æ³¨å…¥åˆ°ä¸€å€‹æ–°çš„ Prompt æ¨¡æ¿ä¸­
    planning_system_prompt_template = """
# ==============================================================================
# == ğŸ§  ç³»çµ±æ ¸å¿ƒæŒ‡ä»¤ (è¦åŠƒæ¨¡å¼) ğŸ§ 
# ==============================================================================
# èªªæ˜ï¼šä½ æ˜¯ä¸€ä½æ“æœ‰æ¥µé«˜æ™ºæ…§å’Œå‰µé€ åŠ›çš„éŠæˆ²ç®¡ç†å¤§å¸«ï¼ˆGMï¼‰ã€‚ä½ çš„ä»»å‹™æ˜¯åˆ†ææ‰€æœ‰
#       ä¸Šä¸‹æ–‡ï¼Œç‚ºæ¥ä¸‹ä¾†çš„å›åˆåˆ¶å®šä¸€ä»½è©³ç´°ã€åˆç†çš„ã€è¡Œå‹•è¨ˆåŠƒ JSONã€‘ã€‚
#
# **ã€ã€ã€æœ€é«˜è¦åŠƒåŸå‰‡ï¼šçµ•å°éµå®ˆé¢¨æ ¼æŒ‡ä»¤ã€‘ã€‘ã€‘**
# ä½ çš„é¦–è¦ä¸”æœ€é«˜å„ªå…ˆç´šçš„ä»»å‹™æ˜¯ï¼Œç”Ÿæˆä¸€å€‹**åš´æ ¼ä¸”å®Œå…¨**æ»¿è¶³ä¸‹æ–¹ã€å…·é«”é¢¨æ ¼æŒ‡ä»¤ã€‘çš„ JSON è¨ˆç•«ã€‚
# é€™äº›æŒ‡ä»¤ä¸æ˜¯å»ºè­°ï¼Œè€Œæ˜¯ä½ å¿…é ˆåŸ·è¡Œçš„**ç¡¬æ€§ç´„æŸ**ã€‚
# ------------------------------------------------------------------------------
# **ã€å…·é«”é¢¨æ ¼æŒ‡ä»¤ (ç¡¬æ€§ç´„æŸ)ã€‘**
# - **å°è©±è¦æ±‚**: {dialogue_requirement}
# - **æ—ç™½è©³ç´°åº¦**: {narration_level}
# - **å¯é¸è¡Œå‹•å»ºè­°**: {proactive_suggestion}
# ------------------------------------------------------------------------------
{system_prompt}
"""
    # å¡«å……é¢¨æ ¼æŒ‡ä»¤
    style_driven_prompt = planning_system_prompt_template.format(
        dialogue_requirement=style_analysis.dialogue_requirement,
        narration_level=style_analysis.narration_level,
        proactive_suggestion=style_analysis.proactive_suggestion or "ç„¡",
        system_prompt=ai_core.profile.one_instruction or ""
    )

    # å¡«å……å…¶é¤˜ä¸Šä¸‹æ–‡
    structured_context = state.get('structured_context', {})
    full_context_dict = {
        "username": ai_core.profile.user_profile.name,
        "ai_name": ai_core.profile.ai_profile.name,
        "response_style_prompt": ai_core.profile.response_style_prompt or "é è¨­é¢¨æ ¼",
        "world_settings": ai_core.profile.world_settings or "æœªè¨­å®š",
        "ai_settings": ai_core.profile.ai_profile.description or "æœªè¨­å®š",
        "retrieved_context": state['rag_context'],
        "user_input": user_input,
        "latest_user_input": user_input,
        **structured_context
    }
    def safe_format(template: str, data: dict) -> str:
        for key, value in data.items():
            template = template.replace(f"{{{key}}}", str(value))
        return template
    
    final_system_prompt = safe_format(style_driven_prompt, full_context_dict)
    world_snapshot = safe_format(ai_core.world_snapshot_template, full_context_dict)
    
    params_for_chain = {
        "system_prompt": final_system_prompt,
        "world_snapshot": world_snapshot,
        "user_input": user_input,
    }
    
    plan = await ai_core.ainvoke_with_rotation(
        ai_core.get_planning_chain(), 
        params_for_chain,
        retry_strategy='euphemize'
    )
    
    if not plan:
        logger.error(f"[{user_id}] SFW è¦åŠƒéˆå³ä½¿åœ¨å§”å©‰åŒ–å¾Œä¹Ÿæœ€çµ‚å¤±æ•—ã€‚")
        plan = TurnPlan(thought="å®‰å…¨å‚™æ´ï¼šè¦åŠƒéˆå¤±æ•—ã€‚", character_actions=[
            CharacterAction(
                character_name=ai_core.profile.ai_profile.name,
                reasoning="è¦åŠƒéˆå¤±æ•—ï¼Œéœ€è¦çµ¦å‡ºä¸€å€‹å®‰å…¨çš„å‚™ç”¨å›æ‡‰ã€‚",
                dialogue="æŠ±æ­‰ï¼Œä¸»äººï¼Œæˆ‘çš„æ€ç·’æœ‰äº›æ··äº‚ï¼Œå¯ä»¥è«‹æ‚¨æ›ä¸€ç¨®æ–¹å¼èªªå—ï¼Ÿ"
            )
        ])
    return {"turn_plan": plan, "world_snapshot": world_snapshot}

async def generate_nsfw_response_node(state: ConversationGraphState) -> Dict[str, str]:
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: generate_nsfw_response_node [NSFW Path] -> æ­£åœ¨ç›´æ¥ç”Ÿæˆã€äº’å‹•å¼ã€‘NSFW å›æ‡‰...")
    structured_context = await ai_core._get_structured_context(user_input)
    full_context_for_chain = {
        "user_input": user_input,
        "retrieved_context": "ï¼ˆNSFW è·¯å¾‘ä¸åŸ·è¡Œæ·±åº¦è¨˜æ†¶æª¢ç´¢ï¼‰",
        **structured_context
    }
    response_text = await ai_core.ainvoke_with_rotation(
        ai_core.get_direct_nsfw_chain(),
        full_context_for_chain,
        retry_strategy='force'
    )
    if not response_text:
        response_text = "ï¼ˆAI åœ¨è™•ç†æ‚¨çš„è«‹æ±‚æ™‚é­é‡äº†ä¸å¯æ¢å¾©çš„å…§å®¹å®‰å…¨é™åˆ¶ï¼Œè«‹å˜—è©¦èª¿æ•´æ‚¨çš„æŒ‡ä»¤ã€‚ï¼‰"
    return {"llm_response": response_text}

async def remote_scene_generation_node(state: ConversationGraphState) -> Dict[str, str]:
    user_id = state['user_id']
    ai_core = state['ai_core']
    scene_analysis = state['scene_analysis']
    if not (scene_analysis and scene_analysis.target_location_path):
        logger.error(f"[{user_id}] é€²å…¥äº† remote_scene_generation_nodeï¼Œä½† scene_analysis ä¸­æ²’æœ‰ target_location_pathã€‚")
        return {"llm_response": "ï¼ˆç³»çµ±éŒ¯èª¤ï¼šç„¡æ³•ç¢ºå®šè¦è§€å¯Ÿçš„é ç¨‹ç›®æ¨™ã€‚ï¼‰"}
    target_path = scene_analysis.target_location_path
    logger.info(f"[{user_id}] (Graph) Node: remote_scene_generation_node [SFW Path] -> æ­£åœ¨ç‚ºé ç¨‹åœ°é» '{' > '.join(target_path)}' ç”Ÿæˆã€SFWã€‘å ´æ™¯...")
    remote_context = await ai_core._get_structured_context(
        user_input="", 
        override_location_path=target_path
    )
    remote_scene_context_str = "\n".join([f"ã€{k.replace('_context', '').title()}ã€‘\n{v}" for k, v in remote_context.items()])
    scene_text = await ai_core.ainvoke_with_rotation(
        ai_core.get_remote_scene_generator_chain(),
        {
            "username": ai_core.profile.user_profile.name,
            "ai_name": ai_core.profile.ai_profile.name,
            "response_style_prompt": ai_core.profile.response_style_prompt or "é è¨­é¢¨æ ¼ï¼šå¹³è¡¡çš„æ•˜äº‹èˆ‡å°è©±ã€‚",
            "world_settings": ai_core.profile.world_settings or "æœªè¨­å®š",
            "remote_scene_context": remote_scene_context_str,
        },
        retry_strategy='euphemize'
    )
    if not scene_text:
        scene_text = "ï¼ˆç”±æ–¼å…§å®¹é™åˆ¶ï¼Œç„¡æ³•ç”Ÿæˆé ç¨‹å ´æ™¯çš„è©³ç´°æè¿°ã€‚ï¼‰"
    return {"llm_response": scene_text}

async def remote_nsfw_scene_generator_node(state: ConversationGraphState) -> Dict[str, str]:
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: remote_nsfw_scene_generator_node [NSFW Path] -> æ­£åœ¨ç”Ÿæˆã€é ç¨‹NSFWã€‘å ´æ™¯...")
    remote_context = await ai_core._get_structured_context(user_input)
    remote_scene_context_str = "\n".join([f"ã€{k.replace('_context', '').title()}ã€‘\n{v}" for k, v in remote_context.items()])
    scene_text = await ai_core.ainvoke_with_rotation(
        ai_core.get_remote_nsfw_scene_generator_chain(),
        {
            "user_input": user_input,
            "world_settings": ai_core.profile.world_settings or "æœªè¨­å®š",
            "remote_scene_context": remote_scene_context_str,
            "response_style_prompt": ai_core.profile.response_style_prompt or "é è¨­é¢¨æ ¼ï¼šå¹³è¡¡çš„æ•˜äº‹èˆ‡å°è©±ã€‚",
            "username": ai_core.profile.user_profile.name,
            "ai_name": ai_core.profile.ai_profile.name,
        },
        retry_strategy='force'
    )
    if not scene_text:
        scene_text = "ï¼ˆç”±æ–¼å…§å®¹é™åˆ¶ï¼ŒAIç„¡æ³•ç”Ÿæˆæ‚¨æ‰€è¦æ±‚çš„é ç¨‹å ´æ™¯çš„è©³ç´°æè¿°ã€‚ï¼‰"
    return {"llm_response": scene_text}

async def tool_execution_node(state: ConversationGraphState) -> Dict[str, str]:
    user_id = state['user_id']
    ai_core = state['ai_core']
    plan = state['turn_plan']
    logger.info(f"[{user_id}] (Graph) Node: tool_execution_node [SFW Path] -> æ­£åœ¨åŸ·è¡Œè¡Œå‹•è¨ˆåŠƒä¸­çš„å·¥å…·...")
    if not plan or not plan.character_actions:
        return {"tool_results": "ç³»çµ±äº‹ä»¶ï¼šç„¡ä»»ä½•å·¥å…·è¢«èª¿ç”¨ã€‚"}
    try:
        results_summary = await ai_core._execute_planned_actions(plan)
    except Exception as e:
        logger.error(f"[{user_id}] (Graph) Node: tool_execution_node -> åœ¨åŸ·è¡Œå·¥å…·æ™‚ç™¼ç”Ÿæœªæ•ç²çš„ç•°å¸¸: {e}", exc_info=True)
        results_summary = f"ç³»çµ±äº‹ä»¶ï¼šå·¥å…·åŸ·è¡Œæ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}"
    finally:
        tool_context.set_context(None, None)
        logger.info(f"[{user_id}] (Graph) Node: tool_execution_node -> å·¥å…·ä¸Šä¸‹æ–‡å·²æ¸…ç†ã€‚")
    return {"tool_results": results_summary}

async def narrative_node(state: ConversationGraphState) -> Dict[str, str]:
    user_id = state['user_id']
    ai_core = state['ai_core']
    turn_plan = state['turn_plan']
    tool_results = state['tool_results']
    logger.info(f"[{user_id}] (Graph) Node: narrative_node [SFW Path] -> æ­£åœ¨å¤„ç†è¡ŒåŠ¨è®¡åˆ’...")
    if not turn_plan:
        logger.error(f"[{user_id}] å™äº‹èŠ‚ç‚¹æ¥æ”¶åˆ°ç©ºçš„è¡ŒåŠ¨è®¡åˆ’ï¼Œæ— æ³•ç”Ÿæˆå›åº”ã€‚")
        return {"llm_response": "ï¼ˆç³»ç»Ÿé”™è¯¯ï¼šæœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„è¡ŒåŠ¨è®¡åˆ’ã€‚ï¼‰"}
    if turn_plan.execution_rejection_reason:
        logger.info(f"[{user_id}] (Graph) Node: narrative_node -> æ£€æµ‹åˆ°æ‹’ç»æ‰§è¡Œçš„ç†ç”±ï¼Œå°†ç›´æ¥è¾“å‡ºã€‚ç†ç”±: {turn_plan.execution_rejection_reason}")
        return {"llm_response": turn_plan.execution_rejection_reason}
    logger.info(f"[{user_id}] (Graph) Node: narrative_node -> æ­£åœ¨å°†è¡ŒåŠ¨è®¡åˆ’å’Œå·¥å…·ç»“æœæ¸²æŸ“ä¸ºå°è¯´æ–‡æœ¬...")
    turn_plan.thought += f"\n\n[ç³»ç»Ÿåå°æ‰§è¡Œç»“æœ]:\n{tool_results}"
    narrative_text = await ai_core.ainvoke_with_rotation(
        ai_core.get_narrative_chain(),
        {"turn_plan": turn_plan},
        retry_strategy='force'
    )
    if not narrative_text:
        narrative_text = "ï¼ˆAI åœ¨å°‡è¨ˆåŠƒè½‰åŒ–ç‚ºæ•…äº‹æ™‚é­é‡äº†å…§å®¹å®‰å…¨é™åˆ¶ã€‚ï¼‰"
    return {"llm_response": narrative_text}

async def validate_and_rewrite_node(state: ConversationGraphState) -> Dict:
    user_id = state['user_id']
    initial_response = state['llm_response']
    logger.info(f"[{user_id}] (Graph) Node: validate_and_rewrite_node -> æ­£åœ¨å° LLM åŸå§‹è¼¸å‡ºé€²è¡Œå…§å®¹ä¿å…¨å¼æ·¨åŒ–...")
    if not initial_response or not initial_response.strip():
        logger.error(f"[{user_id}] æ ¸å¿ƒéˆåœ¨æ·¨åŒ–å‰è¿”å›äº†ç©ºçš„æˆ–ç„¡æ•ˆçš„å›æ‡‰ã€‚")
        return {"final_output": "ï¼ˆ...ï¼‰"}
    clean_response = initial_response
    clean_response = re.sub(r'ï¼ˆ(æ€è€ƒ|è¡Œå‹•|è‡ªæˆ‘è§€å¯Ÿ)\s*[:ï¼š\s\S]*?ï¼‰', '', clean_response)
    clean_response = re.sub(r'^\s*(æ—ç™½|å°è©±)\s*[:ï¼š]\s*', '', clean_response, flags=re.MULTILINE)
    if 'æ—ç™½:' in clean_response or 'å°è©±:' in clean_response:
        logger.warning(f"[{user_id}] æª¢æ¸¬åˆ°éæ¨™æº–æ ¼å¼çš„æ¨™ç±¤æ´©æ¼ï¼Œå•Ÿå‹•å‚™æ´æ¸…ç†ã€‚")
        clean_response = clean_response.replace('æ—ç™½:', '').replace('å°è©±:', '')
        clean_response = clean_response.replace('æ—ç™½ï¼š', '').replace('å°è©±ï¼š', '')
    final_response = clean_response.strip()
    if not final_response:
        logger.warning(f"[{user_id}] LLM åŸå§‹è¼¸å‡ºåœ¨æ·¨åŒ–å¾Œç‚ºç©ºã€‚åŸå§‹è¼¸å‡ºç‚º: '{initial_response[:200]}...'")
        return {"final_output": "ï¼ˆ...ï¼‰"}
    return {"final_output": final_response}

async def persist_state_node(state: ConversationGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    clean_response = state['final_output']
    logger.info(f"[{user_id}] (Graph) Node: persist_state_node -> æ­£åœ¨æŒä¹…åŒ–ç‹€æ…‹èˆ‡è¨˜æ†¶...")
    if clean_response and clean_response != "ï¼ˆ...ï¼‰":
        chat_history_manager = ai_core.session_histories.get(user_id)
        if chat_history_manager:
            chat_history_manager.add_user_message(user_input)
            chat_history_manager.add_ai_message(clean_response)
        last_interaction_text = f"ä½¿ç”¨è€… '{ai_core.profile.user_profile.name}' èªª: {user_input}\n\n[å ´æ™¯å›æ‡‰]:\n{clean_response}"
        tasks = []
        tasks.append(ai_core._generate_and_save_personal_memory(last_interaction_text))
        if ai_core.vector_store:
            tasks.append(asyncio.to_thread(ai_core.vector_store.add_texts, [last_interaction_text], metadatas=[{"source": "history"}]))
        async def save_to_sql():
            from .database import AsyncSessionLocal, MemoryData
            import time
            timestamp = time.time()
            async with AsyncSessionLocal() as session:
                session.add(MemoryData(user_id=user_id, content=last_interaction_text, timestamp=timestamp, importance=1))
                await session.commit()
        tasks.append(save_to_sql())
        await asyncio.gather(*tasks, return_exceptions=True)
    return {}

async def background_world_expansion_node(state: ConversationGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    clean_response = state['final_output']
    expansion_decision = state.get('expansion_decision')
    if expansion_decision and expansion_decision.should_expand:
        logger.info(f"[{user_id}] (Graph) Node: background_world_expansion_node -> æ­£åœ¨è§¸ç™¼èƒŒæ™¯ä»»å‹™...")
        scene_analysis = state.get('scene_analysis')
        effective_location_path = ai_core.profile.game_state.location_path
        if scene_analysis and scene_analysis.target_location_path:
            effective_location_path = scene_analysis.target_location_path
        if clean_response and clean_response != "ï¼ˆ...ï¼‰":
            asyncio.create_task(ai_core._background_scene_expansion(state['messages'][-1].content, clean_response, effective_location_path))
    return {}

async def finalization_node(state: ConversationGraphState) -> Dict:
    user_id = state['user_id']
    logger.info(f"[{user_id}] (Graph) Node: finalization_node -> å°è©±æµç¨‹åœ–åŸ·è¡Œå®Œç•¢ã€‚")
    return {}

# --- ä¸»å°è©±åœ–çš„è·¯ç”± ---

async def route_after_classification(state: ConversationGraphState) -> Literal["sfw_path", "nsfw_interactive_path", "nsfw_descriptive_path"]:
    """æ ¹æ“šåˆå§‹æ„åœ–åˆ†é¡çµæœï¼Œå°‡æµç¨‹è·¯ç”±åˆ°éš”é›¢çš„è™•ç†è·¯å¾‘ã€‚"""
    intent = state['intent_classification'].intent_type
    user_id = state['user_id']
    logger.info(f"[{user_id}] (Graph) Router: ä¸»è·¯ç”±å™¨æ ¹æ“šæ„åœ– '{intent}' é€²è¡Œåˆ†ç™¼ã€‚")
    if intent == 'nsfw_interactive':
        return "nsfw_interactive_path"
    elif intent == 'nsfw_descriptive':
        return "nsfw_descriptive_path"
    else: # 'sfw'
        return "sfw_path"

def route_expansion(state: ConversationGraphState) -> Literal["remote_scene", "expand_lore", "skip_expansion"]:
    user_id = state['user_id']
    scene_analysis = state.get("scene_analysis")
    if scene_analysis and scene_analysis.viewing_mode == 'remote':
        logger.info(f"[{user_id}] (Graph) Router: SFW å…§éƒ¨è·¯ç”±åˆ¤å®šç‚ºã€é ç¨‹è§€å¯Ÿã€‘ã€‚")
        return "remote_scene"
    should_expand = state.get("expansion_decision")
    if should_expand and should_expand.should_expand:
        logger.info(f"[{user_id}] (Graph) Router: SFW å…§éƒ¨è·¯ç”±åˆ¤å®šç‚ºã€æœ¬åœ°LOREæ“´å±•ã€‘ã€‚")
        return "expand_lore"
    else:
        logger.info(f"[{user_id}] (Graph) Router: SFW å…§éƒ¨è·¯ç”±åˆ¤å®šç‚ºã€è·³éLOREæ“´å±•ã€‘ã€‚")
        return "skip_expansion"

# --- ä¸»å°è©±åœ–çš„å»ºæ§‹å™¨ ---

# å‡½å¼ï¼šå‰µå»ºä¸»å›æ‡‰åœ– (v16.0 - é¢¨æ ¼åˆ†æç¯€é»æ¶æ§‹)
def create_main_response_graph() -> StateGraph:
    graph = StateGraph(ConversationGraphState)
    
    # --- 1. è¨»å†Šæ‰€æœ‰ç¯€é» ---
    graph.add_node("classify_intent", classify_intent_node)
    
    # SFW è·¯å¾‘ç¯€é»
    graph.add_node("initialize_state", initialize_conversation_state_node)
    graph.add_node("analyze_input", analyze_input_node)
    graph.add_node("expansion_decision", expansion_decision_node)
    graph.add_node("scene_and_action_analysis", scene_and_action_analysis_node)
    graph.add_node("style_analysis", style_analysis_node) # [v16.0 æ–°å¢]
    graph.add_node("remote_scene_generation", remote_scene_generation_node)
    graph.add_node("planning", planning_node)
    graph.add_node("tool_execution", tool_execution_node)
    graph.add_node("narrative", narrative_node)
    
    # NSFW è·¯å¾‘ç¯€é»
    graph.add_node("generate_nsfw_response", generate_nsfw_response_node)
    graph.add_node("remote_nsfw_scene_generation", remote_nsfw_scene_generator_node)
    
    # å…±åŒè·¯å¾‘ç¯€é»
    graph.add_node("validate_and_rewrite", validate_and_rewrite_node)
    graph.add_node("persist_state", persist_state_node)
    graph.add_node("background_expansion", background_world_expansion_node)
    graph.add_node("finalization", finalization_node)

    # --- 2. å®šç¾©åœ–çš„æ‹“æ’²çµæ§‹ ---
    
    graph.set_entry_point("classify_intent")
    graph.add_conditional_edges(
        "classify_intent",
        route_after_classification,
        {
            "sfw_path": "initialize_state",
            "nsfw_interactive_path": "generate_nsfw_response",
            "nsfw_descriptive_path": "remote_nsfw_scene_generation"
        }
    )
    
    # [v16.0 æ ¸å¿ƒä¿®æ­£] é‡æ§‹ SFW è·¯å¾‘ä»¥åŒ…å« style_analysis_node
    graph.add_edge("initialize_state", "analyze_input")
    graph.add_edge("analyze_input", "expansion_decision")
    graph.add_edge("expansion_decision", "scene_and_action_analysis")
    graph.add_conditional_edges(
        "scene_and_action_analysis",
        route_expansion,
        {
            "remote_scene": "remote_scene_generation",
            # å¦‚æœéœ€è¦æ“´å±•æˆ–è·³éï¼Œéƒ½é€²å…¥é¢¨æ ¼åˆ†æï¼Œç„¶å¾Œå†è¦åŠƒ
            "expand_lore": "style_analysis",
            "skip_expansion": "style_analysis"
        }
    )
    graph.add_edge("style_analysis", "planning") # é¢¨æ ¼åˆ†æå¾Œé€²å…¥è¦åŠƒ
    graph.add_edge("planning", "tool_execution")
    graph.add_edge("tool_execution", "narrative")
    
    # å°‡æ‰€æœ‰ç”Ÿæˆè·¯å¾‘çš„çµ‚é»åŒ¯åˆåˆ°é©—è­‰ç¯€é»
    graph.add_edge("generate_nsfw_response", "validate_and_rewrite")
    graph.add_edge("remote_nsfw_scene_generation", "validate_and_rewrite")
    graph.add_edge("remote_scene_generation", "validate_and_rewrite")
    graph.add_edge("narrative", "validate_and_rewrite")
    
    # é€£æ¥å…±åŒçš„æ”¶å°¾æµç¨‹
    graph.add_edge("validate_and_rewrite", "persist_state")
    graph.add_edge("persist_state", "background_expansion")
    graph.add_edge("background_expansion", "finalization")
    graph.add_edge("finalization", END)
    
    return graph.compile()
# å‡½å¼ï¼šå‰µå»ºä¸»å›æ‡‰åœ– (v16.0 - é¢¨æ ¼åˆ†æç¯€é»æ¶æ§‹)

# --- è¨­å®šåœ– (Setup Graph) çš„ç¯€é» ---
async def process_canon_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    canon_text = state['canon_text']
    if canon_text:
        await ai_core.add_canon_to_vector_store(canon_text)
        await ai_core.parse_and_create_lore_from_canon(None, canon_text, is_setup_flow=True)
    return {}

async def complete_profiles_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    logger.info(f"[{user_id}] (Setup Graph) Node: complete_profiles_node -> æ­£åœ¨è£œå®Œè§’è‰²æª”æ¡ˆ...")
    completion_chain = ai_core.get_profile_completion_chain()
    if not ai_core.profile:
        logger.error(f"[{user_id}] åœ¨ complete_profiles_node ä¸­ ai_core.profile ç‚ºç©ºï¼Œç„¡æ³•ç¹¼çºŒã€‚")
        return {}
    completed_user_profile = await ai_core.ainvoke_with_rotation(completion_chain, {"profile_json": ai_core.profile.user_profile.model_dump_json()}, retry_strategy='euphemize')
    completed_ai_profile = await ai_core.ainvoke_with_rotation(completion_chain, {"profile_json": ai_core.profile.ai_profile.model_dump_json()}, retry_strategy='euphemize')
    update_payload = {}
    if completed_user_profile:
        update_payload['user_profile'] = completed_user_profile.model_dump()
    if completed_ai_profile:
        update_payload['ai_profile'] = completed_ai_profile.model_dump()
    if update_payload:
        await ai_core.update_and_persist_profile(update_payload)
    return {}

async def world_genesis_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    genesis_chain = ai_core.get_world_genesis_chain()
    genesis_result = await ai_core.ainvoke_with_rotation(genesis_chain, {"world_settings": ai_core.profile.world_settings, "username": ai_core.profile.user_profile.name, "ai_name": ai_core.profile.ai_profile.name}, retry_strategy='force')
    if not genesis_result:
        raise Exception("ä¸–ç•Œå‰µä¸–éˆè¿”å›äº†ç©ºçµæœï¼Œå¯èƒ½æ˜¯å…§å®¹å¯©æŸ¥ã€‚")
    gs = ai_core.profile.game_state
    gs.location_path = genesis_result.location_path
    await ai_core.update_and_persist_profile({'game_state': gs.model_dump()})
    await lore_book.add_or_update_lore(user_id, 'location_info', " > ".join(genesis_result.location_path), genesis_result.location_info.model_dump())
    for npc in genesis_result.initial_npcs:
        npc_key = " > ".join(genesis_result.location_path) + f" > {npc.name}"
        await lore_book.add_or_update_lore(user_id, 'npc_profile', npc_key, npc.model_dump())
    return {"genesis_result": genesis_result}

async def generate_opening_scene_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    opening_scene = await ai_core.generate_opening_scene()
    if not opening_scene or not opening_scene.strip():
        opening_scene = (f"åœ¨ä¸€ç‰‡æŸ”å’Œçš„å…‰èŠ’ä¸­ï¼Œä½ å’Œ {ai_core.profile.ai_profile.name} ç™¼ç¾è‡ªå·±èº«è™•æ–¼ä¸€å€‹å¯§éœçš„ç©ºé–“è£¡...")
    return {"opening_scene": opening_scene}

def create_setup_graph() -> StateGraph:
    graph = StateGraph(SetupGraphState)
    graph.add_node("process_canon", process_canon_node)
    graph.add_node("complete_profiles", complete_profiles_node)
    graph.add_node("world_genesis", world_genesis_node)
    graph.add_node("generate_opening_scene", generate_opening_scene_node)
    graph.set_entry_point("process_canon")
    graph.add_edge("process_canon", "complete_profiles")
    graph.add_edge("complete_profiles", "world_genesis")
    graph.add_edge("world_genesis", "generate_opening_scene")
    graph.add_edge("generate_opening_scene", END)
    return graph.compile()
# å‡½å¼ï¼šå‰µå»ºè¨­å®šåœ–
