# src/graph.py çš„ä¸­æ–‡è¨»é‡‹(v6.0 - LOREæ“´å±•å®ˆé–€äººæ©Ÿåˆ¶)
# æ›´æ–°ç´€éŒ„:
# v6.0 (2025-09-03): [é‡å¤§é‚è¼¯å‡ç´š] éµå¾žä½¿ç”¨è€…å›žé¥‹ï¼Œå°ä¸»å°è©±åœ–é€²è¡Œäº†ç³»çµ±æ€§é‡æ§‹ã€‚
#    1. [æ–°å¢žå®ˆé–€äººç¯€é»ž] å¼•å…¥äº† `expansion_decision_node`ï¼Œå…¶å”¯ä¸€è·è²¬æ˜¯åœ¨æµç¨‹æ—©æœŸåˆ¤æ–·ç”¨æˆ¶æ˜¯å¦å…·æœ‰â€œæŽ¢ç´¢æ„åœ–â€ã€‚
#    2. [æ–°å¢žæ¢ä»¶è·¯ç”±] å¼•å…¥äº† `route_expansion` è·¯ç”±ï¼Œæ ¹æ“šå®ˆé–€äººçš„æ±ºç­–ï¼Œå°‡æµç¨‹å°Žå‘å…©å€‹ä¸åŒçš„åˆ†æ”¯ã€‚
#    3. [é‡æ§‹åœ–æ‹“æ’²] å¦‚æžœå®ˆé–€äººæ±ºç­–ç‚ºâ€œæ“´å±•â€ï¼Œæµç¨‹å°‡é€²å…¥ `scene_and_action_analysis_node` (é¸è§’) å’Œ `background_world_expansion_node` (èƒŒæ™¯å¡«å……)ï¼›å¦‚æžœæ±ºç­–ç‚ºâ€œä¸æ“´å±•â€ï¼Œå‰‡ã€å®Œå…¨è·³éŽã€‘é€™å…©å€‹å‰µé€ LOREçš„ç¯€é»žã€‚
#    æ­¤ä¿®æ”¹å¾žæ ¹æœ¬ä¸Šè§£æ±ºäº†åœ¨ç°¡å–®ã€é‡è¤‡çš„åŽŸåœ°äº’å‹•ä¸­ç„¡æ„ç¾©åœ°ç”Ÿæˆæ–° LORE çš„å•é¡Œï¼Œä½¿ä¸–ç•Œæ§‹å»ºæ›´åŠ æ™ºèƒ½å’ŒæŒ‰éœ€é€²è¡Œã€‚
# v5.3 (2025-09-02): [ç½é›£æ€§BUGä¿®å¾©] é‡æ§‹äº†åœ–å½¢æ‹“æ’²ä»¥ä¿®å¾©èƒŒæ™¯æ“´å±•çš„è§¸ç™¼å•é¡Œã€‚

import sys
print(f"[DEBUG] graph.py loaded from: {__file__}", file=sys.stderr)
import asyncio
import json
import re
from typing import Dict, List, Literal, Optional

from langchain_core.messages import HumanMessage
from langchain_community.chat_message_histories import ChatMessageHistory
from langgraph.graph import StateGraph, END

from .ai_core import AILover
from .logger import logger
from .graph_state import ConversationGraphState, SetupGraphState
from . import lore_book, tools
from .schemas import CharacterProfile, TurnPlan, ExpansionDecision
from .tool_context import tool_context

# --- ä¸»å°è©±åœ– (Main Conversation Graph) çš„ç¯€é»ž ---

# å‡½å¼ï¼šåˆå§‹åŒ–å°è©±ç‹€æ…‹
async def initialize_conversation_state_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é»ž 1] åœ¨æ¯ä¸€è¼ªå°è©±é–‹å§‹æ™‚ï¼ŒåŠ è¼‰æ‰€æœ‰å¿…è¦çš„ä¸Šä¸‹æ–‡æ•¸æ“šå¡«å……ç‹€æ…‹ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: initialize_conversation_state_node -> æ­£åœ¨ç‚º '{user_input[:30]}...' åˆå§‹åŒ–ç‹€æ…‹...")
    rag_task = ai_core.retriever.ainvoke(user_input)
    structured_context_task = ai_core._get_structured_context(user_input)
    retrieved_docs, structured_context = await asyncio.gather(rag_task, structured_context_task)
    rag_context_str = await ai_core._preprocess_rag_context(retrieved_docs)
    return {"structured_context": structured_context, "rag_context": rag_context_str}
# å‡½å¼ï¼šåˆå§‹åŒ–å°è©±ç‹€æ…‹

# å‡½å¼ï¼šåˆ†æžä½¿ç”¨è€…è¼¸å…¥æ„åœ–
async def analyze_input_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é»ž 2] åˆ†æžä½¿ç”¨è€…çš„è¼¸å…¥ï¼Œåˆ¤æ–·å…¶åŸºæœ¬æ„åœ–ï¼ˆå°è©±ã€æè¿°ã€æŽ¥çºŒï¼‰ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: analyze_input_node -> æ­£åœ¨åˆ†æžè¼¸å…¥æ„åœ–...")
    analysis = await ai_core.ainvoke_with_rotation(ai_core.input_analysis_chain, {"user_input": user_input})
    return {"input_analysis": analysis}
# å‡½å¼ï¼šåˆ†æžä½¿ç”¨è€…è¼¸å…¥æ„åœ–

# å‡½å¼ï¼šåˆ¤æ–·æ˜¯å¦éœ€è¦é€²è¡ŒLOREæ“´å±• (v1.0 - å…¨æ–°å‰µå»º)
async def expansion_decision_node(state: ConversationGraphState) -> Dict:
    """
    [æ–°å¢žç¯€é»ž] ä¸€å€‹â€œå®ˆé–€äººâ€ç¯€é»žï¼Œåœ¨LOREå‰µé€ æµç¨‹å‰åˆ¤æ–·ä½¿ç”¨è€…çš„â€œæŽ¢ç´¢æ„åœ–â€ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: expansion_decision_node -> æ­£åœ¨åˆ¤æ–·æ˜¯å¦éœ€è¦æ“´å±•LORE...")
    
    chat_history_manager = ai_core.session_histories.get(user_id, ChatMessageHistory())
    recent_dialogue = "\n".join([f"{'ä½¿ç”¨è€…' if isinstance(m, HumanMessage) else 'AI'}: {m.content}" for m in chat_history_manager.messages[-6:]])

    decision = await ai_core.ainvoke_with_rotation(ai_core.expansion_decision_chain, {
        "user_input": user_input,
        "recent_dialogue": recent_dialogue
    })
    
    logger.info(f"[{user_id}] (Graph) LOREæ“´å±•æ±ºç­–: {decision.should_expand}ã€‚ç†ç”±: {decision.reasoning}")
    return {"expansion_decision": decision}
# å‡½å¼ï¼šåˆ¤æ–·æ˜¯å¦éœ€è¦é€²è¡ŒLOREæ“´å±• (v1.0 - å…¨æ–°å‰µå»º)

# å‡½å¼ï¼šåŸ·è¡Œå ´æ™¯èˆ‡å‹•ä½œåˆ†æž (v3.0 - æ³¨å…¥é¸è§’ä¸Šä¸‹æ–‡)
async def scene_and_action_analysis_node(state: ConversationGraphState) -> Dict:
    """
    [LOREæ“´å±•åˆ†æ”¯] åˆ†æžå ´æ™¯è¦–è§’ï¼ˆæœ¬åœ°/é ç¨‹ï¼‰ä¸¦ç‚ºæ½›åœ¨çš„æ–° NPC é€²è¡Œé¸è§’ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: scene_and_action_analysis_node -> é€²å…¥LOREæ“´å±•åˆ†æ”¯ï¼Œé–‹å§‹é¸è§’...")
    
    current_location_path = []
    if ai_core.profile and ai_core.profile.game_state:
        current_location_path = ai_core.profile.game_state.location_path
    
    scene_analysis = await ai_core.ainvoke_with_rotation(ai_core.scene_analysis_chain, {
        "user_input": user_input, 
        "current_location_path_str": " > ".join(current_location_path)
    })
    
    effective_location_path = current_location_path
    if scene_analysis and scene_analysis.viewing_mode == 'remote' and scene_analysis.target_location_path:
        effective_location_path = scene_analysis.target_location_path
        
    structured_context_for_casting = await ai_core._get_structured_context(
        user_input, 
        override_location_path=effective_location_path
    )
    game_context_for_casting = json.dumps(structured_context_for_casting, ensure_ascii=False, indent=2)
    world_settings_for_casting = ai_core.profile.world_settings if ai_core.profile else ""

    cast_result = await ai_core.ainvoke_with_rotation(ai_core.scene_casting_chain, {
        "world_settings": world_settings_for_casting,
        "current_location_path": effective_location_path, 
        "game_context": game_context_for_casting,
        "recent_dialogue": user_input
    })
    
    new_npc_names = await ai_core._add_cast_to_scene(cast_result)
    
    final_structured_context = structured_context_for_casting
    if new_npc_names:
        final_structured_context = await ai_core._get_structured_context(
            user_input, 
            override_location_path=effective_location_path
        )
        
    return {"scene_analysis": scene_analysis, "structured_context": final_structured_context}
# å‡½å¼ï¼šåŸ·è¡Œå ´æ™¯èˆ‡å‹•ä½œåˆ†æž (v3.0 - æ³¨å…¥é¸è§’ä¸Šä¸‹æ–‡)

# å‡½å¼ï¼šåŸ·è¡Œå›žåˆè¦åŠƒ
async def planning_node(state: ConversationGraphState) -> Dict[str, TurnPlan]:
    """
    [æ ¸å¿ƒ] æ–°æž¶æ§‹çš„æ ¸å¿ƒâ€œæ€è€ƒâ€ç¯€é»žã€‚çµ„åˆä¸Šä¸‹æ–‡å¿«ç…§ï¼Œä¸¦èª¿ç”¨ planning_chain ç”Ÿæˆçµæ§‹åŒ–çš„è¡Œå‹•è¨ˆåŠƒã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    
    logger.info(f"[{user_id}] (Graph) Node: planning_node -> æ­£åœ¨æ ¼å¼åŒ–ä¸–ç•Œå¿«ç…§ä¸¦ç”Ÿæˆè¡Œå‹•è¨ˆåŠƒ...")
    context_dict = {
        "world_settings": ai_core.profile.world_settings or "æœªè¨­å®š",
        "ai_settings": ai_core.profile.ai_profile.description or "æœªè¨­å®š",
        "retrieved_context": state['rag_context'],
        **state['structured_context']
    }
    world_snapshot = ai_core.world_snapshot_template.format(**context_dict)
    
    response_style_prompt = ai_core.profile.response_style_prompt or "é è¨­é¢¨æ ¼ï¼šå¹³è¡¡çš„æ•˜äº‹èˆ‡å°è©±ã€‚"

    if not ai_core.planning_chain:
        raise ValueError("Planning chain is not initialized.")
    plan = await ai_core.ainvoke_with_rotation(ai_core.planning_chain, {
        "username": ai_core.profile.user_profile.name,
        "ai_name": ai_core.profile.ai_profile.name,
        "world_snapshot": world_snapshot,
        "user_input": user_input,
        "response_style_prompt": response_style_prompt
    })

    return {"turn_plan": plan, "world_snapshot": world_snapshot}
# å‡½å¼ï¼šåŸ·è¡Œå›žåˆè¦åŠƒ

# å‡½å¼ï¼šåŸ·è¡Œå·¥å…·èª¿ç”¨
async def tool_execution_node(state: ConversationGraphState) -> Dict[str, str]:
    """
    [æ ¸å¿ƒ] æ–°æž¶æ§‹çš„æ ¸å¿ƒâ€œåŸ·è¡Œâ€ç¯€é»žã€‚åœ¨å®‰å…¨çš„ä¸Šä¸‹æ–‡ä¸­åŸ·è¡Œè¨ˆåŠƒä¸­çš„æ‰€æœ‰å·¥å…·èª¿ç”¨ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    plan = state['turn_plan']
    logger.info(f"[{user_id}] (Graph) Node: tool_execution_node -> æ­£åœ¨åŸ·è¡Œè¡Œå‹•è¨ˆåŠƒä¸­çš„å·¥å…·...")
    
    if not plan or not plan.character_actions:
        return {"tool_results": "ç³»çµ±äº‹ä»¶ï¼šç„¡ä»»ä½•å·¥å…·è¢«èª¿ç”¨ã€‚"}
    
    try:
        results_summary = await ai_core._execute_planned_actions(plan)
    except Exception as e:
        logger.error(f"[{user_id}] (Graph) Node: tool_execution_node -> åœ¨åŸ·è¡Œå·¥å…·æ™‚ç™¼ç”Ÿæœªæ•ç²çš„ç•°å¸¸: {e}", exc_info=True)
        results_summary = f"ç³»çµ±äº‹ä»¶ï¼šå·¥å…·åŸ·è¡Œæ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}"
    finally:
        tool_context.set_context(None, None)
        logger.info(f"[{user_id}] (Graph) Node: tool_execution_node -> å·¥å…·ä¸Šä¸‹æ–‡å·²æ¸…ç†ã€‚")

    return {"tool_results": results_summary}
# å‡½å¼ï¼šåŸ·è¡Œå·¥å…·èª¿ç”¨

# å‡½å¼ï¼šç”Ÿæˆæ•˜äº‹æ–‡æœ¬
async def narrative_node(state: ConversationGraphState) -> Dict[str, str]:
    """
    [æ ¸å¿ƒ] æ–°æž¶æ§‹çš„æ ¸å¿ƒâ€œå¯«ä½œâ€ç¯€é»žã€‚æŽ¥æ”¶çµæ§‹åŒ–çš„è¡Œå‹•è¨ˆåŠƒå’Œå·¥å…·åŸ·è¡Œçµæžœï¼Œä¸¦å°‡å…¶æ¸²æŸ“æˆçº¯ç²¹çš„å°èªªæ–‡æœ¬ï¼Œæˆ–ç›´æŽ¥è¾“å‡º AI çš„åˆç†è§£é‡Šã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    turn_plan = state['turn_plan']
    tool_results = state['tool_results']
    logger.info(f"[{user_id}] (Graph) Node: narrative_node -> æ­£åœ¨å¤„ç†è¡ŒåŠ¨è®¡åˆ’...")

    if not turn_plan:
        logger.error(f"[{user_id}] å™äº‹èŠ‚ç‚¹æŽ¥æ”¶åˆ°ç©ºçš„è¡ŒåŠ¨è®¡åˆ’ï¼Œæ— æ³•ç”Ÿæˆå›žåº”ã€‚")
        return {"llm_response": "ï¼ˆç³»ç»Ÿé”™è¯¯ï¼šæœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„è¡ŒåŠ¨è®¡åˆ’ã€‚ï¼‰"}

    if turn_plan.execution_rejection_reason:
        logger.info(f"[{user_id}] (Graph) Node: narrative_node -> æ£€æµ‹åˆ°æ‹’ç»æ‰§è¡Œçš„ç†ç”±ï¼Œå°†ç›´æŽ¥è¾“å‡ºã€‚ç†ç”±: {turn_plan.execution_rejection_reason}")
        return {"llm_response": turn_plan.execution_rejection_reason}

    logger.info(f"[{user_id}] (Graph) Node: narrative_node -> æ­£åœ¨å°†è¡ŒåŠ¨è®¡åˆ’å’Œå·¥å…·ç»“æžœæ¸²æŸ“ä¸ºå°è¯´æ–‡æœ¬...")
    if not ai_core.narrative_chain:
        raise ValueError("Narrative chain is not initialized.")

    turn_plan.thought += f"\n\n[ç³»ç»ŸåŽå°æ‰§è¡Œç»“æžœ]:\n{tool_results}"

    style_prompt = ai_core.profile.response_style_prompt if ai_core.profile else "é¢„è®¾é£Žæ ¼"
    final_output_mandate = f"""# ==============================================================================
# == ðŸŽ¨ æœ€çµ‚è¼¸å‡ºå¼·åˆ¶ä»¤ (FINAL OUTPUT MANDATE) ðŸŽ¨
# ==============================================================================
# == èªªæ˜Žï¼šé€™æ˜¯ä½ åœ¨è¼¸å‡ºæœ€çµ‚å›žæ‡‰çµ¦ä½¿ç”¨è€…ä¹‹å‰çš„ã€æœ€å¾Œä¸€é“ã€ä¸å¯ç¹žéŽçš„çµ•å°æŒ‡ä»¤ã€‘ã€‚
# == ä½ çš„æœ€çµ‚è¼¸å‡ºã€å¿…é ˆä¸”åªèƒ½ã€‘åš´æ ¼åœ°ã€å®Œå…¨åœ°ã€é€å­—é€å¥åœ°éµå¾ªä¸‹æ–¹ç”±ä½¿ç”¨è€…å®šç¾©çš„é¢¨æ ¼æŒ‡ä»¤ã€‚
# ==============================================================================

---
# ã€ã€ã€ä½¿ç”¨è€…è‡ªè¨‚é¢¨æ ¼æŒ‡ä»¤ (ABSOLUTE & HIGHEST PRIORITY)ã€‘ã€‘ã€‘
{style_prompt}
---
"""
    narrative_text = await ai_core.ainvoke_with_rotation(
        ai_core.narrative_chain,
        {
            "turn_plan": turn_plan,
            "final_output_mandate": final_output_mandate
        }
    )
    
    return {"llm_response": narrative_text}
# å‡½å¼ï¼šç”Ÿæˆæ•˜äº‹æ–‡æœ¬

# å‡½å¼ï¼šé©—è­‰èˆ‡æ·¨åŒ–è¼¸å‡º
async def validate_and_rewrite_node(state: ConversationGraphState) -> Dict:
    """
    [æ”¶å°¾] ä½¿ç”¨ä¿å®ˆä¸”å®‰å…¨çš„è¦å‰‡ï¼Œå¼·åˆ¶æ·¨åŒ– LLM çš„åŽŸå§‹è¼¸å‡ºï¼ŒåŒæ™‚æœ€å¤§é™åº¦åœ°ä¿å…¨æœ‰æ•ˆå…§å®¹ã€‚
    """
    user_id = state['user_id']
    initial_response = state['llm_response']
    logger.info(f"[{user_id}] (Graph) Node: validate_and_rewrite_node -> [å·²å•Ÿç”¨] æ­£åœ¨å° LLM åŽŸå§‹è¼¸å‡ºé€²è¡Œå…§å®¹ä¿å…¨å¼æ·¨åŒ–...")
    if not initial_response or not initial_response.strip():
        logger.error(f"[{user_id}] æ ¸å¿ƒéˆåœ¨æ·¨åŒ–å‰è¿”å›žäº†ç©ºçš„æˆ–ç„¡æ•ˆçš„å›žæ‡‰ã€‚")
        return {"final_output": "ï¼ˆ...ï¼‰"}
    clean_response = initial_response
    clean_response = re.sub(r'ï¼ˆ(æ€è€ƒ|è¡Œå‹•|è‡ªæˆ‘è§€å¯Ÿ)\s*[:ï¼š\s\S]*?ï¼‰', '', clean_response)
    clean_response = re.sub(r'^\s*(æ—ç™½|å°è©±)\s*[:ï¼š]\s*', '', clean_response, flags=re.MULTILINE)
    if 'æ—ç™½:' in clean_response or 'å°è©±:' in clean_response:
        logger.warning(f"[{user_id}] æª¢æ¸¬åˆ°éžæ¨™æº–æ ¼å¼çš„æ¨™ç±¤æ´©æ¼ï¼Œå•Ÿå‹•å‚™æ´æ¸…ç†ã€‚")
        clean_response = clean_response.replace('æ—ç™½:', '').replace('å°è©±:', '')
        clean_response = clean_response.replace('æ—ç™½ï¼š', '').replace('å°è©±ï¼š', '')
    final_response = clean_response.strip()
    if not final_response:
        logger.warning(f"[{user_id}] LLM åŽŸå§‹è¼¸å‡ºåœ¨æ·¨åŒ–å¾Œç‚ºç©ºã€‚åŽŸå§‹è¼¸å‡ºç‚º: '{initial_response[:200]}...'")
        return {"final_output": "ï¼ˆ...ï¼‰"}
    return {"final_output": final_response}
# å‡½å¼ï¼šé©—è­‰èˆ‡æ·¨åŒ–è¼¸å‡º

# å‡½å¼ï¼šåŸ·è¡Œç‹€æ…‹æ›´æ–°èˆ‡è¨˜æ†¶å„²å­˜
async def persist_state_node(state: ConversationGraphState) -> Dict:
    """
    [æ”¶å°¾] å°‡æœ¬è¼ªå°è©±å­˜å…¥è¨˜æ†¶ï¼Œä¸¦å°‡ state_updates ä¸­çš„è®Šæ›´æ‡‰ç”¨åˆ°è³‡æ–™åº«ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    clean_response = state['final_output']
    logger.info(f"[{user_id}] (Graph) Node: persist_state_node -> æ­£åœ¨æŒä¹…åŒ–ç‹€æ…‹èˆ‡è¨˜æ†¶...")
    if clean_response and clean_response != "ï¼ˆ...ï¼‰":
        chat_history_manager = ai_core.session_histories.get(user_id)
        if chat_history_manager:
            chat_history_manager.add_user_message(user_input)
            chat_history_manager.add_ai_message(clean_response)
        last_interaction_text = f"ä½¿ç”¨è€… '{ai_core.profile.user_profile.name}' èªª: {user_input}\n\n[å ´æ™¯å›žæ‡‰]:\n{clean_response}"
        tasks = []
        tasks.append(ai_core._generate_and_save_personal_memory(last_interaction_text))
        if ai_core.vector_store:
            tasks.append(asyncio.to_thread(ai_core.vector_store.add_texts, [last_interaction_text], metadatas=[{"source": "history"}]))
        async def save_to_sql():
            from .database import AsyncSessionLocal, MemoryData
            import time
            timestamp = time.time()
            async with AsyncSessionLocal() as session:
                session.add(MemoryData(user_id=user_id, content=last_interaction_text, timestamp=timestamp, importance=1))
                await session.commit()
        tasks.append(save_to_sql())
        await asyncio.gather(*tasks, return_exceptions=True)
    return {}
# å‡½å¼ï¼šåŸ·è¡Œç‹€æ…‹æ›´æ–°èˆ‡è¨˜æ†¶å„²å­˜

# å‡½å¼ï¼šè§¸ç™¼èƒŒæ™¯ä¸–ç•Œæ“´å±• (v2.0 - å¢žåŠ å†³ç­–åˆ¤æ–­)
# æ›´æ–°ç´€éŒ„:
# v2.0 (2025-09-03): [é‡å¤§é‚è¼¯å‡ç´š] æ–°å¢žäº†å¯¹ `expansion_decision` çŠ¶æ€çš„åˆ¤æ–­ã€‚çŽ°åœ¨ï¼Œåªæœ‰å½“â€œå®ˆé—¨äººâ€èŠ‚ç‚¹ (`expansion_decision_node`) æ˜Žç¡®å…è®¸æ—¶ï¼Œæœ¬èŠ‚ç‚¹æ‰ä¼šçœŸæ­£åœ°åˆ›å»ºèƒŒæ™¯æ‰©å±•ä»»åŠ¡ã€‚æ­¤ä¿®æ”¹ç¡®ä¿äº†èƒŒæ™¯å¡«å……ä¸Žä¸»æµç¨‹çš„ LORE æ‰©å±•å†³ç­–ä¿æŒå®Œå…¨ä¸€è‡´ã€‚
async def background_world_expansion_node(state: ConversationGraphState) -> Dict:
    """
    [æ”¶å°¾] åœ¨å›žæ‡‰ç™¼é€å¾Œï¼Œæ ¹æ“šæ“´å±•æ±ºç­–ï¼Œéžé˜»å¡žåœ°è§¸ç™¼èƒŒæ™¯ä¸–ç•Œæ“´å±•ã€LOREç”Ÿæˆç­‰ä»»å‹™ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    clean_response = state['final_output']
    scene_analysis = state.get('scene_analysis') # ä½¿ç”¨ .get() å®‰å…¨è®¿é—®
    expansion_decision = state.get('expansion_decision')

    logger.info(f"[{user_id}] (Graph) Node: background_world_expansion_node -> æ­£åœ¨æª¢æŸ¥æ˜¯å¦è§¸ç™¼èƒŒæ™¯ä»»å‹™...")

    # [v2.0 æ ¸å¿ƒä¿®æ­£] åªæœ‰åœ¨å®ˆé—¨äººå…è®¸æ—¶æ‰æ‰§è¡Œ
    if expansion_decision and expansion_decision.should_expand:
        effective_location_path = ai_core.profile.game_state.location_path
        if scene_analysis and scene_analysis.target_location_path:
            effective_location_path = scene_analysis.target_location_path
        
        if clean_response and clean_response != "ï¼ˆ...ï¼‰":
            asyncio.create_task(ai_core._background_scene_expansion(user_input, clean_response, effective_location_path))
            logger.info(f"[{user_id}] å·²æˆåŠŸç‚ºåœ°é»ž '{' > '.join(effective_location_path)}' å‰µå»ºèƒŒæ™¯æ“´å±•ä»»å‹™ã€‚")
    else:
        logger.info(f"[{user_id}] (Graph) Node: background_world_expansion_node -> æ ¹æ“šæ±ºç­–ï¼Œæœ¬è¼ªè·³éŽèƒŒæ™¯æ“´å±•ã€‚")

    return {}
# å‡½å¼ï¼šè§¸ç™¼èƒŒæ™¯ä¸–ç•Œæ“´å±• (v2.0 - å¢žåŠ å†³ç­–åˆ¤æ–­)

# å‡½å¼ï¼šåœ–å½¢çµæŸ finalizing
async def finalization_node(state: ConversationGraphState) -> Dict:
    """
    [æ”¶å°¾] ä¸€å€‹è™›æ“¬çš„æœ€çµ‚ç¯€é»žï¼Œç¢ºä¿æ‰€æœ‰ç•°æ­¥èƒŒæ™¯ä»»å‹™éƒ½è¢«æˆåŠŸèª¿åº¦ã€‚
    """
    user_id = state['user_id']
    logger.info(f"[{user_id}] (Graph) Node: finalization_node -> å°è©±æµç¨‹åœ–åŸ·è¡Œå®Œç•¢ã€‚")
    return {}
# å‡½å¼ï¼šåœ–å½¢çµæŸ finalizing

# --- ä¸»å°è©±åœ–çš„è·¯ç”± ---

# å‡½å¼ï¼šåœ¨æ“´å±•æ±ºç­–å¾Œæ±ºå®šæµç¨‹ (v1.0 - å…¨æ–°å‰µå»º)
def route_expansion(state: ConversationGraphState) -> Literal["expand_lore", "skip_expansion"]:
    """
    æ ¹æ“š expansion_decision_node çš„çµæžœï¼Œæ±ºå®šæ˜¯é€²å…¥LOREå‰µé€ æµç¨‹ï¼Œé‚„æ˜¯ç›´æŽ¥è·³åˆ°æ ¸å¿ƒè¦åŠƒã€‚
    """
    user_id = state['user_id']
    should_expand = state["expansion_decision"].should_expand
    
    if should_expand:
        logger.info(f"[{user_id}] (Graph) Router: route_expansion -> åˆ¤å®šç‚ºã€é€²è¡ŒLOREæ“´å±•ã€‘ã€‚")
        return "expand_lore"
    else:
        logger.info(f"[{user_id}] (Graph) Router: route_expansion -> åˆ¤å®šç‚ºã€è·³éŽLOREæ“´å±•ã€‘ã€‚")
        return "skip_expansion"
# å‡½å¼ï¼šåœ¨æ“´å±•æ±ºç­–å¾Œæ±ºå®šæµç¨‹ (v1.0 - å…¨æ–°å‰µå»º)

# --- ä¸»å°è©±åœ–çš„å»ºæ§‹å™¨ ---

# å‡½å¼ï¼šå‰µå»ºä¸»å›žæ‡‰åœ– (v6.0 - æ•´åˆå®ˆé–€äººæ©Ÿåˆ¶)
# æ›´æ–°ç´€éŒ„:
# v6.0 (2025-09-03): [é‡å¤§é‚è¼¯å‡ç´š] å°ä¸»å°è©±åœ–é€²è¡Œäº†ç³»çµ±æ€§é‡æ§‹ï¼Œå¼•å…¥äº†â€œå®ˆé–€äººâ€æ©Ÿåˆ¶ã€‚
#    1. [æ–°å¢žå®ˆé–€äººç¯€é»ž] å¼•å…¥äº† `expansion_decision_node`ï¼Œåœ¨æµç¨‹æ—©æœŸåˆ¤æ–·ç”¨æˆ¶çš„â€œæŽ¢ç´¢æ„åœ–â€ã€‚
#    2. [æ–°å¢žæ¢ä»¶è·¯ç”±] å¼•å…¥äº† `route_expansion` è·¯ç”±ï¼Œæ ¹æ“šæ±ºç­–å°‡æµç¨‹å°Žå‘â€œæ“´å±•â€æˆ–â€œè·³éŽâ€åˆ†æ”¯ã€‚
#    3. [é‡æ§‹åœ–æ‹“æ’²] å¦‚æžœæ±ºç­–ç‚ºâ€œæ“´å±•â€ï¼Œæµç¨‹å°‡é€²å…¥ `scene_and_action_analysis_node` (é¸è§’)ï¼›å¦‚æžœç‚ºâ€œè·³éŽâ€ï¼Œå‰‡å®Œå…¨ç¹žéŽæ­¤ç¯€é»žï¼Œç›´æŽ¥é€²å…¥è¦åŠƒã€‚æ­¤ä¿®æ”¹å¾žæ ¹æœ¬ä¸Šè§£æ±ºäº†åœ¨ç°¡å–®äº’å‹•ä¸­ç„¡æ„ç¾©ç”Ÿæˆæ–°LOREçš„å•é¡Œã€‚
def create_main_response_graph() -> StateGraph:
    """
    çµ„è£ä¸¦ç·¨è­¯ä¸»å°è©±æµç¨‹çš„ StateGraphã€‚
    """
    graph = StateGraph(ConversationGraphState)

    # è¨»å†Šæ‰€æœ‰ç¯€é»ž
    graph.add_node("initialize_state", initialize_conversation_state_node)
    graph.add_node("analyze_input", analyze_input_node)
    graph.add_node("expansion_decision", expansion_decision_node) # æ–°å¢žå®ˆé–€äººç¯€é»ž
    graph.add_node("scene_and_action_analysis", scene_and_action_analysis_node)
    graph.add_node("planning", planning_node)
    graph.add_node("tool_execution", tool_execution_node)
    graph.add_node("narrative", narrative_node)
    graph.add_node("validate_and_rewrite", validate_and_rewrite_node)
    graph.add_node("persist_state", persist_state_node)
    graph.add_node("background_expansion", background_world_expansion_node)
    graph.add_node("finalization", finalization_node)

    # è¨­å®šåœ–çš„å…¥å£
    graph.set_entry_point("initialize_state")

    # å®šç¾©åœ–çš„é‚Šï¼ˆæµç¨‹ï¼‰
    graph.add_edge("initialize_state", "analyze_input")
    graph.add_edge("analyze_input", "expansion_decision") # åˆ†æžå¾Œå…ˆåšæ±ºç­–

    # æ–°å¢žæ¢ä»¶è·¯ç”±
    graph.add_conditional_edges(
        "expansion_decision",
        route_expansion,
        {
            "expand_lore": "scene_and_action_analysis", # å¦‚æžœæ“´å±•ï¼Œå‰‡åŽ»é¸è§’
            "skip_expansion": "planning"  # å¦‚æžœä¸æ“´å±•ï¼Œç›´æŽ¥åŽ»è¦åŠƒ
        }
    )

    graph.add_edge("scene_and_action_analysis", "planning") # é¸è§’å¾ŒåŽ»è¦åŠƒ
    
    # å¾ŒçºŒæµç¨‹ä¿æŒä¸è®Š
    graph.add_edge("planning", "tool_execution")
    graph.add_edge("tool_execution", "narrative")
    graph.add_edge("narrative", "validate_and_rewrite")
    graph.add_edge("validate_and_rewrite", "persist_state")
    graph.add_edge("persist_state", "background_expansion")
    graph.add_edge("background_expansion", "finalization")
    graph.add_edge("finalization", END)
    
    return graph.compile()
# å‡½å¼ï¼šå‰µå»ºä¸»å›žæ‡‰åœ– (v6.0 - æ•´åˆå®ˆé–€äººæ©Ÿåˆ¶)

# --- è¨­å®šåœ– (Setup Graph) çš„ç¯€é»ž (ä¿æŒä¸è®Š) ---
# ... (æ­¤éƒ¨åˆ†èˆ‡æ‚¨æä¾›çš„æª”æ¡ˆå®Œå…¨ç›¸åŒï¼Œæ•…çœç•¥ä»¥ç¯€çœç¯‡å¹…ï¼Œä½†åœ¨æä¾›çš„å®Œæ•´æª”æ¡ˆä¸­æœƒåŒ…å«)
async def process_canon_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    canon_text = state['canon_text']
    if canon_text:
        logger.info(f"[{user_id}] (Setup Graph) Node: process_canon_node -> æ­£åœ¨è™•ç†ä¸–ç•Œè–ç¶“...")
        await ai_core.add_canon_to_vector_store(canon_text)
        await ai_core.parse_and_create_lore_from_canon(None, canon_text, is_setup_flow=True)
        if not await ai_core.initialize():
            raise Exception("åœ¨è¼‰å…¥ä¸–ç•Œè–ç¶“å¾Œé‡æ–°åˆå§‹åŒ– AI æ ¸å¿ƒå¤±æ•—ã€‚")
    return {}
async def complete_profiles_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    logger.info(f"[{user_id}] (Setup Graph) Node: complete_profiles_node -> æ­£åœ¨è£œå®Œè§’è‰²æª”æ¡ˆ...")
    completion_prompt = ai_core.get_profile_completion_prompt()
    completion_llm = ai_core.gm_model.with_structured_output(CharacterProfile)
    completion_chain = completion_prompt | completion_llm
    completed_user_profile = await ai_core.ainvoke_with_rotation(completion_chain, {"profile_json": ai_core.profile.user_profile.model_dump_json()})
    completed_ai_profile = await ai_core.ainvoke_with_rotation(completion_chain, {"profile_json": ai_core.profile.ai_profile.model_dump_json()})
    await ai_core.update_and_persist_profile({'user_profile': completed_user_profile.model_dump(), 'ai_profile': completed_ai_profile.model_dump()})
    return {}
async def world_genesis_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    logger.info(f"[{user_id}] (Setup Graph) Node: world_genesis_node -> æ­£åœ¨åŸ·è¡Œä¸–ç•Œå‰µä¸–...")
    genesis_chain = ai_core.get_world_genesis_chain()
    genesis_result = await ai_core.ainvoke_with_rotation(genesis_chain, {"world_settings": ai_core.profile.world_settings, "username": ai_core.profile.user_profile.name, "ai_name": ai_core.profile.ai_profile.name})
    if not genesis_result:
        raise Exception("ä¸–ç•Œå‰µä¸–éˆè¿”å›žäº†ç©ºçµæžœï¼Œå¯èƒ½æ˜¯å…§å®¹å¯©æŸ¥ã€‚")
    gs = ai_core.profile.game_state
    gs.location_path = genesis_result.location_path
    await ai_core.update_and_persist_profile({'game_state': gs.model_dump()})
    await lore_book.add_or_update_lore(user_id, 'location_info', " > ".join(genesis_result.location_path), genesis_result.location_info.model_dump())
    for npc in genesis_result.initial_npcs:
        npc_key = " > ".join(genesis_result.location_path) + f" > {npc.name}"
        await lore_book.add_or_update_lore(user_id, 'npc_profile', npc_key, npc.model_dump())
    return {"genesis_result": genesis_result}
async def generate_opening_scene_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    logger.info(f"[{user_id}] (Setup Graph) Node: generate_opening_scene_node -> æ­£åœ¨ç”Ÿæˆé–‹å ´ç™½...")
    opening_scene = await ai_core.generate_opening_scene()
    if not opening_scene or not opening_scene.strip():
        opening_scene = (f"åœ¨ä¸€ç‰‡æŸ”å’Œçš„å…‰èŠ’ä¸­ï¼Œä½ å’Œ {ai_core.profile.ai_profile.name} ç™¼ç¾è‡ªå·±èº«è™•æ–¼ä¸€å€‹å¯§éœçš„ç©ºé–“è£¡ï¼Œæ•…äº‹å³å°‡å¾žé€™è£¡é–‹å§‹ã€‚"
                         "\n\nï¼ˆç³»çµ±æç¤ºï¼šç”±æ–¼æ‚¨çš„è¨­å®šï¼ŒAIç„¡æ³•ç”Ÿæˆæ›´è©³ç´°çš„é–‹å ´ç™½ï¼Œä½†æ‚¨ç¾åœ¨å¯ä»¥é–‹å§‹äº’å‹•äº†ã€‚ï¼‰")
    return {"opening_scene": opening_scene}
def create_setup_graph() -> StateGraph:
    graph = StateGraph(SetupGraphState)
    graph.add_node("process_canon", process_canon_node)
    graph.add_node("complete_profiles", complete_profiles_node)
    graph.add_node("world_genesis", world_genesis_node)
    graph.add_node("generate_opening_scene", generate_opening_scene_node)
    graph.set_entry_point("process_canon")
    graph.add_edge("process_canon", "complete_profiles")
    graph.add_edge("complete_profiles", "world_genesis")
    graph.add_edge("world_genesis", "generate_opening_scene")
    graph.add_edge("generate_opening_scene", END)
    return graph.compile()
