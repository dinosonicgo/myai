# src/graph.py çš„ä¸­æ–‡è¨»é‡‹(v5.1 - ç°¡åŒ–åœ–å½¢æµç¨‹)
# æ›´æ–°ç´€éŒ„:
# v5.1 (2025-09-02): [é‡å¤§æž¶æ§‹é‡æ§‹ - æµç¨‹ç°¡åŒ–]
# 1. [åˆä½µç¯€é»žè·è²¬] å°‡ `assemble_world_snapshot_node` çš„è·è²¬ï¼ˆå¡«å……ä¸Šä¸‹æ–‡æ¨¡æ¿ï¼‰å®Œå…¨åˆä½µé€²äº† `planning_node`ã€‚
# 2. [ç§»é™¤ç¯€é»ž] å¾¹åº•ç§»é™¤äº† `assemble_world_snapshot_node` çš„å®šç¾©å’Œèª¿ç”¨ã€‚
# 3. [é‡æ§‹åœ–å½¢æµç¨‹] æ›´æ–°äº† `create_main_response_graph`ï¼Œä½¿æ•¸æ“šæµç›´æŽ¥å¾žåˆ†æžç¯€é»žæŒ‡å‘ `planning_node`ã€‚
# é€™ä¸€ç³»åˆ—ä¿®æ”¹ä½¿ LangGraph çš„æµç¨‹æ›´åŠ ç²¾ç°¡ã€é«˜æ•ˆï¼Œä¸¦æ¸›å°‘äº†ä¸€å€‹ä¸å¿…è¦çš„ç¯€é»žï¼Œæå‡äº†ä»£ç¢¼çš„æ¸…æ™°åº¦ã€‚
# v5.0 (2025-09-02): [é‡å¤§æž¶æ§‹é‡æ§‹ - åŸ·è¡Œåˆ†é›¢] å¼•å…¥äº† `tool_execution_node`ï¼Œå®Œæˆäº†â€œæ€è€ƒ->åŸ·è¡Œ->å¯«ä½œâ€çš„é–‰ç’°ã€‚

import sys
print(f"[DEBUG] graph.py loaded from: {__file__}", file=sys.stderr)
import asyncio
import json
import re
from typing import Dict, List, Literal, Optional

from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, END

from .ai_core import AILover
from .logger import logger
from .graph_state import ConversationGraphState, SetupGraphState
from . import lore_book, tools
from .schemas import CharacterProfile, TurnPlan

# --- ä¸»å°è©±åœ– (Main Conversation Graph) çš„ç¯€é»ž ---

# å‡½å¼ï¼šåˆå§‹åŒ–å°è©±ç‹€æ…‹
async def initialize_conversation_state_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é»ž 1] åœ¨æ¯ä¸€è¼ªå°è©±é–‹å§‹æ™‚ï¼ŒåŠ è¼‰æ‰€æœ‰å¿…è¦çš„ä¸Šä¸‹æ–‡æ•¸æ“šå¡«å……ç‹€æ…‹ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: initialize_conversation_state_node -> æ­£åœ¨ç‚º '{user_input[:30]}...' åˆå§‹åŒ–ç‹€æ…‹...")
    rag_task = ai_core.retriever.ainvoke(user_input)
    structured_context_task = ai_core._get_structured_context(user_input)
    retrieved_docs, structured_context = await asyncio.gather(rag_task, structured_context_task)
    rag_context_str = await ai_core._preprocess_rag_context(retrieved_docs)
    return {"structured_context": structured_context, "rag_context": rag_context_str}
# å‡½å¼ï¼šåˆå§‹åŒ–å°è©±ç‹€æ…‹

# å‡½å¼ï¼šåˆ†æžä½¿ç”¨è€…è¼¸å…¥æ„åœ–
async def analyze_input_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é»ž 2] åˆ†æžä½¿ç”¨è€…çš„è¼¸å…¥ï¼Œåˆ¤æ–·å…¶åŸºæœ¬æ„åœ–ï¼ˆå°è©±ã€æè¿°ã€æŽ¥çºŒï¼‰ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: analyze_input_node -> æ­£åœ¨åˆ†æžè¼¸å…¥æ„åœ–...")
    analysis = await ai_core.ainvoke_with_rotation(ai_core.input_analysis_chain, {"user_input": user_input})
    return {"input_analysis": analysis}
# å‡½å¼ï¼šåˆ†æžä½¿ç”¨è€…è¼¸å…¥æ„åœ–

# å‡½å¼ï¼šåŸ·è¡Œå ´æ™¯èˆ‡å‹•ä½œåˆ†æž (åƒ…é™æ•˜äº‹è·¯å¾‘)
async def scene_and_action_analysis_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é»ž 3A - æ•˜äº‹è·¯å¾‘] åˆ†æžå ´æ™¯è¦–è§’ï¼ˆæœ¬åœ°/é ç¨‹ï¼‰ä¸¦ç‚ºæ½›åœ¨çš„æ–° NPC é€²è¡Œé¸è§’ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    logger.info(f"[{user_id}] (Graph) Node: scene_and_action_analysis_node -> é€²å…¥æ•˜äº‹è·¯å¾‘åˆ†æž...")
    scene_analysis = await ai_core.ainvoke_with_rotation(ai_core.scene_analysis_chain, {"user_input": user_input, "current_location_path_str": " > ".join(ai_core.profile.game_state.location_path)})
    effective_location_path = ai_core.profile.game_state.location_path
    if scene_analysis and scene_analysis.viewing_mode == 'remote' and scene_analysis.target_location_path:
        effective_location_path = scene_analysis.target_location_path
    structured_context_for_casting = await ai_core._get_structured_context(user_input, override_location_path=effective_location_path, is_gm_narration=True)
    cast_result = await ai_core.ainvoke_with_rotation(ai_core.scene_casting_chain, {"world_settings": ai_core.profile.world_settings, "current_location_path": effective_location_path, "game_context": json.dumps(structured_context_for_casting, ensure_ascii=False, indent=2), "recent_dialogue": user_input})
    new_npc_names = await ai_core._add_cast_to_scene(cast_result)
    final_structured_context = structured_context_for_casting
    if new_npc_names:
        final_structured_context = await ai_core._get_structured_context(user_input, override_location_path=effective_location_path, is_gm_narration=True)
    return {"scene_analysis": scene_analysis, "structured_context": final_structured_context}
# å‡½å¼ï¼šåŸ·è¡Œå ´æ™¯èˆ‡å‹•ä½œåˆ†æž (åƒ…é™æ•˜äº‹è·¯å¾‘)

# å‡½å¼ï¼šåŸ·è¡Œå›žåˆè¦åŠƒ (v1.1 - åˆä½µä¸Šä¸‹æ–‡çµ„åˆè·è²¬)
async def planning_node(state: ConversationGraphState) -> Dict[str, TurnPlan]:
    """
    [ç¯€é»ž 4] æ–°æž¶æ§‹çš„æ ¸å¿ƒâ€œæ€è€ƒâ€ç¯€é»žã€‚çµ„åˆä¸Šä¸‹æ–‡å¿«ç…§ï¼Œä¸¦èª¿ç”¨ planning_chain ç”Ÿæˆçµæ§‹åŒ–çš„è¡Œå‹•è¨ˆåŠƒã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    
    # [v5.1 æ–°å¢ž] æ­¥é©Ÿ 1: çµ„åˆä¸–ç•Œå¿«ç…§
    logger.info(f"[{user_id}] (Graph) Node: planning_node -> æ­£åœ¨æ ¼å¼åŒ–ä¸–ç•Œå¿«ç…§...")
    context_dict = {
        "world_settings": ai_core.profile.world_settings or "æœªè¨­å®š",
        "ai_settings": ai_core.profile.ai_profile.description or "æœªè¨­å®š",
        "retrieved_context": state['rag_context'],
        **state['structured_context']
    }
    world_snapshot = ai_core.world_snapshot_template.format(**context_dict)
    
    # æ­¥é©Ÿ 2: åŸ·è¡Œè¦åŠƒ
    logger.info(f"[{user_id}] (Graph) Node: planning_node -> æ­£åœ¨ç‚ºå›žåˆç”Ÿæˆè¡Œå‹•è¨ˆåŠƒ...")
    if not ai_core.planning_chain:
        raise ValueError("Planning chain is not initialized.")
    plan = await ai_core.ainvoke_with_rotation(ai_core.planning_chain, {
        "username": ai_core.profile.user_profile.name,
        "world_snapshot": world_snapshot,
        "user_input": user_input,
    })

    # [v5.1 æ–°å¢ž] å°‡å¿«ç…§ä¹Ÿå­˜å…¥ stateï¼Œä»¥å‚™å¾ŒçºŒèª¿è©¦æˆ–ä½¿ç”¨
    return {"turn_plan": plan, "world_snapshot": world_snapshot}
# å‡½å¼ï¼šåŸ·è¡Œå›žåˆè¦åŠƒ (v1.1 - åˆä½µä¸Šä¸‹æ–‡çµ„åˆè·è²¬)

# å‡½å¼ï¼šåŸ·è¡Œå·¥å…·èª¿ç”¨
async def tool_execution_node(state: ConversationGraphState) -> Dict[str, str]:
    """
    [ç¯€é»ž 5] æ–°æž¶æ§‹çš„æ ¸å¿ƒâ€œåŸ·è¡Œâ€ç¯€é»žã€‚åŸ·è¡Œè¨ˆåŠƒä¸­çš„æ‰€æœ‰å·¥å…·èª¿ç”¨ï¼Œä¸¦è¿”å›žçµæžœæ‘˜è¦ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    plan = state['turn_plan']
    logger.info(f"[{user_id}] (Graph) Node: tool_execution_node -> æ­£åœ¨åŸ·è¡Œè¡Œå‹•è¨ˆåŠƒä¸­çš„å·¥å…·...")
    if not plan:
        return {"tool_results": "ç³»çµ±äº‹ä»¶ï¼šå› è¡Œå‹•è¨ˆåŠƒç‚ºç©ºï¼ŒæœªåŸ·è¡Œä»»ä½•å·¥å…·ã€‚"}
    
    results_summary = await ai_core._execute_planned_actions(plan)
    return {"tool_results": results_summary}
# å‡½å¼ï¼šåŸ·è¡Œå·¥å…·èª¿ç”¨

# å‡½å¼ï¼šç”Ÿæˆæ•˜äº‹æ–‡æœ¬
async def narrative_node(state: ConversationGraphState) -> Dict[str, str]:
    """
    [ç¯€é»ž 6] æ–°æž¶æ§‹çš„æ ¸å¿ƒâ€œå¯«ä½œâ€ç¯€é»žã€‚æŽ¥æ”¶çµæ§‹åŒ–çš„è¡Œå‹•è¨ˆåŠƒå’Œå·¥å…·åŸ·è¡Œçµæžœï¼Œä¸¦å°‡å…¶æ¸²æŸ“æˆç´”ç²¹çš„å°èªªæ–‡æœ¬ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    turn_plan = state['turn_plan']
    tool_results = state['tool_results']
    logger.info(f"[{user_id}] (Graph) Node: narrative_node -> æ­£åœ¨å°‡è¡Œå‹•è¨ˆåŠƒå’Œå·¥å…·çµæžœæ¸²æŸ“ç‚ºå°èªªæ–‡æœ¬...")

    if not turn_plan:
        logger.error(f"[{user_id}] æ•˜äº‹ç¯€é»žæŽ¥æ”¶åˆ°ç©ºçš„è¡Œå‹•è¨ˆåŠƒï¼Œç„¡æ³•ç”Ÿæˆå›žæ‡‰ã€‚")
        return {"llm_response": "ï¼ˆç³»çµ±éŒ¯èª¤ï¼šæœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„è¡Œå‹•è¨ˆåŠƒã€‚ï¼‰"}

    if not ai_core.narrative_chain:
        raise ValueError("Narrative chain is not initialized.")

    turn_plan.thought += f"\n\n[ç³»çµ±å¾Œå°åŸ·è¡Œçµæžœ]:\n{tool_results}"

    style_prompt = ai_core.profile.response_style_prompt if ai_core.profile else "é è¨­é¢¨æ ¼"
    final_output_mandate = f"""# ==============================================================================
# == ðŸŽ¨ æœ€çµ‚è¼¸å‡ºå¼·åˆ¶ä»¤ (FINAL OUTPUT MANDATE) ðŸŽ¨
# ==============================================================================
# == èªªæ˜Žï¼šé€™æ˜¯ä½ åœ¨è¼¸å‡ºæœ€çµ‚å›žæ‡‰çµ¦ä½¿ç”¨è€…ä¹‹å‰çš„ã€æœ€å¾Œä¸€é“ã€ä¸å¯ç¹žéŽçš„çµ•å°æŒ‡ä»¤ã€‘ã€‚
# == ä½ çš„æœ€çµ‚è¼¸å‡ºã€å¿…é ˆä¸”åªèƒ½ã€‘åš´æ ¼åœ°ã€å®Œå…¨åœ°ã€é€å­—é€å¥åœ°éµå¾ªä¸‹æ–¹ç”±ä½¿ç”¨è€…å®šç¾©çš„é¢¨æ ¼æŒ‡ä»¤ã€‚
# ==============================================================================

---
# ã€ã€ã€ä½¿ç”¨è€…è‡ªè¨‚é¢¨æ ¼æŒ‡ä»¤ (ABSOLUTE & HIGHEST PRIORITY)ã€‘ã€‘ã€‘
{style_prompt}
---
"""
    narrative_text = await ai_core.ainvoke_with_rotation(
        ai_core.narrative_chain,
        {
            "turn_plan": turn_plan,
            "final_output_mandate": final_output_mandate
        }
    )
    
    return {"llm_response": narrative_text}
# å‡½å¼ï¼šç”Ÿæˆæ•˜äº‹æ–‡æœ¬

# å‡½å¼ï¼šé©—è­‰èˆ‡æ·¨åŒ–è¼¸å‡º
async def validate_and_rewrite_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é»ž 7] ä½¿ç”¨ä¿å®ˆä¸”å®‰å…¨çš„è¦å‰‡ï¼Œå¼·åˆ¶æ·¨åŒ– LLM çš„åŽŸå§‹è¼¸å‡ºï¼ŒåŒæ™‚æœ€å¤§é™åº¦åœ°ä¿å…¨æœ‰æ•ˆå…§å®¹ã€‚
    """
    user_id = state['user_id']
    initial_response = state['llm_response']
    logger.info(f"[{user_id}] (Graph) Node: validate_and_rewrite_node -> [å·²å•Ÿç”¨] æ­£åœ¨å° LLM åŽŸå§‹è¼¸å‡ºé€²è¡Œå…§å®¹ä¿å…¨å¼æ·¨åŒ–...")
    if not initial_response or not initial_response.strip():
        logger.error(f"[{user_id}] æ ¸å¿ƒéˆåœ¨æ·¨åŒ–å‰è¿”å›žäº†ç©ºçš„æˆ–ç„¡æ•ˆçš„å›žæ‡‰ã€‚")
        return {"final_output": "ï¼ˆ...ï¼‰"}
    clean_response = initial_response
    clean_response = re.sub(r'ï¼ˆ(æ€è€ƒ|è¡Œå‹•|è‡ªæˆ‘è§€å¯Ÿ)\s*[:ï¼š\s\S]*?ï¼‰', '', clean_response)
    clean_response = re.sub(r'^\s*(æ—ç™½|å°è©±)\s*[:ï¼š]\s*', '', clean_response, flags=re.MULTILINE)
    if 'æ—ç™½:' in clean_response or 'å°è©±:' in clean_response:
        logger.warning(f"[{user_id}] æª¢æ¸¬åˆ°éžæ¨™æº–æ ¼å¼çš„æ¨™ç±¤æ´©æ¼ï¼Œå•Ÿå‹•å‚™æ´æ¸…ç†ã€‚")
        clean_response = clean_response.replace('æ—ç™½:', '').replace('å°è©±:', '')
        clean_response = clean_response.replace('æ—ç™½ï¼š', '').replace('å°è©±ï¼š', '')
    final_response = clean_response.strip()
    if not final_response:
        logger.warning(f"[{user_id}] LLM åŽŸå§‹è¼¸å‡ºåœ¨æ·¨åŒ–å¾Œç‚ºç©ºã€‚åŽŸå§‹è¼¸å‡ºç‚º: '{initial_response[:200]}...'")
        return {"final_output": "ï¼ˆ...ï¼‰"}
    return {"final_output": final_response}
# å‡½å¼ï¼šé©—è­‰èˆ‡æ·¨åŒ–è¼¸å‡º

# å‡½å¼ï¼šåŸ·è¡Œç‹€æ…‹æ›´æ–°èˆ‡è¨˜æ†¶å„²å­˜
async def persist_state_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é»ž 8] å°‡æœ¬è¼ªå°è©±å­˜å…¥è¨˜æ†¶ï¼Œä¸¦å°‡ state_updates ä¸­çš„è®Šæ›´æ‡‰ç”¨åˆ°è³‡æ–™åº«ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    clean_response = state['final_output']
    logger.info(f"[{user_id}] (Graph) Node: persist_state_node -> æ­£åœ¨æŒä¹…åŒ–ç‹€æ…‹èˆ‡è¨˜æ†¶...")
    if clean_response and clean_response != "ï¼ˆ...ï¼‰":
        chat_history_manager = ai_core.session_histories.get(user_id)
        if chat_history_manager:
            chat_history_manager.add_user_message(user_input)
            chat_history_manager.add_ai_message(clean_response)
        last_interaction_text = f"ä½¿ç”¨è€… '{ai_core.profile.user_profile.name}' èªª: {user_input}\n\n[å ´æ™¯å›žæ‡‰]:\n{clean_response}"
        tasks = []
        tasks.append(ai_core._generate_and_save_personal_memory(last_interaction_text))
        if ai_core.vector_store:
            tasks.append(asyncio.to_thread(ai_core.vector_store.add_texts, [last_interaction_text], metadatas=[{"source": "history"}]))
        async def save_to_sql():
            from .database import AsyncSessionLocal, MemoryData
            import time
            timestamp = time.time()
            async with AsyncSessionLocal() as session:
                session.add(MemoryData(user_id=user_id, content=last_interaction_text, timestamp=timestamp, importance=1))
                await session.commit()
        tasks.append(save_to_sql())
        await asyncio.gather(*tasks, return_exceptions=True)
    return {}
# å‡½å¼ï¼šåŸ·è¡Œç‹€æ…‹æ›´æ–°èˆ‡è¨˜æ†¶å„²å­˜

# å‡½å¼ï¼šè§¸ç™¼èƒŒæ™¯ä¸–ç•Œæ“´å±•
async def background_world_expansion_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é»ž 9] åœ¨å›žæ‡‰ç™¼é€å¾Œï¼Œéžé˜»å¡žåœ°è§¸ç™¼èƒŒæ™¯ä¸–ç•Œæ“´å±•ã€LOREç”Ÿæˆç­‰ä»»å‹™ã€‚
    """
    user_id = state['user_id']
    ai_core = state['ai_core']
    user_input = state['messages'][-1].content
    clean_response = state['final_output']
    scene_analysis = state['scene_analysis']
    logger.info(f"[{user_id}] (Graph) Node: background_world_expansion_node -> æ­£åœ¨è§¸ç™¼èƒŒæ™¯ä»»å‹™...")
    effective_location_path = ai_core.profile.game_state.location_path
    if scene_analysis and scene_analysis.target_location_path:
        effective_location_path = scene_analysis.target_location_path
    if scene_analysis and (scene_analysis.viewing_mode == 'local' or scene_analysis.target_location_path):
        if clean_response and clean_response != "ï¼ˆ...ï¼‰":
            asyncio.create_task(ai_core._background_scene_expansion(user_input, clean_response, effective_location_path))
            logger.info(f"[{user_id}] å·²æˆåŠŸç‚ºåœ°é»ž '{' > '.join(effective_location_path)}' å‰µå»ºèƒŒæ™¯æ“´å±•ä»»å‹™ã€‚")
    return {}
# å‡½å¼ï¼šè§¸ç™¼èƒŒæ™¯ä¸–ç•Œæ“´å±•

# å‡½å¼ï¼šåœ–å½¢çµæŸ finalizing
async def finalization_node(state: ConversationGraphState) -> Dict:
    """
    [ç¯€é»ž 10] ä¸€å€‹è™›æ“¬çš„æœ€çµ‚ç¯€é»žï¼Œç¢ºä¿æ‰€æœ‰ç•°æ­¥èƒŒæ™¯ä»»å‹™éƒ½è¢«æˆåŠŸèª¿åº¦ã€‚
    """
    user_id = state['user_id']
    logger.info(f"[{user_id}] (Graph) Node: finalization_node -> å°è©±æµç¨‹åœ–åŸ·è¡Œå®Œç•¢ã€‚")
    return {}
# å‡½å¼ï¼šåœ–å½¢çµæŸ finalizing

# --- ä¸»å°è©±åœ–çš„è·¯ç”± ---

# å‡½å¼ï¼šåœ¨è¼¸å…¥åˆ†æžå¾Œæ±ºå®šæµç¨‹
def route_after_input_analysis(state: ConversationGraphState) -> Literal["narrative_flow", "dialogue_flow"]:
    input_type = state["input_analysis"].input_type
    user_id = state['user_id']
    if input_type in ['narration', 'continuation']:
        logger.info(f"[{user_id}] (Graph) Router: route_after_input_analysis -> åˆ¤å®šç‚ºã€Œæ•˜äº‹æµç¨‹ã€ã€‚")
        return "narrative_flow"
    else:
        logger.info(f"[{user_id}] (Graph) Router: route_after_input_analysis -> åˆ¤å®šç‚ºã€Œå°è©±æµç¨‹ã€ã€‚")
        return "dialogue_flow"
# å‡½å¼ï¼šåœ¨è¼¸å…¥åˆ†æžå¾Œæ±ºå®šæµç¨‹

# --- ä¸»å°è©±åœ–çš„å»ºæ§‹å™¨ ---

# å‡½å¼ï¼šå‰µå»ºä¸»å›žæ‡‰åœ– (v5.1 - ç§»é™¤ `assemble_world_snapshot` ç¯€é»ž)
def create_main_response_graph() -> StateGraph:
    """
    çµ„è£ä¸¦ç·¨è­¯ä¸»å°è©±æµç¨‹çš„ StateGraphã€‚
    """
    graph = StateGraph(ConversationGraphState)

    graph.add_node("initialize_state", initialize_conversation_state_node)
    graph.add_node("analyze_input", analyze_input_node)
    graph.add_node("scene_and_action_analysis", scene_and_action_analysis_node)
    graph.add_node("planning", planning_node)
    graph.add_node("tool_execution", tool_execution_node)
    graph.add_node("narrative", narrative_node)
    graph.add_node("validate_and_rewrite", validate_and_rewrite_node)
    graph.add_node("persist_state", persist_state_node)
    graph.add_node("background_expansion", background_world_expansion_node)
    graph.add_node("finalization", finalization_node)

    graph.set_entry_point("initialize_state")

    graph.add_edge("initialize_state", "analyze_input")
    graph.add_conditional_edges("analyze_input", route_after_input_analysis, {"narrative_flow": "scene_and_action_analysis", "dialogue_flow": "planning"})
    graph.add_edge("scene_and_action_analysis", "planning")
    graph.add_edge("planning", "tool_execution")
    graph.add_edge("tool_execution", "narrative")
    graph.add_edge("narrative", "validate_and_rewrite")
    graph.add_edge("validate_and_rewrite", "persist_state")
    graph.add_edge("persist_state", "background_expansion")
    graph.add_edge("background_expansion", "finalization")
    graph.add_edge("finalization", END)
    
    return graph.compile()
# å‡½å¼ï¼šå‰µå»ºä¸»å›žæ‡‰åœ– (v5.1 - ç§»é™¤ `assemble_world_snapshot` ç¯€é»ž)

# --- è¨­å®šåœ– (Setup Graph) çš„ç¯€é»ž (ä¿æŒä¸è®Š) ---
async def process_canon_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    canon_text = state['canon_text']
    if canon_text:
        logger.info(f"[{user_id}] (Setup Graph) Node: process_canon_node -> æ­£åœ¨è™•ç†ä¸–ç•Œè–ç¶“...")
        await ai_core.add_canon_to_vector_store(canon_text)
        await ai_core.parse_and_create_lore_from_canon(None, canon_text, is_setup_flow=True)
        if not await ai_core.initialize():
            raise Exception("åœ¨è¼‰å…¥ä¸–ç•Œè–ç¶“å¾Œé‡æ–°åˆå§‹åŒ– AI æ ¸å¿ƒå¤±æ•—ã€‚")
    return {}
async def complete_profiles_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    logger.info(f"[{user_id}] (Setup Graph) Node: complete_profiles_node -> æ­£åœ¨è£œå®Œè§’è‰²æª”æ¡ˆ...")
    completion_prompt = ai_core.get_profile_completion_prompt()
    completion_llm = ai_core.gm_model.with_structured_output(CharacterProfile)
    completion_chain = completion_prompt | completion_llm
    completed_user_profile = await ai_core.ainvoke_with_rotation(completion_chain, {"profile_json": ai_core.profile.user_profile.model_dump_json()})
    completed_ai_profile = await ai_core.ainvoke_with_rotation(completion_chain, {"profile_json": ai_core.profile.ai_profile.model_dump_json()})
    await ai_core.update_and_persist_profile({'user_profile': completed_user_profile.model_dump(), 'ai_profile': completed_ai_profile.model_dump()})
    return {}
async def world_genesis_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    logger.info(f"[{user_id}] (Setup Graph) Node: world_genesis_node -> æ­£åœ¨åŸ·è¡Œä¸–ç•Œå‰µä¸–...")
    genesis_chain = ai_core.get_world_genesis_chain()
    genesis_result = await ai_core.ainvoke_with_rotation(genesis_chain, {"world_settings": ai_core.profile.world_settings, "username": ai_core.profile.user_profile.name, "ai_name": ai_core.profile.ai_profile.name})
    if not genesis_result:
        raise Exception("ä¸–ç•Œå‰µä¸–éˆè¿”å›žäº†ç©ºçµæžœï¼Œå¯èƒ½æ˜¯å…§å®¹å¯©æŸ¥ã€‚")
    gs = ai_core.profile.game_state
    gs.location_path = genesis_result.location_path
    await ai_core.update_and_persist_profile({'game_state': gs.model_dump()})
    await lore_book.add_or_update_lore(user_id, 'location_info', " > ".join(genesis_result.location_path), genesis_result.location_info.model_dump())
    for npc in genesis_result.initial_npcs:
        npc_key = " > ".join(genesis_result.location_path) + f" > {npc.name}"
        await lore_book.add_or_update_lore(user_id, 'npc_profile', npc_key, npc.model_dump())
    return {"genesis_result": genesis_result}
async def generate_opening_scene_node(state: SetupGraphState) -> Dict:
    user_id = state['user_id']
    ai_core = state['ai_core']
    logger.info(f"[{user_id}] (Setup Graph) Node: generate_opening_scene_node -> æ­£åœ¨ç”Ÿæˆé–‹å ´ç™½...")
    opening_scene = await ai_core.generate_opening_scene()
    if not opening_scene or not opening_scene.strip():
        opening_scene = (f"åœ¨ä¸€ç‰‡æŸ”å’Œçš„å…‰èŠ’ä¸­ï¼Œä½ å’Œ {ai_core.profile.ai_profile.name} ç™¼ç¾è‡ªå·±èº«è™•æ–¼ä¸€å€‹å¯§éœçš„ç©ºé–“è£¡ï¼Œæ•…äº‹å³å°‡å¾žé€™è£¡é–‹å§‹ã€‚"
                         "\n\nï¼ˆç³»çµ±æç¤ºï¼šç”±æ–¼æ‚¨çš„è¨­å®šï¼ŒAIç„¡æ³•ç”Ÿæˆæ›´è©³ç´°çš„é–‹å ´ç™½ï¼Œä½†æ‚¨ç¾åœ¨å¯ä»¥é–‹å§‹äº’å‹•äº†ã€‚ï¼‰")
    return {"opening_scene": opening_scene}
def create_setup_graph() -> StateGraph:
    graph = StateGraph(SetupGraphState)
    graph.add_node("process_canon", process_canon_node)
    graph.add_node("complete_profiles", complete_profiles_node)
    graph.add_node("world_genesis", world_genesis_node)
    graph.add_node("generate_opening_scene", generate_opening_scene_node)
    graph.set_entry_point("process_canon")
    graph.add_edge("process_canon", "complete_profiles")
    graph.add_edge("complete_profiles", "world_genesis")
    graph.add_edge("world_genesis", "generate_opening_scene")
    graph.add_edge("generate_opening_scene", END)
    return graph.compile()
